{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xspencer6/CPE-313---Activities/blob/main/Hands_on_Activity_2_2_Training_Neural_Networks_ALMODiEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 2.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Px-f0pj-lMb",
        "outputId": "f6a8fbce-edc6-407a-860e-a9fe6cda0f67"
      },
      "id": "4Px-f0pj-lMb",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"/content/drive/MyDrive/data/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "faf07cb8-f370-4e34-e3ea-d3660e1e930f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "495               6                     166              74               0   \n",
              "202               0                     108              68              20   \n",
              "669               9                     154              78              30   \n",
              "521               3                     124              80              33   \n",
              "89                1                     107              68              19   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "495        0  26.6              0.304   66             0  \n",
              "202        0  27.3              0.787   32             0  \n",
              "669      100  30.9              0.164   45             0  \n",
              "521      130  33.2              0.305   26             0  \n",
              "89         0  26.5              0.165   24             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ed17c96-0c50-49f4-949d-be4f951845db\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>6</td>\n",
              "      <td>166</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.304</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>0</td>\n",
              "      <td>108</td>\n",
              "      <td>68</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>27.3</td>\n",
              "      <td>0.787</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>9</td>\n",
              "      <td>154</td>\n",
              "      <td>78</td>\n",
              "      <td>30</td>\n",
              "      <td>100</td>\n",
              "      <td>30.9</td>\n",
              "      <td>0.164</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>3</td>\n",
              "      <td>124</td>\n",
              "      <td>80</td>\n",
              "      <td>33</td>\n",
              "      <td>130</td>\n",
              "      <td>33.2</td>\n",
              "      <td>0.305</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>107</td>\n",
              "      <td>68</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>0.165</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ed17c96-0c50-49f4-949d-be4f951845db')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ed17c96-0c50-49f4-949d-be4f951845db button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ed17c96-0c50-49f4-949d-be4f951845db');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee3408e9-0ed9-45f4-9503-77fa0798d94c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee3408e9-0ed9-45f4-9503-77fa0798d94c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee3408e9-0ed9-45f4-9503-77fa0798d94c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6b490a-885c-467a-8309-94a8e5c2f09f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aecd356-d8cf-463f-abe4-3cd0a99c223e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c494af7-e07c-407f-92d3-c3974252b9b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 12)                108       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90856613-462f-4fff-cca2-fca9bc9c0371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.6817 - accuracy: 0.6042 - val_loss: 0.6718 - val_accuracy: 0.6562\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.6372 - val_loss: 0.6547 - val_accuracy: 0.6510\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.6545 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6806 - val_loss: 0.6289 - val_accuracy: 0.6667\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6231 - accuracy: 0.7014 - val_loss: 0.6190 - val_accuracy: 0.6823\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.7031 - val_loss: 0.6106 - val_accuracy: 0.6875\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.7170 - val_loss: 0.6034 - val_accuracy: 0.7031\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.7205 - val_loss: 0.5971 - val_accuracy: 0.6927\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.7257 - val_loss: 0.5915 - val_accuracy: 0.6771\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.7257 - val_loss: 0.5866 - val_accuracy: 0.6823\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.7240 - val_loss: 0.5821 - val_accuracy: 0.6823\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7240 - val_loss: 0.5781 - val_accuracy: 0.6875\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7274 - val_loss: 0.5743 - val_accuracy: 0.6875\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7240 - val_loss: 0.5708 - val_accuracy: 0.6927\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5633 - accuracy: 0.7292 - val_loss: 0.5675 - val_accuracy: 0.6979\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.7309 - val_loss: 0.5644 - val_accuracy: 0.7031\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7344 - val_loss: 0.5615 - val_accuracy: 0.7031\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7326 - val_loss: 0.5586 - val_accuracy: 0.7083\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7326 - val_loss: 0.5560 - val_accuracy: 0.7083\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7361 - val_loss: 0.5534 - val_accuracy: 0.7083\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7361 - val_loss: 0.5509 - val_accuracy: 0.7083\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.7431 - val_loss: 0.5485 - val_accuracy: 0.7083\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7431 - val_loss: 0.5462 - val_accuracy: 0.7135\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7431 - val_loss: 0.5440 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7465 - val_loss: 0.5419 - val_accuracy: 0.7240\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7448 - val_loss: 0.5398 - val_accuracy: 0.7292\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7465 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7465 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7517 - val_loss: 0.5307 - val_accuracy: 0.7292\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5168 - accuracy: 0.7500 - val_loss: 0.5291 - val_accuracy: 0.7396\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5148 - accuracy: 0.7517 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5128 - accuracy: 0.7552 - val_loss: 0.5261 - val_accuracy: 0.7552\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7569 - val_loss: 0.5247 - val_accuracy: 0.7552\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7552 - val_loss: 0.5233 - val_accuracy: 0.7552\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.7535 - val_loss: 0.5220 - val_accuracy: 0.7604\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5055 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7708\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5038 - accuracy: 0.7604 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7639 - val_loss: 0.5184 - val_accuracy: 0.7812\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.7691 - val_loss: 0.5173 - val_accuracy: 0.7760\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7708 - val_loss: 0.5163 - val_accuracy: 0.7812\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7708 - val_loss: 0.5153 - val_accuracy: 0.7865\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7708 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4943 - accuracy: 0.7726 - val_loss: 0.5135 - val_accuracy: 0.7865\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4929 - accuracy: 0.7726 - val_loss: 0.5127 - val_accuracy: 0.7865\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4916 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7865\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.5111 - val_accuracy: 0.7865\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4890 - accuracy: 0.7708 - val_loss: 0.5104 - val_accuracy: 0.7812\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7743 - val_loss: 0.5097 - val_accuracy: 0.7812\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7743 - val_loss: 0.5091 - val_accuracy: 0.7812\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.5085 - val_accuracy: 0.7812\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.5069 - val_accuracy: 0.7760\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7760\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.7760 - val_loss: 0.5055 - val_accuracy: 0.7865\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7865\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.5047 - val_accuracy: 0.7865\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7726 - val_loss: 0.5044 - val_accuracy: 0.7865\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.5041 - val_accuracy: 0.7865\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 1s 36ms/step - loss: 0.4746 - accuracy: 0.7726 - val_loss: 0.5037 - val_accuracy: 0.7865\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.4731 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7865\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4716 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7865\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 29ms/step - loss: 0.4710 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7865\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7778 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7795 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4644 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4626 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.7812 - val_loss: 0.5014 - val_accuracy: 0.7865\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7812 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4604 - accuracy: 0.7830 - val_loss: 0.5015 - val_accuracy: 0.7865\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.5016 - val_accuracy: 0.7865\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.5017 - val_accuracy: 0.7865\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4579 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7865\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.5019 - val_accuracy: 0.7865\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.7812 - val_loss: 0.5020 - val_accuracy: 0.7865\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7865\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.7812 - val_loss: 0.5022 - val_accuracy: 0.7865\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7812 - val_loss: 0.5023 - val_accuracy: 0.7865\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.7795 - val_loss: 0.5024 - val_accuracy: 0.7865\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.5025 - val_accuracy: 0.7865\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7795 - val_loss: 0.5026 - val_accuracy: 0.7865\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7795 - val_loss: 0.5027 - val_accuracy: 0.7865\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7778 - val_loss: 0.5028 - val_accuracy: 0.7865\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.5029 - val_accuracy: 0.7865\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7778 - val_loss: 0.5030 - val_accuracy: 0.7865\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.7778 - val_loss: 0.5031 - val_accuracy: 0.7865\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7778 - val_loss: 0.5032 - val_accuracy: 0.7865\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5033 - val_accuracy: 0.7865\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5034 - val_accuracy: 0.7865\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7795 - val_loss: 0.5035 - val_accuracy: 0.7865\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7795 - val_loss: 0.5036 - val_accuracy: 0.7865\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7795 - val_loss: 0.5037 - val_accuracy: 0.7917\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5038 - val_accuracy: 0.7865\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.7795 - val_loss: 0.5039 - val_accuracy: 0.7865\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5040 - val_accuracy: 0.7865\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7812 - val_loss: 0.5042 - val_accuracy: 0.7865\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5043 - val_accuracy: 0.7865\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7847 - val_loss: 0.5044 - val_accuracy: 0.7812\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.7830 - val_loss: 0.5046 - val_accuracy: 0.7812\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5047 - val_accuracy: 0.7812\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5049 - val_accuracy: 0.7812\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5050 - val_accuracy: 0.7812\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5051 - val_accuracy: 0.7865\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5053 - val_accuracy: 0.7865\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5054 - val_accuracy: 0.7865\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5056 - val_accuracy: 0.7865\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5057 - val_accuracy: 0.7865\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5058 - val_accuracy: 0.7865\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7899 - val_loss: 0.5060 - val_accuracy: 0.7865\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.7899 - val_loss: 0.5063 - val_accuracy: 0.7865\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7882 - val_loss: 0.5065 - val_accuracy: 0.7865\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.7882 - val_loss: 0.5066 - val_accuracy: 0.7917\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.5067 - val_accuracy: 0.7917\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7899 - val_loss: 0.5069 - val_accuracy: 0.7917\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7865 - val_loss: 0.5070 - val_accuracy: 0.7917\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7882 - val_loss: 0.5071 - val_accuracy: 0.7917\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7882 - val_loss: 0.5073 - val_accuracy: 0.7917\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7865 - val_loss: 0.5074 - val_accuracy: 0.7917\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7865 - val_loss: 0.5075 - val_accuracy: 0.7917\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7865 - val_loss: 0.5077 - val_accuracy: 0.7917\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7882 - val_loss: 0.5079 - val_accuracy: 0.7917\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7882 - val_loss: 0.5080 - val_accuracy: 0.7917\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7882 - val_loss: 0.5082 - val_accuracy: 0.7917\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7882 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.7882 - val_loss: 0.5085 - val_accuracy: 0.7917\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7865 - val_loss: 0.5086 - val_accuracy: 0.7917\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.7882 - val_loss: 0.5088 - val_accuracy: 0.7917\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5089 - val_accuracy: 0.7917\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5091 - val_accuracy: 0.7917\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.7830 - val_loss: 0.5092 - val_accuracy: 0.7917\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7830 - val_loss: 0.5094 - val_accuracy: 0.7917\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7847 - val_loss: 0.5095 - val_accuracy: 0.7917\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.5096 - val_accuracy: 0.7917\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7812 - val_loss: 0.5097 - val_accuracy: 0.7917\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7812 - val_loss: 0.5099 - val_accuracy: 0.7917\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.5100 - val_accuracy: 0.7917\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.5101 - val_accuracy: 0.7917\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7917\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7812 - val_loss: 0.5104 - val_accuracy: 0.7917\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7917\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7830 - val_loss: 0.5106 - val_accuracy: 0.7917\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.7812 - val_loss: 0.5108 - val_accuracy: 0.7917\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.7847 - val_loss: 0.5109 - val_accuracy: 0.7917\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7830 - val_loss: 0.5110 - val_accuracy: 0.7917\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.7830 - val_loss: 0.5112 - val_accuracy: 0.7917\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7865\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7812 - val_loss: 0.5114 - val_accuracy: 0.7865\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.7865 - val_loss: 0.5115 - val_accuracy: 0.7865\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7865\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7812\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7847 - val_loss: 0.5119 - val_accuracy: 0.7812\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7812\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.7847 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.7847 - val_loss: 0.5122 - val_accuracy: 0.7812\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.7847 - val_loss: 0.5124 - val_accuracy: 0.7812\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7847 - val_loss: 0.5126 - val_accuracy: 0.7812\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.7847 - val_loss: 0.5127 - val_accuracy: 0.7760\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.7847 - val_loss: 0.5128 - val_accuracy: 0.7760\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.7847 - val_loss: 0.5129 - val_accuracy: 0.7760\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.7847 - val_loss: 0.5130 - val_accuracy: 0.7760\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.7847 - val_loss: 0.5132 - val_accuracy: 0.7760\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.7847 - val_loss: 0.5133 - val_accuracy: 0.7760\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7847 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5137 - val_accuracy: 0.7812\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.7847 - val_loss: 0.5138 - val_accuracy: 0.7812\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.7847 - val_loss: 0.5139 - val_accuracy: 0.7812\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.7847 - val_loss: 0.5140 - val_accuracy: 0.7812\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5141 - val_accuracy: 0.7812\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7812\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7812\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4369 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7812\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7812\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7812\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8341b3cc-5263-4cc9-fa62-8821ee91a543"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ba780c-9e86-4f7a-b936-cb69dc4d67cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d08d1f-a67a-4bfa-8e6f-95b0cecda7e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58051276],\n",
              "       [0.5974004 ],\n",
              "       [0.29516488],\n",
              "       [0.18257546],\n",
              "       [0.25017953],\n",
              "       [0.42416787],\n",
              "       [0.02065038],\n",
              "       [0.2635917 ],\n",
              "       [0.9502044 ],\n",
              "       [0.14437601]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "5c8ee245-5f11-4ee6-fb64-f147541fb6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.781\n",
            "roc-auc is 0.815\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuxElEQVR4nO3deVhV5frG8RuQQUDUEscshwYzO2qaHgPTSqUyy1PmmFPmkNpEZU5paoZlmg2O5VApgnmsrDwqaZ4yLcuhrNQcs1JQc0DZAht4f3902D8REDbT2sP3c11ctRdr7fXAu5Gb513r3T7GGCMAAADAIr5WFwAAAADvRiAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYCkCKQAAACxFIAWQr6lTp6pevXry8/NTkyZNrC4HLqRfv36qU6dOjm0+Pj564YUXnH6uRYsWycfHR99//33JFOdF2rZtq0aNGhW436FDh+Tj46NFixaVflFAERBI4bKyf0llf5QrV061atVSv3799Oeff+Z5jDFG77//vm699VZVqlRJwcHBuvHGGzVx4kSlpKTke64PP/xQd911l6pUqaKAgADVrFlTXbt21fr16wtVa2pqql577TW1bNlSFStWVFBQkK699loNHz5cv/76a5G+fqutXbtWI0aMUEREhBYuXKiXXnqpVM/Xr18/+fj46B//+IfyekdjHx8fDR8+3PE4+xesj4+P/v3vf+fa/4UXXpCPj49OnDhRqnUXVnY92R/BwcFq2LChxo4dq+TkZMd+eYWz7GN9fX31+++/53ru5ORklS9fPtf36EK7du2Sj4+PgoKCdPr06RL/+lzNqlWrihSOAVijnNUFAAWZOHGi6tatq9TUVH3zzTdatGiRNm7cqJ9++klBQUGO/TIzM9WzZ08tW7ZMrVu31gsvvKDg4GB99dVXmjBhgj744AN9/vnnqlatmuMYY4wefvhhLVq0SE2bNlV0dLSqV6+uo0eP6sMPP9Qdd9yhr7/+Wrfccku+9Z04cUJ33nmntm7dqnvuuUc9e/ZUaGio9uzZo7i4OM2bN0/p6eml+j0qDevXr5evr6/mz5+vgICAMjvvzp07tWLFCj3wwAOFPmbixIm6//775ePjU4qVlYzZs2crNDRU586d09q1azV58mStX79eX3/9dYH1BwYGaunSpRoxYkSO7StWrCjwvIsXL1b16tV16tQpLV++XI888kixvo68nD9/XuXKucavlVWrVmnmzJmEUsBNuMa/HMAl3HXXXWrevLkk6ZFHHlGVKlX08ssva+XKleratatjv1deeUXLli3TM888o6lTpzq2Dxo0SF27dlXnzp3Vr18//ec//3F8btq0aVq0aJGefPJJTZ8+PUcgGDNmjN5///0Cf8H269dP27dv1/Lly3OFqEmTJmnMmDHF+vqzZWRkKCsrq8zC4bFjx1S+fPkSO58xRqmpqSpfvny++5QvX161a9d2KmA2adJEO3bs0Icffqj777+/RGotTV26dFGVKlUkSUOGDNEDDzygFStW6JtvvlGrVq0ueezdd9+dZyCNjY1Vx44d8+wUS39/72NjY9WzZ08dPHhQS5YsKZVAeuEfiCialJQUhYSEWF0GUOaYsofbad26tSRp//79jm3nz5/X1KlTde211yomJibXMZ06dVLfvn21evVqffPNN45jYmJi1KBBA7366qt5hp/evXurRYsW+dby7bff6rPPPtOAAQPy7OgFBgbq1VdfdTxu27at2rZtm2u/i6/Hy56OfvXVVzVjxgzVr19fgYGB2r59u8qVK6cJEybkeo49e/bIx8dHb731lmPb6dOn9eSTT6p27doKDAzU1VdfrZdffllZWVn5fk3S39PjCxcuVEpKimOKOfvas4yMDE2aNMlRU506dTR69GilpaXleI46deronnvu0Zo1a9S8eXOVL19ec+fOveR5fX19NXbsWP3444/68MMPL7lvtu7du+vaa6/VxIkT85zqL4zt27frrrvuUlhYmEJDQ3XHHXc4XifZsqfSv/76a0VHRys8PFwhISH617/+pePHjxfpvJJ0++23S5IOHjxY4L49e/bUjh07tHv3bse2xMRErV+/Xj179sz3uK+//lqHDh1S9+7d1b17d3355Zf6448/Cl3jRx99pEaNGikoKEiNGjXKd2wuvob0t99+09ChQ3XdddepfPnyuvzyy/Xggw/q0KFDeR5vs9k0ePBgXX755QoLC1OfPn106tSpXPv95z//UevWrRUSEqIKFSqoY8eO+vnnnx2f79evn2bOnOmoKfsjW1ZWlmbMmKEbbrhBQUFBqlatmgYPHpzrXN9//72ioqJUpUoVlS9fXnXr1tXDDz9c4Pcr+7W/du1aNWnSREFBQWrYsGGuTnb2a+q///2vhg4dqqpVq+qKK65wfH7WrFm64YYbFBgYqJo1a2rYsGH5Xm6xdetW3XLLLY4658yZU2CdkrR792516dJFl112mYKCgtS8eXOtXLkyzzo3btyoxx9/XOHh4apUqZIGDx6s9PR0nT59Wn369FHlypVVuXJljRgxosg/i/BeBFK4nexfZpUrV3Zs27hxo06dOqWePXvm29Hs06ePJOnTTz91HHPy5En17NlTfn5+Raol+x/u3r17F+n4gixcuFBvvvmmBg0apGnTpqlGjRpq06aNli1blmvf+Ph4+fn56cEHH5T09y/3Nm3aaPHixerTp4/eeOMNRUREaNSoUYqOjr7ked9//321bt1agYGBev/99x3X5Up/d6nHjRunm266Sa+99pratGmjmJgYde/ePdfz7NmzRz169FD79u31+uuvF+rGqJ49e+qaa64pdMD08/PT2LFj9cMPPxQ6xF7o559/VuvWrfXDDz9oxIgRev7553Xw4EG1bdtW3377ba79H3vsMf3www8aP368Hn30UX3yySf5XrdZGNl/WF1++eUF7nvrrbfqiiuuUGxsrGNbfHy8QkND1bFjx3yPW7JkierXr6+bb75ZnTp1UnBwsJYuXVqo+tauXasHHnhAPj4+iomJUefOndW/f/9C3YD03XffadOmTerevbveeOMNDRkyROvWrVPbtm1ls9ly7T98+HDt2rVLL7zwgvr06aMlS5aoc+fOOV4H77//vjp27KjQ0FC9/PLLev755/XLL78oMjLS8W/D4MGD1b59e8f+2R/ZBg8erGeffVYRERF6/fXX1b9/fy1ZskRRUVGy2+2S/p4h6NChgw4dOqSRI0fqzTffVK9evXL9oZKfvXv3qlu3brrrrrsUExOjcuXK6cEHH1RCQkKufYcOHapffvlF48aN08iRIyX9fd3wsGHDVLNmTU2bNk0PPPCA5s6dqw4dOjhqzHbq1CndfffdatasmV555RVdccUVevTRR7VgwYJL1vjzzz/rn//8p3bt2qWRI0dq2rRpCgkJUefOnfP8WXrssce0d+9eTZgwQffee6/mzZun559/Xp06dVJmZqZeeuklRUZGaurUqTm+30ChGMBFLVy40Egyn3/+uTl+/Lj5/fffzfLly014eLgJDAw0v//+u2PfGTNmGEnmww8/zPf5Tp48aSSZ+++/3xhjzOuvv17gMQX517/+ZSSZU6dOFWr/Nm3amDZt2uTa3rdvX3PVVVc5Hh88eNBIMmFhYebYsWM59p07d66RZHbu3Jlje8OGDc3tt9/ueDxp0iQTEhJifv311xz7jRw50vj5+ZnDhw9fsta+ffuakJCQHNt27NhhJJlHHnkkx/ZnnnnGSDLr1693bLvqqquMJLN69epLniev87377rtGklmxYoXj85LMsGHDHI+zv0dTp041GRkZ5pprrjGNGzc2WVlZxhhjxo8fbySZ48ePX/K8nTt3NgEBAWb//v2ObUeOHDEVKlQwt956q2Nb9uuxXbt2jnMYY8xTTz1l/Pz8zOnTpy95nux69uzZY44fP24OHjxo5s6dawIDA021atVMSkpKjvN89913uY49fvy4eeaZZ8zVV1/t+NzNN99s+vfvn+f3yBhj0tPTzeWXX27GjBnj2NazZ0/TuHHjS9abrUmTJqZGjRo5vr61a9caSTles9nnHz9+vOOxzWbL9XybN282ksx7773n2Jb9NTdr1sykp6c7tr/yyitGkvn444+NMcacPXvWVKpUyQwcODDHcyYmJpqKFSvm2D5s2DCT16+4r776ykgyS5YsybF99erVObZ/+OGHucahsLJf+//+978d286cOWNq1KhhmjZtmuvrjoyMNBkZGY7tx44dMwEBAaZDhw4mMzPTsf2tt94yksyCBQsc29q0aWMkmWnTpjm2paWlmSZNmpiqVas6vp/ZPy8LFy507HfHHXeYG2+80aSmpjq2ZWVlmVtuucVcc801ueqMiorK8dpv1aqV8fHxMUOGDHFsy8jIMFdccUWe/84Bl0KHFC6vXbt2Cg8PV+3atdWlSxeFhIRo5cqVOaa2zp49K0mqUKFCvs+T/bnsO5qz/3upYwpSEs9xKQ888IDCw8NzbLv//vtVrlw5xcfHO7b99NNP+uWXX9StWzfHtg8++ECtW7dW5cqVdeLECcdHu3btlJmZqS+//NLpelatWiVJuTqsTz/9tCTps88+y7G9bt26ioqKcvo8vXr1KnKX9KOPPir0eTIzM7V27Vp17txZ9erVc2yvUaOGevbsqY0bN+a4A176+5rkC6d/W7durczMTP3222+FOud1112n8PBw1a1bV4MHD9bVV1+tzz77TMHBwYU6vmfPntq3b5++++47x38vNV3/n//8R3/99Zd69Ojh2NajRw/98MMPOaa583L06FHt2LFDffv2VcWKFR3b27dvr4YNGxZY64XXC9vtdv3111+6+uqrValSJW3bti3X/oMGDZK/v7/j8aOPPqpy5co5XncJCQk6ffq0evTokeM17efnp5YtW+qLL74osKYPPvhAFStWVPv27XM8R7NmzRQaGup4jkqVKkn6e0bl4o5kYdSsWVP/+te/HI+zL0HYvn27EhMTc+w7cODAHLM0n3/+udLT0/Xkk0/K19c3x35hYWG5fs7KlSunwYMHOx4HBARo8ODBOnbsmLZu3ZpnfSdPntT69evVtWtXnT171vF9+OuvvxQVFaW9e/fmWs1kwIABOV77LVu2lDFGAwYMcGzz8/NT8+bNdeDAgcJ8mwAHAilc3syZM5WQkKDly5fr7rvv1okTJxQYGJhjn+xAmB1M83JxaA0LCyvwmIKUxHNcSt26dXNtq1Kliu64444c0/bx8fEqV65cjpt69u7dq9WrVys8PDzHR7t27ST9PSXprN9++02+vr66+uqrc2yvXr26KlWqlCuU5VV/YWQHzB07dhQ6YPbq1UtXX321U9eSHj9+XDabTdddd12uz11//fXKysrKtczSlVdemeNx9qUjeV3rmJd///vfSkhI0IYNG7Rv3z799NNPatasWaGOlaSmTZuqQYMGio2N1ZIlS1S9enXHdah5Wbx4serWravAwEDt27dP+/btU/369RUcHKwlS5Zc8lzZ43nNNdfk+lxe37OLnT9/XuPGjXNcw1ylShWFh4fr9OnTOnPmTK79Lz5PaGioatSo4ZiK37t3r6S/r7u9+HW9du3aQr2m9+7dqzNnzqhq1aq5nuPcuXOO52jTpo0eeOABTZgwQVWqVNF9992nhQsX5rpWOj9XX311ruvSr732WknKdQ3txT8n2d/3i7/HAQEBqlevXq6fs5o1a+a6ESq/c2Xbt2+fjDF6/vnnc30fxo8fLyn3vxEXv/az/0ipXbt2ru2F/XkAsnGXPVxeixYtHHfZd+7cWZGRkerZs6f27Nmj0NBQSX+HB0n68ccf1blz5zyf58cff5QkR2enQYMGkv5eZii/Ywpy4XNk32x1KT4+PnmGpczMzDz3z++O9O7du6t///7asWOHmjRpomXLlumOO+5w3L0t/X3jRvv27XPdkZ0t+xdWURR2eaVL3VFfkF69emnSpEmaOHFiocYnO8T269dPH3/8cZHPW5jz5KWwIfjWW2/NMU5F0bNnT82ePVsVKlRQt27dcnTRLpScnKxPPvlEqampeYbK2NhYTZ48udSWy3rssce0cOFCPfnkk2rVqpUqVqwoHx8fde/evcAb6/KSfcz777+v6tWr5/p8YZacysrKUtWqVfMN49kzEj4+Plq+fLm++eYbffLJJ1qzZo0efvhhTZs2Td98843j356SUJyfk6LK/l4+88wz+c5iXPyHZ36v/by2F/bnAchGIIVb8fPzU0xMjG677Ta99dZbjhsAIiMjValSJcXGxmrMmDF5/gP53nvvSZLuuecexzGVK1fW0qVLNXr06CLd2NSpUyfFxMRo8eLFhQqklStXznMqq7DTvdk6d+6swYMHO6btf/31V40aNSrHPvXr19e5c+ccHdGScNVVVykrK0t79+51/BEgSUlJSTp9+rSuuuqqEjtXUQLmQw89pBdffNFx00VBwsPDFRwcrD179uT63O7du+Xr65ur++MKevbsqXHjxuno0aOXvHlkxYoVSk1N1ezZs3OF4D179mjs2LH6+uuvFRkZmefx2eOZ3Zm8+PiCLF++XH379tW0adMc21JTU/O9U3zv3r267bbbHI/PnTuno0eP6u6775b092takqpWrVrg6zq/kF2/fn19/vnnioiIKFQQ/Oc//6l//vOfmjx5smJjY9WrVy/FxcUVuGxWdgfywjqy3yTj4ne4ulj2933Pnj05LiVJT0/XwYMHc33tR44cybVcVEHnyn5ef3//Ev03Aigqpuzhdtq2basWLVpoxowZSk1NlSQFBwfrmWee0Z49e/Jc9/Ozzz7TokWLFBUVpX/+85+OY5577jnt2rVLzz33XJ5/0S9evFhbtmzJt5ZWrVrpzjvv1DvvvJPn1HJ6erqeeeYZx+P69etr9+7dOZYJ+uGHH/T1118X+uuX/r6+LSoqSsuWLVNcXJwCAgJydRG7du2qzZs3a82aNbmOP336tDIyMpw6pyRHMJgxY0aO7dOnT5ekS97pXRQPPfSQrr766jyXucrLhVP9Fy9dk9/+HTp00Mcff5xjajMpKUmxsbGKjIx0XJbhSurXr68ZM2YoJibmksuSLV68WPXq1dOQIUPUpUuXHB/PPPOMQkNDLzltX6NGDTVp0kTvvvtujin2hIQE/fLLLwXW6efnl+vn6s0338x3RmDevHk5rtecPXu2MjIydNddd0mSoqKiFBYWppdeeinP6zov/LnKDmcXh9+uXbsqMzNTkyZNynV8RkaGY/9Tp07lqj17lYjCTNsfOXIkx53qycnJeu+999SkSZM8u7sXateunQICAvTGG2/kqGH+/Pk6c+ZMrp+zjIyMHEuqpaena+7cuQoPD8/3cpCqVauqbdu2mjt3ro4ePZrr88VZygwoCjqkcEvPPvusHnzwQS1atEhDhgyRJI0cOVLbt2/Xyy+/rM2bN+uBBx5Q+fLltXHjRi1evFjXX3+93n333VzP8/PPP2vatGn64osv1KVLF1WvXl2JiYn66KOPtGXLFm3atOmStbz33nvq0KGD7r//fnXq1El33HGHQkJCtHfvXsXFxeno0aOOtUgffvhhTZ8+XVFRURowYICOHTumOXPm6IYbbsh180xBunXrpoceekizZs1SVFSU4yaMC7+2lStX6p577lG/fv3UrFkzpaSkaOfOnVq+fLkOHTrk9NRx48aN1bdvX82bN0+nT59WmzZttGXLFr377rvq3Llzju5WSfDz89OYMWPUv3//Qh+TPdW/Y8eOQu3/4osvKiEhQZGRkRo6dKjKlSunuXPnKi0tTa+88koRKy99TzzxxCU/f+TIEX3xxRd6/PHH8/x8YGCgoqKi9MEHH+iNN97IcTPRhWJiYtSxY0dFRkbq4Ycf1smTJ/Xmm2/qhhtu0Llz5y5Zwz333KP3339fFStWVMOGDbV582Z9/vnn+S5xlZ6erjvuuENdu3bVnj17NGvWLEVGRjq63WFhYZo9e7Z69+6tm266Sd27d1d4eLgOHz6szz77TBEREY51eLOD2OOPP66oqCj5+fmpe/fuatOmjQYPHqyYmBjt2LFDHTp0kL+/v/bu3asPPvhAr7/+urp06aJ3331Xs2bN0r/+9S/Vr19fZ8+e1dtvv62wsDDHH2aXcu2112rAgAH67rvvVK1aNS1YsEBJSUlauHBhgceGh4dr1KhRmjBhgu68807de++9ju/HzTffrIceeijH/jVr1tTLL7+sQ4cO6dprr1V8fLx27NihefPm5Tuu0t/X50dGRurGG2/UwIEDVa9ePSUlJWnz5s36448/9MMPPxRYK1BirLm5HyhYXsvfZMvMzDT169c39evXz7FcSmZmplm4cKGJiIgwYWFhJigoyNxwww1mwoQJ5ty5c/mea/ny5aZDhw7msssuM+XKlTM1atQw3bp1Mxs2bChUrTabzbz66qvm5ptvNqGhoSYgIMBcc8015rHHHjP79u3Lse/ixYtNvXr1TEBAgGnSpIlZs2ZNvss+TZ06Nd9zJicnm/LlyxtJZvHixXnuc/bsWTNq1Chz9dVXm4CAAFOlShVzyy23mFdffTXH8jp5yWvZJ2OMsdvtZsKECaZu3brG39/f1K5d24waNSrH0jHG/L30TceOHS95jsKer379+pdc9uli2a8dFWLZJ2OM2bZtm4mKijKhoaEmODjY3HbbbWbTpk15PufFr8cvvvjCSDJffPHFJc9R2GWoClr26VIu/B5NmzbNSDLr1q3Ld/9FixblWFYpP//+97/N9ddfbwIDA03Dhg3NihUrcr1ms89/4bJPp06dMv379zdVqlQxoaGhJioqyuzevdtcddVVpm/fvrm+5v/+979m0KBBpnLlyiY0NNT06tXL/PXXX7nq+eKLL0xUVJSpWLGiCQoKMvXr1zf9+vUz33//vWOfjIwM89hjj5nw8HDj4+OTawmoefPmmWbNmpny5cubChUqmBtvvNGMGDHCHDlyxBjz92uiR48e5sorrzSBgYGmatWq5p577slxjvxkv/bXrFlj/vGPf5jAwEDToEED88EHH+TY71L/xhnz9zJPDRo0MP7+/qZatWrm0UcfzbXEXJs2bcwNN9xgvv/+e9OqVSsTFBRkrrrqKvPWW2/l2C+vZZ+MMWb//v2mT58+pnr16sbf39/UqlXL3HPPPWb58uUF1pnf6zK/n2XgUnyM4cpjAABKSp06ddSoUSPHm3AAKBjXkAIAAMBSBFIAAABYikAKAAAAS3ENKQAAACxFhxQAAACWIpACAADAUm6xMH5WVpaOHDmiChUqlNp7LgMAAKDojDE6e/asatasKV9f53qebhFIjxw54pLvJw0AAICcfv/9d11xxRVOHeMWgbRChQqS/v4CL3xfabvdrrVr1zre+g2ehzH2Doyzd2CcPR9j7B3yG+fk5GTVrl3bkduc4XQg/fLLLzV16lRt3bpVR48e1YcffqjOnTtf8pgNGzYoOjpaP//8s2rXrq2xY8eqX79+hT5n9jR9WFhYrkAaHByssLAwXvgeijH2Doyzd2CcPR9j7B0KGueiXF7p9E1NKSkpaty4sWbOnFmo/Q8ePKiOHTvqtttu044dO/Tkk0/qkUce0Zo1a5wuFgAAAJ7H6Q7pXXfdpbvuuqvQ+8+ZM0d169bVtGnTJEnXX3+9Nm7cqNdee01RUVHOnh4AAAD6+yYim81W5ue12+1KTU1VSS5lX+rXkG7evFnt2rXLsS0qKkpPPvlkvsekpaUpLS3N8Tg5OVnS398Au93u2J79/xdug2dhjL0D4+wdGGfPxxiXHWOM2rZtq82bN1tWw7Fjx1SpUiXH4+KMe6kH0sTERFWrVi3HtmrVqik5OVnnz59X+fLlcx0TExOjCRMm5Nq+du1aBQcH59qekJBQcgXDJTHG3oFx9g6Ms+djjEtfamqqpWFUktavX6+goCDH4+J0a13yLvtRo0YpOjra8Tj7rq0OHTrkuqkpISFB7du35+JpD8UYewfG2Tswzp6PMS47KSkpjv//448/FBISUurn3Ldvn6KjozVz5kz98ssvuueeexQQEOD4fPaMdlGUeiCtXr26kpKScmxLSkpSWFhYnt1RSQoMDFRgYGCu7f7+/nm+wPPbDs/BGHsHxtk7MM6ejzEufRd+fytVqlTqgdQYoyNHjig+Pl5VqlTRgQMHFBAQkKOO4ox5qb91aKtWrbRu3boc2xISEtSqVavSPjUAAACKaffu3erVq5fuvfde1ahRo1TO4XQgPXfunHbs2KEdO3ZI+ntZpx07dujw4cOS/p5u79Onj2P/IUOG6MCBAxoxYoR2796tWbNmadmyZXrqqadK5isAAABAqTh69KiGDRum6dOnl+p5nA6k33//vZo2baqmTZtKkqKjo9W0aVONGzdO0t+FZ4dTSapbt64+++wzJSQkqHHjxpo2bZreeecdlnwCAABwYXv27FFgYKBWrFih6tWrl+q5nL6GtG3btpdcd2rRokV5HrN9+3ZnTwUAAAAL/Pzzz3riiScUGxuryy67rNTPV+rXkAIAAMC9LFu2TLGxsapatWqZnM8ll30CAABA2du5c6cSEhLyXA++NBFIAQAAoJ07dyo6OlpLly4t83MzZQ8AAODlTpw4oUqVKmnp0qWqUqVKmZ+fQAoAAODFduzYoR49eqhq1aqWhFGJQAoAAOC10tPTNWnSJMXHx+f5LpllhWtIAQAAvNC2bduUkpKi5cuXy8fHx9Ja6JACAAB4ma1bt2rkyJFq1KiR5WFUokMKAADgVbKysvTHH39o2bJlqlSpktXlSCKQAgAAD2eMkc1ms7qMEpWSklKk47777jvNmjVLCxcuLOGKiodACgAAPJYxRpGRkdq0aZPVpVjuwIEDev755xUfH291KblwDSkAAPBYNpvNo8NoRESEgoODC9xv+/btuuyyy/Tvf/9bFStWLIPKnEOHFAAAeIWkpCSFhIRYXUaJCg4OLvCmpM2bN2vixImKj4932a+fQAoAALxCSEiIyway0rR69WrFx8crLCzM6lLyRSAFAADwQJs2bdK2bds0YcIEq0spEIEUAADAw2zevFmTJ09WXFyc1aUUCoEUAADAgyQmJqpmzZqKj49XaGio1eUUCnfZAwAAeIgvv/xSAwcOVK1atdwmjEp0SAEAcDnuupC73W5XamqqUlJS5O/vb3U5koq+gLw7SklJ0cyZMxUXF6dy5dwr4rlXtQAAeDgWckdRbNiwQcHBwS656H1hMGUPAIAL8fSF3K1S2AXk3dEXX3yh6dOnq1GjRlaXUmR0SAEAcFHutpC73W7XmjVrFBUV5TJT9tkKs4C8O8rIyNDZs2cVFxfn1oGbQAoAgItyt4Xc7Xa7goKCFBIS4nKB1BN9/vnnWrFihWbNmmV1KcVGIAUAAHAzP/30k9566y0tXbrU6lJKBNeQAgAAuJFNmzbpyiuvVFxcnMqXL291OSWCQAoAAOAm1qxZo1dffVUBAQEKCgqyupwSw5Q9AMAtuetanQXxpnUz4RxjjDZv3qzY2FiPCqMSgRQA4IZYqxPeZtWqVTpy5IheeOEFq0spFQRSAIDb8Ya1Oj153Uw4Z82aNVq4cKEWL15sdSmlhkAKAHBr7rZWZ2F56rqZcM7vv/+u66+/XosXL1ZgYKDV5ZQaAikAwK2521qdQGGtXLlSsbGxWrp0qcf/ccJd9gAAAC7m5MmTWrFihd577z2PD6MSHVIAAACX8tFHH6lu3bpatGiR1aWUGTqkAAAALmLFihWKj49Xw4YNrS6lTBFIAQAAXEB6eroCAgL03nvvyd/f3+pyyhRT9gAAl1KYBe9ZPB6eZvny5fr22281depUq0uxBIEUAOAyWPAe3uibb77RRx995FXXjF6MKXsAgMtwdsF7Fo+Hu/v88891ww03aNGiRSpXznv7hN77lQMAXFphFrxn8Xi4s6VLl+o///mP2rZt69VhVCKQAgBcFAvew5NlZmbq4MGDWrBggdeHUYlACgAAUKaWLFkiHx8fjR492upSXAbXkAIAAJSR+Ph4rVu3Tt26dbO6FJdChxQAAKAMHDhwQBEREerSpYv8/PysLsel0CEFAAAoZYsWLdKUKVN0xRVXEEbzQIcUAJCvwixSX1h2u12pqalKSUnJ911oWPAenujo0aP67rvvNGfOHKtLcVkEUgBAnlikHii+d999V61atdLMmTOtLsWlMWUPAMiTs4vUlyQWvIcneOedd7R582ZdffXVVpfi8uiQAgAKVJhF6gtit9u1Zs0aRUVF5Ttln40F7+HuUlNTdcUVV+jhhx+Wry/9v4IQSAEABSqJRertdruCgoIUEhJSYCAF3NncuXOVlJSkcePGWV2K2yCQAgAAlJCEhATt3LlTb775ptWluBUCKQAAQAn4+OOP1b59e7Vr145LTpzERQ0AAADFNHPmTK1fv17ly5cnjBYBgRQAAKAY0tPTlZqaqhkzZhBGi4gpewAAgCJ6/fXXVadOHT399NNWl+LW6JACAAAUwdy5c3X48GHde++9Vpfi9uiQAgAAOGn37t3q1KmTatSowTR9CaBDCgAA4IRp06Zp0aJFqlmzJmG0hBBIAQAACmn//v06efKkYmJirC7FoxBIAQAACmHGjBkKCAjQ5MmT6YyWMK4hBQAAKMCUKVN09uxZXXHFFVaX4pEIpAAAAJeQkpKili1bqm3btnRGSwmBFABcjDFGNpvN6jKUkpJidQmA5V588UWFhYXp8ccft7oUj0YgBQAXYoxRZGSkNm3aZHUpgNdbvny57Ha7HnvsMatL8XgEUgBwITabzeXCaEREhIKDg60uAyhTS5cu1QMPPKAuXbpYXYpXIJACgItKSkpSSEiI1WUoODiY6+bgVV544QX5+voqICDA6lK8BoEUAFxUSEiISwRSwFtkX79do0YNDR482OpyvArrkAIAAK9njNG4ceO0ZcsWwqgFCKQAAMDrTZkyRcHBwbrtttusLsUrMWUPAAC8ljFGO3fu1COPPKLw8HCry/FadEgBAIBXMsZo1KhRWrNmDWHUYnRIAcAJpb1oPYvRA2Vn586dCg8P19NPP211KV6PQAoAhcSi9YBnMMZo4sSJGjp0KGHURTBlDwCFVJaL1rMYPVA6jDF69tlnFRYWxjS9C6FDCgBFUNqL1rMYPVDyjDE6e/as7r//ft1yyy1Wl4MLEEgBoAhYtB5wL8YYRUdH66abblLv3r2tLgcXYcoeAAB4vIULF6pevXqEURdFhxQAAHgsY4wWLFigfv36yc/Pz+pykA86pAAAwCMZY/T4448rPT2dMOri6JACAACPY4zRmTNn1KpVK/Xs2dPqclAAAikA/E9Bi96zaD3gHrKysjR8+HA9/PDDhFE3QSAFALHoPeBJRo4cqaZNm6p58+ZWl4JCIpACgJxb9J5F6wHXlJWVpW3btmnkyJG67LLLrC4HTiCQAsBFClr0nkXrAdeTlZWlIUOGqFWrVnRG3RCBFAAuwqL3gPv59ttv1apVK/Xv39/qUlAELPsEAADcVmZmpp555hndcMMNhFE3RiAFAABuKSsrS4MGDVLjxo0VFhZmdTkoBqbsAQCA28nMzNTZs2c1dOhQNWvWzOpyUEx0SAEAgFvJzMzUgAED9NVXXxFGPQQdUgCloqBF5i9kt9uVmpqqlJQU+fv7l3JleWPRe8B9vPXWW+rQoYM6depkdSkoIQRSACWOReYBlIaMjAy9/fbbevzxx1l6zcMwZQ+gxDmzyLyrYdF7wDVlZGSof//+uuyyywijHogOKYBSVdAi89LfU/Zr1qxRVFSUZVP22Vj0HnA9WVlZOnXqlLp27co0vYcikAIoVYVZZN5utysoKEghISGWB1IArsVut6tfv356/vnnCaMejCl7AADgsh577DHdf//9atCggdWloBTRIQUAAC7Hbrdr27ZteuWVV1j03gvQIQUAAC4lPT1dDz30kI4ePUoY9RJ0SAHky5m1RC/Emp4AiuOrr75Sz549dd9991ldCsoIgRRAnlhLFEBZS09P11NPPaVp06YpKCjI6nJQhpiyB5CnklhLlDU9ARSW3W7XQw89pLvuuosw6oXokAIoUGHWEs0La3oCKIy0tDTZbDaNGzdOjRo1srocWIBACqBAhVlLFACKIjU1Vb169dJjjz2mtm3bWl0OLMKUPQAAsMxrr72mRx55hDDq5eiQAgCAMpeamqr58+dr5MiRXNoDOqQAAKBspaamqkePHrrmmmsIo5BEhxQAAJShzMxMnTx5Uo8//rhuu+02q8uBiyCQAqWkqIvKuwoWtwdQ0mw2m3r06KE333yTMIocCKRAKWBReQDIbdCgQXriiSd05ZVXWl0KXAyBFCgFJbGovKtgcXsAxWWz2bRjxw7NnTuXJeSQJwIpUMqKuqi8q2BxewDFkZKSou7du+uZZ55x638LUboIpEApY1F5AN7siy++0DPPPKM2bdpYXQpcWJGWfZo5c6bq1KmjoKAgtWzZUlu2bLnk/jNmzNB1112n8uXLq3bt2nrqqaeUmppapIIBAIDrO3funAYOHKg777yTMIoCOR1I4+PjFR0drfHjx2vbtm1q3LixoqKidOzYsTz3j42N1ciRIzV+/Hjt2rVL8+fPV3x8vEaPHl3s4gEAgOs5f/68unfvrr59+6pcOSZjUTCnA+n06dM1cOBA9e/fXw0bNtScOXMUHBysBQsW5Ln/pk2bFBERoZ49e6pOnTrq0KGDevToUWBXFQAAuJ/z588rLS1N06dPV2RkpNXlwE049WdLenq6tm7dqlGjRjm2+fr6ql27dtq8eXOex9xyyy1avHixtmzZohYtWujAgQNatWqVevfune950tLSlJaW5nicnJwsSbLb7bLb7Y7t2f9/4TZ4Fncd44tfp+5Wf1lz13GGcxhnz3fy5ElNnTpVtWvXVosWLRhrD5Xfz3JxxtupQHrixAllZmaqWrVqObZXq1ZNu3fvzvOYnj176sSJE4qMjJQxRhkZGRoyZMglp+xjYmI0YcKEXNvXrl2b5/IzCQkJznwZcEOuNMbGmBx/MOXlwmuk16xZo6CgoNIuyyO40jij9DDOnmvp0qXq2rWrTpw4oVWrVlldDkrZxT/LxXkzmFK/sGPDhg166aWXNGvWLLVs2VL79u3TE088oUmTJun555/P85hRo0YpOjra8Tg5OVm1a9dWhw4dFBYW5thut9uVkJCg9u3by9/fv7S/FFjA1cbYGKO2bdvmOyOQl6ioKO6yL4CrjTNKB+Psuc6cOaPFixdrwYIFjLEXyO9nOXtGuyicCqRVqlSRn5+fkpKScmxPSkpS9erV8zzm+eefV+/evfXII49Ikm688UalpKRo0KBBGjNmjHx9c1/GGhgYqMDAwFzb/f3983yB57cdnsNVxjglJcWpMBoREaGKFSuyjmchuco4o3Qxzp7lzJkzeuihhzRx4kTHuDLG3uHicS7OmDsVSAMCAtSsWTOtW7dOnTt3liRlZWVp3bp1Gj58eJ7H2Gy2XKHTz89P0t/dJsBdFWbBexaVB+DJ7Ha7Tp8+rRdffFHNmzfnmlEUmdNT9tHR0erbt6+aN2+uFi1aaMaMGUpJSVH//v0lSX369FGtWrUUExMjSerUqZOmT5+upk2bOqbsn3/+eXXq1MkRTAF3xIL3ALzZ6dOn1a1bNy1evFjNmze3uhy4OacDabdu3XT8+HGNGzdOiYmJatKkiVavXu240enw4cM5OqJjx46Vj4+Pxo4dqz///FPh4eHq1KmTJk+eXHJfBQAAKDPGGD388MOaPHmywsPDrS4HHqBINzUNHz483yn6DRs25DxBuXIaP368xo8fX5RTAQAAF3Lq1Cnt2rVLsbGxrCCCElOktw4FAADe5+TJk+rWrZuCgoIIoyhRvJ8XAAAolA0bNujll19W06ZNrS4FHoZAClyCMSbHQr8pKSkWVgMA1vjrr7/07LPPav78+awcglLBlD2QD2OMIiMjFRoa6vi4+F3KAMDTnTlzRt27d9eTTz5JGEWpoUMK5MNms2nTpk15fi4iIiLPt7EFAE9y4sQJ+fv765133tFVV11ldTnwYHRIgUJISkrSuXPnHB9fffUVnQIAHu348ePq3r27jh49ShhFqaNDChQCi+AD8DavvfaaZsyYoQYNGlhdCrwAgRQAADgcO3ZMy5Yt00svvWR1KfAiTNkDAABJf1+e1KNHD91+++1WlwIvQ4cUAAAoLS1N586d01tvvaXrr7/e6nLgZeiQAv9jjFFKSkqODwDwBkePHlXHjh0VHh5OGIUl6JAC+v81R/Nb5gkAPFVWVpYGDhyomTNnKiwszOpy4KUIpIBYcxSAdzpy5Ih+++03rVixQgEBAVaXAy/GlD1wEdYcBeAN/vzzTz300EOqUqUKYRSWo0MKXIQ1RwF4g40bN2ru3Lm65pprrC4FoEMKAIA3+eOPPzRgwAB17dqVMAqXQYcUAAAvcezYMfXp00dvv/02lyLBpRBIAQDwAn/88YfCwsK0ZMkS1ahRw+pygByYsgcAwMP99ttv6tOnj06fPk0YhUuiQwq3ZYyRzWYrkediEXwAnuytt97SggULdOWVV1pdCpAnAincEgvZA0DBDh06pFWrVmnq1KlWlwJcElP2cEuXWsi+OFgEH4CnOHjwoB5++GHdc889VpcCFIgOKdxeUlJSia0bGhwczJ2nANyezWZTenq6Fi1axDQ93AKBFG6PhewB4P/t379fgwcP1qeffqqgoCCrywEKhSl7AAA8hN1u12OPPaZFixYRRuFW6JACAOAB9u7dq1OnTmnlypUqV45f73AvdEgBAHBze/fu1eDBg1WrVi3CKNwSr1oAANyYMUbfffedFi9erJo1a1pdDlAkBFJYqqDF7e12u1JTU5WSkiJ/f3/HdhayBwBpz549mjZtmubNm2d1KUCxEEhhGRa3B4CiO3z4sIYOHaolS5ZYXQpQbFxDCsuUxOL2LGQPwBvt379flStX1rJly1S9enWrywGKjQ4pXEJ+i9vb7XatWbNGUVFROabss7GQPQBv88svv+ixxx5TXFycwsPDrS4HKBEEUriE/Ba3t9vtCgoKUkhISJ6BFAC8zfz587V06VLCKDwKgRQAADfw008/afPmzZo2bZrVpQAljmtIAQBwcTt37tSTTz6pzp07W10KUCrokAIA4MLOnj2rcuXKKS4uTlWqVLG6HKBU0CEFAMBF/fDDD+rSpYuuueYawig8GoEUAAAXZLPZNHr0aMXGxvJ2oPB4vMIBAHAx27dvlyR98skn8vWldwTPx6scAAAXsm3bNj333HO66qqrCKPwGnRIAQBwEcYY/fLLL4qPj1flypWtLgcoMwRSAABcwPfff6+FCxdq5syZVpcClDkCKQAAFtu9e7fGjBmj+Ph4q0sBLMHFKQAAWOjnn39WrVq19MEHH6hSpUpWlwNYgkAKAIBFvv32Wz3zzDMyxigsLMzqcgDLMGWPMmWMkc1mkySlpKRYXA0AWMcYo/j4eMXHxxNG4fUIpCgzxhhFRkZq06ZNVpcCAJbavHmz9uzZo+nTp1tdCuASmLJHmbHZbHmG0YiICAUHB1tQEQCUvU2bNmnSpEl64IEHrC4FcBl0SGGJpKQkhYSESJKCg4Pl4+NjcUUAUPpOnTqlSpUqKT4+XhUqVLC6HMBl0CGFJUJCQhwfhFEA3uCrr75Sv3791KBBA8IocBECKQAApez06dOaPn26lixZwtuBAnlgyh4AgFL03//+V1WqVNGKFSuYEQLywZ9pAACUkg0bNujVV19VnTp1CKPAJdAhBQCgFGRlZenPP/9UfHw8K4kABSCQAgBQwtatW6dVq1Zp2rRpVpcCuAUCKQAAJWjr1q164403FBcXZ3UpgNvgGlIAAErI999/r+uuu05xcXEqX7681eUAboNACgBACVizZo0mT56scuXKEUYBJxFIAQAopqysLH3++edaunSpgoKCrC4HcDtcQwoAQDGsXr1ap0+f1tSpU60uBXBbdEgBACii//znP3rnnXf0r3/9y+pSALdGIAUAoAiOHz+uOnXqaMmSJQoMDLS6HMCtEUgBAHDSJ598oieeeEINGjQgjAIlgEAKAIATEhMTtXTpUi1atIi3AwVKCIEUAIBC+vTTT3Xu3DktWbJEAQEBVpcDeAwCKQAAhfDhhx9q8eLFuuqqq+iMAiWMQAoAQAEyMzOVmpqq999/X/7+/laXA3gc1iEFAOAS/v3vf2vHjh2aNGmS1aUAHotACgBAPv773/9qxYoVWrRokdWlAB6NQAoAQB42btyoZs2a6d1331W5cvy6BEoT15ACAHCR+Ph4zZs3T0FBQYRRoAwQSAEAuIDdbtePP/6oBQsWEEaBMsJPGgAA/xMbG6vQ0FBNnjzZ6lIAr0KHFAAASUuXLlVCQoI6duxodSmA16FDCgDwekeOHNFNN92krl27ys/Pz+pyAK9DIAUAeLX33ntPmzZt0pw5c6wuBfBaBFIAgNc6ePCgvv76a82aNcvqUgCvxjWkAACvtGTJEpUrV05z585lmh6wGIEUAOB1FixYoK+++kq1atWyuhQAIpACALxMRkaGwsLCNGvWLPn68msQcAVcQ+qljDGy2Wxles6UlJQyPR8AXGzevHk6ffq0RowYYXUpAC5AIPVCxhhFRkZq06ZNVpcCAGXmk08+0Q8//KA333zT6lIAXIRA6oVsNpulYTQiIkLBwcGWnR+A90lISNDtt9+ujh07Mk0PuCACqZdLSkpSSEhImZ4zODhYPj4+ZXpOAN5r1qxZ2rVrl9q1a8e/PYCLIpB6uZCQkDIPpABQVmw2m06dOqU33niDMAq4MAIpAMAjvfXWW7r++us1ZswYq0sBUAAupAEAeJxZs2bpwIEDuv32260uBUAh0CEFAHiUw4cPKyoqSo8++ijT9ICboEMKAPAYr732mubMmaP69esTRgE3QocUAOARfvrpJyUlJSkmJsbqUgA4iQ4pAMDtzZ49W1WrVtWUKVPojAJuiA4pAMCtvfLKKzp16pTCw8OtLgVAERFIAQBuKy0tTQ0aNFCnTp3ojAJujEAKAHBLL730ki6//HINHjzY6lIAFBPXkAIA3M7777+v1NRUDRo0yOpSAJQAOqQAALeycuVKPfjggwoMDGSaHvAQdEgBAG5j4sSJ2r59u4KCggijgAehQwoAcAunT59WxYoV9cQTT1hdCoASRocUAODSjDF64YUX9OuvvxJGAQ9FIAUAuLTJkyfL399fLVq0sLoUAKWEKXsAgEsyxmj//v3q06ePrrzySqvLAVCK6JACAFyOMUZjxozRxx9/TBgFvACBFADgcr799ltVqlRJTz/9tNWlACgDBFIAgMswxmjKlCm6/vrrNWLECKvLAVBGCKQAAJdgjNFzzz2ngIAAVaxY0epyAJQhbmoCAFjOGKPz58+rXbt26tChg9XlAChjBFIAgKWMMXr66afVsmVLdevWzepyAFiAQOoFjDGy2WyOxykpKRZWAwA5zZw5U3Xq1CGMAl6MQOrhjDGKjIzUpk2brC4FAHIwxuiDDz7QkCFDVK4cv44Ab1akm5qy/5oNCgpSy5YttWXLlkvuf/r0aQ0bNkw1atRQYGCgrr32Wq1atapIBcM5Npst3zAaERGh4ODgMq4IAP4Oo0888YSOHz9OGAXgfIc0Pj5e0dHRmjNnjlq2bKkZM2YoKipKe/bsUdWqVXPtn56ervbt26tq1apavny5atWqpd9++02VKlUqifrhhKSkJIWEhDgeBwcHy8fHx8KKAHirY8eOqWnTpurfv7/VpQBwAU53SKdPn66BAweqf//+atiwoebMmaPg4GAtWLAgz/0XLFigkydP6qOPPlJERITq1KmjNm3aqHHjxsUuHs4JCQnJ8UEYBVDWsrKy9OSTT+qvv/4ijAJwcCqQpqena+vWrWrXrt3/P4Gvr9q1a6fNmzfneczKlSvVqlUrDRs2TNWqVVOjRo300ksvKTMzs3iVAwDczqJFi9SoUSM1bNjQ6lIAuBCnpuxPnDihzMxMVatWLcf2atWqaffu3Xkec+DAAa1fv169evXSqlWrtG/fPg0dOlR2u13jx4/P85i0tDSlpaU5HicnJ0uS7Ha77Ha7Y3v2/1+4DTld/P1yt+8VY+wdGGfPl5WVpV9++UWdO3dWt27dGGsPxc+yd8hvnIsz7qV+JXlWVpaqVq2qefPmyc/PT82aNdOff/6pqVOn5htIY2JiNGHChFzb165dm+dNOAkJCSVet6dITU11/P+aNWsUFBRkYTVFxxh7B8bZM2VlZWnu3Lm69tprdccddzDOXoAx9g4Xj/OFS0w6y6lAWqVKFfn5+SkpKSnH9qSkJFWvXj3PY2rUqCF/f3/5+fk5tl1//fVKTExUenq6AgICch0zatQoRUdHOx4nJyerdu3a6tChg8LCwhzb7Xa7EhIS1L59e/n7+zvzpXiNC9ccjYqKynFTkztgjL0D4+zZ1q1bpwceeEC9evVinD0cP8veIb9xzp7RLgqnAmlAQICaNWumdevWqXPnzpL+/st33bp1Gj58eJ7HREREKDY2VllZWfL1/fuS1V9//VU1atTIM4xKUmBgoAIDA3Nt9/f3z/MFnt92KMf3xZ2/T+5cOwqPcfYsWVlZGj9+vEaPHq3y5cs7pvMYZ8/HGHuHi8e5OGPu9F320dHRevvtt/Xuu+9q165devTRR5WSkuK4W7JPnz4aNWqUY/9HH31UJ0+e1BNPPKFff/1Vn332mV566SUNGzasyEUDAFxbZmamBg0apKuvvlrly5e3uhwALs7pa0i7deum48ePa9y4cUpMTFSTJk20evVqx41Ohw8fdnRCJal27dpas2aNnnrqKf3jH/9QrVq19MQTT+i5554rua8CAOAyMjMzdf78efXt21etW7e2uhwAbqBINzUNHz483yn6DRs25NrWqlUrffPNN0U5FQDAjWRmZuqRRx5Rt27ddOedd1pdDgA3UaS3DgUAIC+vvPKK2rVrRxgF4BTeQBgAUGwZGRmKj4/XiBEjcqyqAgCFQYcUAFAsGRkZevjhh+Xn50cYBVAkdEgBAEVmjNHRo0d133336YEHHrC6HABuig4pAKBIMjIy1LdvX2VlZRFGARQLgRQAUCSDBw/Wvffeq6uuusrqUgC4OabsAQBOsdvt+vXXXzVlyhSFh4dbXQ4AD0CHFABQaHa7XX369NHevXsJowBKDIEUAFBoq1atUrdu3dS5c2erSwHgQZiyBwAUKD09XaNHj9aUKVNUrhy/OgCULDqkAIBLSk9P10MPPaQ2bdoQRgGUCv5lAQDkKy0tTenp6Xr22Wd18803W10OAA9FhxQAkKe0tDT16tVLP/74I2EUQKkikAIA8jRp0iQ9/PDDioiIsLoUAB6OKXsAQA6pqamKj4/XpEmT5OPjY3U5ALwAHVIAgENqaqp69Oih6tWrE0YBlBk6pAAASZIxRn/88YeGDh2q9u3bW10OAC9ChxQAoPPnz6tLly4KCwsjjAIocwRSAPByxhj17dtXQ4cOVdWqVa0uB4AXYsoeALyYzWbT/v37NW/ePFWqVMnqcgB4KTqkAOClUlJS1K1bN504cYIwCsBSdEgBwEt98sknevrpp9W2bVurSwHg5QikHsYYI5vN5nickpJiYTUAXFFKSorGjBmj6dOny9eXiTIA1uNfIg9ijFFkZKRCQ0MdH9WqVbO6LAAuJHua/oEHHiCMAnAZdEg9iM1m06ZNm/L8XEREhIKDg8u4IgCu5Ny5c5KkmJgY3XjjjRZXAwD/jz+PPVRSUpLOnTvn+Pjqq6941xXAi509e1Zdu3bV/v37CaMAXA4dUg8VEhKikJAQq8sA4CImTJigsWPHqnHjxlaXAgC5EEgBwIMlJydrxYoVmjp1KrMkAFwWU/YA4KHOnDmjrl27qkGDBoRRAC6NDikAeKCsrCz9+eefmjBhglq2bGl1OQBwSQRSN3Hx+qJ5Yc1RAJJ0+vRp9erVS7GxsapYsaLV5QBAgQikbiB7fdH8lnQCgGxZWVl66KGH9MILLxBGAbgNAqkbuNT6onlhzVHAO506dUq///67li5dqgoVKlhdDgAUGoHUzSQlJRW4nFNwcDA3MABe5tSpU+rWrZumTJlCGAXgdgikbob1RQHkZeXKlZoyZYpuuukmq0sBAKcRSAHAjZ08eVIvvPCCXn/9dWZGALgt1iEFADd16tQpde/eXQMGDCCMAnBrdEgBwA2dPHlS/v7+mjlzpq655hqrywGAYqFDCgBu5sSJE+ratasSExMJowA8AoEUANzMhAkT9NprrxFGAXgMpuwBwE0cO3ZMq1at0htvvME1owA8Ch1SAHADx44dU48ePdSiRQvCKACPQyAFABeXkZGho0eP6s0331TDhg2tLgcAShyBFABcWGJiojp27Khrr72WMArAYxFIAcBF2e129e3bV6+//rrKly9vdTkAUGq4qQkAXNDRo0f1119/6cMPP1RwcLDV5QBAqaJDCgAu5siRI+rVq5cCAgIIowC8Ah1SAHAxq1at0ty5c1lnFIDXIJC6IGOMbDab43FKSoqF1QAoK3/++adeeeUVvf7661aXAgBlikDqYowxioyM1KZNm6wuBUAZOnr0qHr37q158+ZZXQoAlDkCqYux2Wz5htGIiAiuJwM8UGJiokJDQ7Vo0SJdeeWVVpcDAGWOm5pcWFJSks6dO+f4+Oqrr3iHFsDDHD58WD169FBycjJhFIDXokPqwkJCQhQSEmJ1GQBKUUxMjBYsWKBatWpZXQoAWIZACgAW+O233/Tll19q9uzZVpcCAJZjyh4AytihQ4fUv39/3XrrrVaXAgAugUAKAGUoPT1df/31lxYuXKirrrrK6nIAwCUQSAGgjBw4cED33nuv/vGPfxBGAeACXEMKAGXg/PnzGjx4sBYsWCB/f3+rywEAl0IgBYBStm/fPtntdn366acKDAy0uhwAcDlM2QNAKdq3b58GDx6ssLAwwigA5INACgClaN26dXrvvfdYZxQALoEpewAoBb/++qvmzp2radOmWV0KALg8AikAlLADBw7o0Ucf1eLFi60uBQDcAoEUAErQ4cOHFR4ertjYWFWrVs3qcgDALXANKQCUkF27dql///5KT08njAKAE+iQlhJjjGw2m9PHpaSklEI1AEqbMUavvfaaYmNjdfnll1tdDgC4FQJpKTDGKDIyUps2bbK6FABl4Oeff9aPP/6oefPmWV0KALglpuxLgc1mK3YYjYiIUHBwcAlVBKC0/PTTT3riiSfUrl07q0sBALdFh7SUJSUlKSQkxOnjgoOD5ePjUwoVASgpqampstlsWrp0qcLDw60uBwDcFoG0lIWEhBQpkAJwbT/++KNGjx6tlStXyteXySYAKA4CKQA46cyZM3r22WcVGxtLGAWAEkAgBQAn7NixQyEhIfr000/l7+9vdTkA4BH40x4ACmn79u0aMWKELr/8csIoAJQgAikAFNK3336ruLg4XXbZZVaXAgAehSl7ACjA1q1b9cEHH2jKlClWlwIAHolACgCX8NNPP2n06NGKj4+3uhQA8FhM2QNAPvbu3asrr7xS8fHxqlSpktXlAIDHIpACQB62bNmi4cOHy8fHhzAKAKWMQAoAF8nKytL8+fO1bNkyVahQwepyAMDjcQ0pAFzgm2++0Z9//qm5c+daXQoAeA06pADwP5s3b9bEiRPVvn17q0sBAK9ChxQAJKWkpMjPz0/x8fFM0wNAGaNDCsDrbdy4UX379tXNN99MGAUAC9AhLQHGGNlsNsfjlJQUC6sB4Ixjx47p5Zdf1tKlS+Xj42N1OQDgleiQFpMxRpGRkQoNDXV8VKtWzeqyABTCxo0bZbPZ9NFHHyk0NNTqcgDAaxFIi8lms2nTpk15fi4iIkLBwcFlXBGAwvjvf/+rl19+WeHh4fLz87O6HADwakzZl6CkpCSFhIQ4HgcHBzMFCLggY4x27dqluLi4HD+zAABrEEhLUEhICL/cABf3xRdfaMOGDZowYYLVpQAA/odACsBrfPPNN5oxY4aWLl1qdSkAgAtwDSkAr/DTTz/p+uuv19KlS7m2GwBcDIEUgMdLSEjQ888/r8DAQMIoALggAikAj5aRkaGPPvpIS5cuVVBQkNXlAADywDWkADzWmjVrZLfbNXPmTKtLAQBcAh1SAB5p9erVmjdvntq1a2d1KQCAAtAhBeBxkpOTdfnllys2NlaBgYFWlwMAKAAdUgAe5dNPP9Vjjz2mm2++mTAKAG6CDikAj/Hbb7/pvffe0/vvv291KQAAJ9AhBeAR/vOf/6hcuXKKi4ujMwoAboZACsDtffzxx3r33XcVHh4uX1/+WQMAd8O/3ADcmjFGSUlJeu+99xQQEGB1OQCAIuAaUgBua8WKFfr11181cuRIq0sBABQDgRSAW0pISNDy5cv17rvvWl0KAKCYCKQA3M7WrVvVokULtW3bVv7+/laXAwAoJq4hBeBWli1bptdee00hISGEUQDwEARSAG7j/Pnz+uabb7Ro0SKVK8cEDwB4Cv5FB+AW4uLiVLVqVU2fPt3qUgAAJYwOKQCXt3TpUq1evVq33nqr1aUAAEoBHVIALu3kyZNq0KCBunbtKj8/P6vLAQCUAgIpAJf1/vvv69tvv9Vbb71ldSkAgFJEIHWSMUY2m83xOCUlxcJqAM/1yy+/aMOGDZo3b57VpQAASlmRriGdOXOm6tSpo6CgILVs2VJbtmwp1HFxcXHy8fFR586di3JayxljFBkZqdDQUMdHtWrVrC4L8DgffPCBwsPD9c477zBNDwBewOlAGh8fr+joaI0fP17btm1T48aNFRUVpWPHjl3yuEOHDumZZ55R69ati1ys1Ww2mzZt2pTn5yIiIhQcHFzGFQGeZ+HChUpISNDll18uHx8fq8sBAJQBpwPp9OnTNXDgQPXv318NGzbUnDlzFBwcrAULFuR7TGZmpnr16qUJEyaoXr16xSrYVSQlJencuXOOj6+++opfnkAxZWVlSZLmzJkjX18WAQEAb+HUv/jp6enaunWr2rVr9/9P4Ourdu3aafPmzfkeN3HiRFWtWlUDBgwoeqUuJiQkJMcHYRQonoSEBM2ePVv9+/cnjAKAl3HqpqYTJ04oMzMz13WT1apV0+7du/M8ZuPGjZo/f7527NhR6POkpaUpLS3N8Tg5OVmSZLfbZbfbHduz///CbaXp4nOX1Xm9WVmPMayxbNky7d+/X1OmTGGsPRg/z56PMfYO+Y1zcca9VO+yP3v2rHr37q23335bVapUKfRxMTExmjBhQq7ta9euzfM6zYSEhGLVWVipqamO/1+zZo2CgoLK5LwouzFG2du9e7euvPJKDRo0SOvWrbO6HJQBfp49H2PsHS4e5wtXIXKWjzHGFHbn9PR0BQcHa/ny5TnulO/bt69Onz6tjz/+OMf+O3bsUNOmTXPcJZt9jZivr6/27Nmj+vXr5zpPXh3S2rVr68SJEwoLC3Nst9vtSkhIUPv27eXv71/YL6PIUlJSVLlyZUnSqVOnFBISUurn9HZlPcYoW/PmzdPPP/+sqVOn6vPPP2ecPRw/z56PMfYO+Y1zcnKyqlSpojNnzuTIa4XhVIc0ICBAzZo107p16xyBNCsrS+vWrdPw4cNz7d+gQQPt3Lkzx7axY8fq7Nmzev3111W7du08zxMYGKjAwMBc2/39/fN8gee3vaRdeI6yOif+xvfb85w5c0ZHjx7VzJkzlZGRIYlx9haMs+djjL3DxeNcnDF3eso+Ojpaffv2VfPmzdWiRQvNmDFDKSkp6t+/vySpT58+qlWrlmJiYhQUFKRGjRrlOL5SpUqSlGu7q7pwIXwWwQdKxqxZs9SsWTO9+OKLVpcCAHABTgfSbt266fjx4xo3bpwSExPVpEkTrV692nGj0+HDhz3mDtnshfDzW3sUgPNmzpypvXv36tFHH7W6FACAiyjSTU3Dhw/Pc4pekjZs2HDJYxctWlSUU1oiv4XwWQQfKJpjx46pdevWGjp0KEulAQAceC/7QkpKSnLcxBQcHMwvU8BJM2bM0IkTJ5imBwDkQiAtpOwF8AE4b8uWLfrjjz80depUq0sBALggz7jYE4DLmj9/vq677jpNnTqVmQUAQJ7okAIoNVOnTtVff/2lsLAwwigAIF8EUgClIiMjQzVr1tQzzzxDGAUAXBKBFECJmzJlimrUqKG+fftaXQoAwA1wDSmAEjV//nylpKSoT58+VpcCAHATdEgBlJj169ere/fuLI0GAHAKgRRAiZg0aZIyMzN1++23W10KAMDNEEgBFNuxY8cUGBioESNGWF0KAMANcQ0pgGKZOHGijh07RhgFABQZgRRAkU2cOFG+vr5q1KiR1aUAANwYU/YAnGaM0dGjR9W1a1c1aNDA6nIAAG6ODikApxhj9PzzzysuLo4wCgAoEQRSAE5Zt26dQkNDFR0dbXUpAAAPwZQ9gEIxxuj111/X4MGD1a5dO6vLAQB4EDqkAApkjNHIkSOVkZGh8uXLW10OAMDD0CEFcEnGGKWlpalVq1bq3Lmz1eUAADwQgRRAvowxevbZZxUZGUkYBQCUGqbsAeRr+vTpql27NmEUAFCq6JACyMUYo9WrV2vYsGEKCgqyuhwAgIejQwogB2OMnnzySe3fv58wCgAoE3RIAeRw+PBh3XDDDRo0aJDVpQAAvAQdUgCS/u6MPvXUU8rKyiKMAgDKFIEUgCTpqaee0nXXXae6detaXQoAwMswZQ94uaysLP3xxx96/PHHVa9ePavLAQB4ITqkgBfLysrSsGHDtH79esIoAMAyBFLAi61cuVLNmjVTv379rC4FAODFmLIHvFBWVpZiYmI0YsQI+fv7W10OAMDL0SEFvExWVpYGDx6sWrVqEUYBAC6BDingRTIzM5WamqouXbooKirK6nIAAJBEhxTwGpmZmRo4cKC2bNlCGAUAuBQCKeAlJkyYoNtvv1233Xab1aUAAJADU/aAh8vMzNRnn32msWPHKiAgwOpyAADIhQ4p4MEyMjL08MMPKyUlhTAKAHBZdEgBD7Z//3517NhRXbt2tboUAADyRYcU8EAZGRkaMGCAKlasSBgFALg8AingYYwxGjBggO68805Vr17d6nIAACgQU/aAB7Hb7frjjz/04osvqnbt2laXAwBAodAhBTyE3W5Xnz599MMPPxBGAQBuhUAKeIhly5bpwQcfVOfOna0uBQAApzBlD7i59PR0TZ48WePHj5evL39jAgDcD7+9ADeWnp6u3r1766abbiKMAgDcFh1SwE2lp6crLS1Nw4cPV+vWra0uBwCAIqOlArihtLQ09erVS7t37yaMAgDcHoEUcEOjR49Wv379dPPNN1tdCgAAxcaUPeBGUlNTtWrVKr388ssqV44fXwCAZ6BDCriJ1NRU9ezZU8HBwYRRAIBH4bca4CZ+/fVXDR48WFFRUVaXAgBAiaJDCri48+fPq3v37rryyisJowAAj0QgBVxYVlaWevXqpQEDBqhSpUpWlwMAQKlgyh5wUTabTYmJiZo1a5aqV69udTkAAJQaOqSAC7LZbOrRo4d+++03wigAwOMRSAEXFBsbqyeeeEK33Xab1aUAAFDqmLIHXEhKSopeeuklvfjii/Lx8bG6HAAAygQdUsBFpKSkqFu3burQoQNhFADgVeiQAi7AZrMpMzNTL7zwgpo3b251OQAAlCk6pIDFzp07pwcffFB//vknYRQA4JXokF7AGCObzeZ4nJKSYmE18BbPPvusRo8ereuvv97qUgAAsASB9H+MMYqMjNSmTZusLgVe4uzZs1q7dq1mzpwpX18mKwAA3ovfgv9js9nyDaMREREKDg4u44rgyZKTk9W1a1fVrFmTMAoA8Hp0SPOQlJSkkJAQx+Pg4GDuekaJMcZo9+7dGj9+vP75z39aXQ4AAJYjkOYhJCQkRyAFSsqZM2fUr18/LVmyhK47AAD/w1whUEYyMjLUvXt3jRo1ijAKAMAF6JACZeD06dM6efKk3n//fVWpUsXqcgAAcCl0SIFSdurUKXXt2lUnT54kjAIAkAc6pEApW7p0qWJiYtSsWTOrSwEAwCURSIFScvLkSU2bNk2TJ0+2uhQAAFwaU/ZAKTh58qS6d++uLl26WF0KAAAujw4pUMKSk5Pl5+enGTNmqGHDhlaXAwCAy6NDCpSgEydO6P7779epU6cIowAAFBKBFChBI0aM0PTp01WnTh2rSwEAwG0wZQ+UgOPHj+vLL7/U/PnzeZtZAACcRIcUKKZjx46pe/fuuu666wijAAAUAR1SoBiMMfr111/1xhtv6IYbbrC6HAAA3BIdUqCIkpKSdN9996lly5aEUQAAioEOKVAEqamp6tWrl9588035+/tbXQ4AAG6NQAo46ejRo0pLS9Py5ctVqVIlq8sBAMDtMWUPOOHo0aPq1auX0tLSCKMAAJQQAinghPj4eM2ePVvXXXed1aUAAOAxmLIHCuHPP//U7Nmz9eKLL1pdCgAAHocOKVCAI0eOqE+fPurXr5/VpQAA4JHokAKX8Ndff6l8+fJ6++23Va9ePavLAQDAI9EhBfLx+++/68EHH1R6ejphFACAUkQgBfJgjNHo0aP1zjvvqFq1alaXAwCAR2PKHrjIb7/9pm3btum9997jvekBACgDdEiBCxw6dEj9+/dX06ZNCaMAAJQRAinwP5mZmTp06JAWLFigOnXqWF0OAABeg0AKSDp48KDuv/9+3XrrrYRRAADKGNeQwuslJydrwIABWrRokXx9+RsNAICyRiCFV9u/f78CAgK0cuVKhYaGWl0OAABeiXYQvNa+ffs0aNAg+fr6EkYBALAQgRRe6+OPP9Z7772nWrVqWV0KAABejSl7eJ29e/dq8eLFmjBhgtWlAAAAEUjhZfbt26chQ4bo/ffft7oUAADwPwRSeI3ExERddtllWrx4sWrUqGF1OQAA4H+4hhReYffu3erZs6d8fX0JowAAuBgCKTyeMUaTJk1SbGysKlWqZHU5AADgIkzZw6P98ssv2r9/v5YsWWJ1KQAAIB90SOGxfv75Zz3++ONq2bKl1aUAAIBLIJDCI2VkZCgpKUmxsbGqWrWq1eUAAIBLIJDC4+zcuVPdu3fXbbfdRhgFAMANcA0pPMrx48cVHR2tpUuXysfHx+pyAABAIdAhhcfYuXOn7Ha7Vq5cqSpVqlhdDgAAKCQCKTzCjh079PTTTyswMFDly5e3uhwAAOAEpuzhERISEhQXF6fLLrvM6lIAAICTCKRwa9u2bdOqVas0duxYq0sBAABFRCCF2/rhhx80atQoxcXFWV0KAAAoBq4hhVv6/fffVbNmTcXFxaly5cpWlwMAAIqBQAq389133+mRRx5RSEgIYRQAAA9QpEA6c+ZM1alTR0FBQWrZsqW2bNmS775vv/22WrdurcqVK6ty5cpq167dJfcHLiUjI0Ovv/66li1bpuDgYKvLAQAAJcDpQBofH6/o6GiNHz9e27ZtU+PGjRUVFaVjx47luf+GDRvUo0cPffHFF9q8ebNq166tDh066M8//yx28fAu3377rdatW6fFixerYsWKVpcDAABKiNOBdPr06Ro4cKD69++vhg0bas6cOQoODtaCBQvy3H/JkiUaOnSomjRpogYNGuidd95RVlaW1q1bV+zi4T2+/fZbvfDCC2rVqpXVpQAAgBLm1F326enp2rp1q0aNGuXY5uvrq3bt2mnz5s2Feg6bzSa73X7J9SLT0tKUlpbmeJycnCxJstvtstvtju3Z/3/htqK6+HlL4jlRfNljcebMGS1evFjly5dnbDxQSf4sw3Uxzp6PMfYO+Y1zccbdqUB64sQJZWZmqlq1ajm2V6tWTbt37y7Uczz33HOqWbOm2rVrl+8+MTExmjBhQq7ta9euzfO6wYSEhEKd+1JSU1Md/79mzRoFBQUV+zlRfLt379aqVasUHR2tjRs3Wl0OSllJ/CzD9THOno8x9g4Xj7PNZivyc5XpOqRTpkxRXFycNmzYcMnAN2rUKEVHRzseJycnO649DQsLc2y32+1KSEhQ+/bt5e/vX6zaUlJSHP8fFRWlkJCQYj0fiu/w4cOaPXu2Hn300RIZY7iukvxZhutinD0fY+wd8hvn7BntonAqkFapUkV+fn5KSkrKsT0pKUnVq1e/5LGvvvqqpkyZos8//1z/+Mc/LrlvYGCgAgMDc2339/fP8wWe33ZnXHh8STwfiuebb75RvXr1tHz5cq1bt44x8RKMs3dgnD0fY+wdLh7n4oy5Uzc1BQQEqFmzZjluSMq+QelSN5u88sormjRpklavXq3mzZsXuVh4hy+//FKTJ09WSEhInn+YAAAAz+L0lH10dLT69u2r5s2bq0WLFpoxY4ZSUlLUv39/SVKfPn1Uq1YtxcTESJJefvlljRs3TrGxsapTp44SExMlSaGhoQoNDS3BLwWeYsuWLYqLi1NISAgXxgMA4AWcDqTdunXT8ePHNW7cOCUmJqpJkyZavXq140anw4cPy9f3/xuvs2fPVnp6urp06ZLjecaPH68XXniheNXDo2zYsEHfffednn32WatLAQAAZahINzUNHz5cw4cPz/NzGzZsyPH40KFDRTkFvMzGjRs1ffp0xcXFWV0KAAAoY7yXPSy3f/9+XXfddYqLi+PtQAEA8EIEUljq888/V3R0tCpVqkQYBQDASxFIYZnU1FTFxsYqLi6O5UEAAPBiZbowPpBt7dq1CgwM1IIFC6wuBQAAWIwOKcrcmjVrNGfOHLVs2dLqUgAAgAsgkKJMpaamKiAgQLGxsZd8+1gAAOA9mLJHmVm1apU++ugjzZs3z+pSAACAC/HaQGqMkc1mczxOSUmxsBrPt3v3bi1cuFCLFy+2uhQAAOBivHLK3hijyMhIx9uXhoaGOt5pCiVv3bp1Cg8P19KlS3lvegAAkItXBlKbzaZNmzbl+bmIiAjWwyxBK1eu1Ny5c1WhQgWVK+e1DXkAAHAJXp8QkpKSFBIS4ngcHBwsHx8fCyvyHMYY7du3T4sXL1ZAQIDV5QAAABfl9YE0JCQkRyBFyfjoo4/0+++/Kzo62upSAACAi/P6QIqSt2rVKsXHx+u9996zuhQAAOAGCKQoUbt27dLNN9+s9u3b83agAACgULzypiaUjuXLl+vFF1/U5ZdfThgFAACFRiBFiUhOTtb69ev17rvvyteXlxUAACg8puxRbPHx8apbt65mzZpldSkAAMAN0cpCscTFxemzzz7TTTfdZHUpAADATRFIUWTnzp1TzZo1tWDBAha9BwAARUaKQJEsXrxY27Zt0/Tp060uBQAAuDkCKZz2/fffa/369Xr77betLgUAAHgApuzhlI8//ljXXHON3n77bfn5+VldDgAA8AAEUhTaokWL9Omnn6pChQqEUQAAUGIIpCiUrKwsJScna+7cuawzCgAAShTXkKJACxYskCQ9/vjjFlcCAAA8Ea0uXNLSpUu1ZcsW9evXz+pSAACAh6JDinz98MMPat++vbp168Y0PQAAKDWkDORp7ty5mjdvni6//HLCKAAAKFUkDeRy/Phx7d+/X2+99ZZ8fHysLgcAAHg4AilymDNnjhITE/XKK68QRgEAQJkgkMJh5syZ2rVrlxo1amR1KQAAwItwUxMkSWfOnNFNN92koUOH0hkFAABlikAKvf766zp9+rTGjx9vdSkAAMALEUi93BdffKHDhw/r1VdftboUAADgpQikXmzJkiXq3Lmz2rZtyzQ9AACwDDc1ealp06bphx9+UHBwMGEUAABYig6pF7Lb7QoLC1N0dDRhFAAAWI5A6mVeeeUV1a1bVwMHDrS6FAAAAElM2XuV2bNn68yZM+rSpYvVpQAAADjQIfUS3333nbp3765KlSoxTQ8AAFwKHVIvMHnyZK1cuVKVK1cmjAIAAJdDIPVwhw8fliRNnDjR4koAAADy5hWB1BijlJSUHB/eICYmRhkZGRozZgydUQAA4LI8/hpSY4wiIyO1adMmq0spUxMmTJCPj4/q1atndSkAAACX5PGB1Gaz5RtGIyIiFBwcXMYVlS5jjE6ePKl77rlHzZo1s7ocAACAAnl8IL1QUlKSQkJCHI897V2KjDEaN26cwsPD9fjjj1tdDgAAQKF4VSANCQnJEUg9zcqVKxUcHEwYBQAAbsWrAqmnMsZo3rx56t+/v+677z6rywEAAHCKV9xl78mMMRo1apSSk5MVEBBgdTkAAABOo0PqxowxSk1N1Y033qhevXpZXQ4AAECR0CF1U8YYPffcc/ryyy8JowAAwK15XIfUGCObzeZ47KmL4MfExKhGjRqKioqyuhQAAIBi8ahA6g2L4Btj9PXXX2v48OEKCwuzuhwAAIBi86gpe09fBN8Yo+joaG3bto0wCgAAPIZHdUgv5ImL4P/666+65pprNHToUKtLAQAAKDEe1SG9UPYi+Nkf7hxGjTEaMWKEwsLCCKMAAMDjeGwg9RTGGD3xxBOqW7euatSoYXU5AAAAJc5jp+w9QVZWlk6cOKFBgwapUaNGVpcDAABQKuiQuqisrCwNHz5ca9asIYwCAACPRiB1UbGxsWratKl69+5tdSkAAACliil7F5OVlaU33nhDjz/+uHx9+XsBAAB4PhKPC8nKytKQIUMUFhZGGAUAAF6DDqmLyMrKUkpKijp27Kj77rvP6nIAAADKDG04F5CZmalBgwbpp59+IowCAACvQyB1AaNHj1abNm3UqlUrq0sBAAAoc0zZWygzM1Nffvmlxo8fr+DgYKvLAQAAsAQdUotkZmbqkUce0ZEjRwijAADAq9EhtcjOnTvVoUMH9ejRw+pSAAAALOXWHVJjjFJTU5WSkuL4cHUZGRl69NFHddVVVxFGAQAA5MYdUmOM2rZtq82bN1tdSqEZY9S/f3/dc889qly5stXlAAAAuAS3DaQ2my3fMBoREeFy12VmZGToxIkTGjt2rK677jqrywEAAHAZbj1ln+2PP/7QuXPnHB9fffWVfHx8rC7LwW63q2/fvvruu+8IowAAABdx2w7phUJCQhQSEmJ1GflasGCB7r//fnXq1MnqUgAAAFyORwRSV2W32/Xaa6/p2WefdamOLQAAgCvxiCl7V5Senq7evXvr2muvJYwCAABcAh3SUmC322Wz2fTII4+oXbt2VpcDAADg0uiQlrD09HT16tVLv//+O2EUAACgEAikJeypp55Snz59dOONN1pdCgAAgFtgyr6EpKWl6csvv9S0adMUFBRkdTkAAABugw5pCUhLS1OvXr2UkZFBGAUAAHASHdISsHXrVj3yyCO68847rS4FAADA7dAhLYbU1FT169dPjRs3JowCAAAUEYG0iDIyMtSjRw/17NnTpd8lCgAAwNUxZV8E58+f15kzZzR9+nTVrVvX6nIAAADcGh1SJ9lsNnXv3l179uwhjAIAAJQAAqmT5s2bp8cff1xt2rSxuhQAAACPwJR9IaWkpOiNN97QqFGjrC4FAADAo9AhLYSUlBR1795drVq1sroUAAAAj0OHtABpaWlKTU3V6NGjCaQAAAClgA7pJZw7d04PPPCAzpw5QxgFAAAoJQTSSxg+fLhGjhypevXqWV0KAACAx2LKPg9nz57V5s2b9fbbb8vf39/qcgAAADwaHdKLnD17Vt26dVNoaChhFAAAoAzQIb3Id999p+eff55rRgEAAMoIgfR/kpOTNWTIEC1atEgBAQFWlwMAAOA1mLKXlJqaqq5du+rJJ58kjAIAAJQxr++Qnj59WmlpaZo/f75q1apldTkAAABex6s7pKdPn1a3bt30559/EkYBAAAs4tWBdO7cuZo8ebJuuukmq0sBAADwWl45ZX/q1CnNmTNHo0aNsroUAAAAr+d1HdKTJ0+qW7duioqKsroUAAAAyMs6pDabTRkZGZo6daoaN25sdTkAAACQF3VI//rrL913333KzMwkjAIAALgQrwmkw4YN06uvvqoaNWpYXQoAAAAu4PFT9idOnNC2bdu0ePFilSvn8V8uAACA2/HoDunx48fVvXt31axZkzAKAADgojw2kBpjtHXrVs2YMUONGjWyuhwAAADkwyMD6bFjx9S9e3e1b9+eMAoAAODiPG4e++zZs+rZs6feeOMN+fn5WV0OAAAACuBRgTQxMVF+fn5asmSJqlWrZnU5AAAAKIQiTdnPnDlTderUUVBQkFq2bKktW7Zccv8PPvhADRo0UFBQkG688UatWrWqSMVeytGjR9WrVy+dOnWKMAoAAOBGnA6k8fHxio6O1vjx47Vt2zY1btxYUVFROnbsWJ77b9q0ST169NCAAQO0fft2de7cWZ07d9ZPP/1U7OIvNH/+fM2aNUvXXnttiT4vAAAASpfTgXT69OkaOHCg+vfvr4YNG2rOnDkKDg7WggUL8tz/9ddf15133qlnn31W119/vSZNmqSbbrpJb731VrGLz/baa69p7Nixuu6660rsOQEAAFA2nLqGND09XVu3btWoUaMc23x9fdWuXTtt3rw5z2M2b96s6OjoHNuioqL00Ucf5XuetLQ0paWlOR4nJydLkux2u+x2u+P/s9199905HsNz5DXe8DyMs3dgnD0fY+wd8hvn4oy7U4H0xIkTyszMzHWNZrVq1bR79+48j0lMTMxz/8TExHzPExMTowkTJuTavnbtWgUHB0uSUlNTHdsPHTp0yeeD+0tISLC6BJQBxtk7MM6ejzH2DhePs81mK/JzueRd9qNGjcrRVU1OTlbt2rXVoUMHhYWFSfp74ftjx45p/fr1uueeexQQEGBVuShFdrtdCQkJat++vfz9/a0uB6WEcfYOjLPnY4y9Q37jnD2jXRROBdIqVarIz89PSUlJObYnJSWpevXqeR5TvXp1p/aXpMDAQAUGBuba7u/vn+MLr1SpkoKCghQQEMAL38NdPPbwTIyzd2CcPR9j7B0uHufijLlTNzUFBASoWbNmWrdunWNbVlaW1q1bp1atWuV5TKtWrXLsL/3d4s1vfwAAAHgXp6fso6Oj1bdvXzVv3lwtWrTQjBkzlJKSov79+0uS+vTpo1q1aikmJkaS9MQTT6hNmzaaNm2aOnbsqLi4OH3//feaN29eyX4lAAAAcEtOB9Ju3brp+PHjGjdunBITE9WkSROtXr3acePS4cOH5ev7/43XW265RbGxsRo7dqxGjx6ta665Rh999JFT7zFvjJGU+9oEu90um82m5ORkpgY8FGPsHRhn78A4ez7G2DvkN87ZOS07tznDxxTlqDL2xx9/qHbt2laXAQAAgAL8/vvvuuKKK5w6xi0CaVZWlo4cOaIKFSrIx8fHsT377vvff//dcfc9PAtj7B0YZ+/AOHs+xtg75DfOxhidPXtWNWvWzDFbXhguuezTxXx9fS+ZtMPCwnjhezjG2Dswzt6BcfZ8jLF3yGucK1asWKTncvqtQwEAAICSRCAFAACApdw6kAYGBmr8+PF5LqIPz8AYewfG2Tswzp6PMfYOpTHObnFTEwAAADyXW3dIAQAA4P4IpAAAALAUgRQAAACWIpACAADAUi4fSGfOnKk6deooKChILVu21JYtWy65/wcffKAGDRooKChIN954o1atWlVGlaKonBnjt99+W61bt1blypVVuXJltWvXrsDXBFyDsz/L2eLi4uTj46POnTuXboEoNmfH+PTp0xo2bJhq1KihwMBAXXvttfyb7QacHecZM2bouuuuU/ny5VW7dm099dRTSk1NLaNq4awvv/xSnTp1Us2aNeXj46OPPvqowGM2bNigm266SYGBgbr66qu1aNEi509sXFhcXJwJCAgwCxYsMD///LMZOHCgqVSpkklKSspz/6+//tr4+fmZV155xfzyyy9m7Nixxt/f3+zcubOMK0dhOTvGPXv2NDNnzjTbt283u3btMv369TMVK1Y0f/zxRxlXDmc4O87ZDh48aGrVqmVat25t7rvvvrIpFkXi7BinpaWZ5s2bm7vvvtts3LjRHDx40GzYsMHs2LGjjCuHM5wd5yVLlpjAwECzZMkSc/DgQbNmzRpTo0YN89RTT5Vx5SisVatWmTFjxpgVK1YYSebDDz+85P4HDhwwwcHBJjo62vzyyy/mzTffNH5+fmb16tVOndelA2mLFi3MsGHDHI8zMzNNzZo1TUxMTJ77d+3a1XTs2DHHtpYtW5rBgweXap0oOmfH+GIZGRmmQoUK5t133y2tElECijLOGRkZ5pZbbjHvvPOO6du3L4HUxTk7xrNnzzb16tUz6enpZVUiSoCz4zxs2DBz++2359gWHR1tIiIiSrVOlIzCBNIRI0aYG264Ice2bt26maioKKfO5bJT9unp6dq6davatWvn2Obr66t27dpp8+bNeR6zefPmHPtLUlRUVL77w1pFGeOL2Ww22e12XXbZZaVVJoqpqOM8ceJEVa1aVQMGDCiLMlEMRRnjlStXqlWrVho2bJiqVaumRo0a6aWXXlJmZmZZlQ0nFWWcb7nlFm3dutUxrX/gwAGtWrVKd999d5nUjNJXUtmrXEkWVZJOnDihzMxMVatWLcf2atWqaffu3Xkek5iYmOf+iYmJpVYniq4oY3yx5557TjVr1sz1wwDXUZRx3rhxo+bPn68dO3aUQYUorqKM8YEDB7R+/Xr16tVLq1at0r59+zR06FDZ7XaNHz++LMqGk4oyzj179tSJEycUGRkpY4wyMjI0ZMgQjR49uixKRhnIL3slJyfr/PnzKl++fKGex2U7pEBBpkyZori4OH344YcKCgqyuhyUkLNnz6p37956++23VaVKFavLQSnJyspS1apVNW/ePDVr1kzdunXTmDFjNGfOHKtLQwnasGGDXnrpJc2aNUvbtm3TihUr9Nlnn2nSpElWlwYX47Id0ipVqsjPz09JSUk5ticlJal69ep5HlO9enWn9oe1ijLG2V599VVNmTJFn3/+uf7xj3+UZpkoJmfHef/+/Tp06JA6derk2JaVlSVJKleunPbs2aP69euXbtFwSlF+lmvUqCF/f3/5+fk5tl1//fVKTExUenq6AgICSrVmOK8o4/z888+rd+/eeuSRRyRJN954o1JSUjRo0CCNGTNGvr70xdxdftkrLCys0N1RyYU7pAEBAWrWrJnWrVvn2JaVlaV169apVatWeR7TqlWrHPtLUkJCQr77w1pFGWNJeuWVVzRp0iStXr1azZs3L4tSUQzOjnODBg20c+dO7dixw/Fx77336rbbbtOOHTtUu3btsiwfhVCUn+WIiAjt27fP8ceGJP3666+qUaMGYdRFFWWcbTZbrtCZ/UfI3/fMwN2VWPZy7n6rshUXF2cCAwPNokWLzC+//GIGDRpkKlWqZBITE40xxvTu3duMHDnSsf/XX39typUrZ1599VWza9cuM378eJZ9cnHOjvGUKVNMQECAWb58uTl69Kjj4+zZs1Z9CSgEZ8f5Ytxl7/qcHePDhw+bChUqmOHDh5s9e/aYTz/91FStWtW8+OKLVn0JKARnx3n8+PGmQoUKZunSpebAgQNm7dq1pn79+qZr165WfQkowNmzZ8327dvN9u3bjSQzffp0s337dvPbb78ZY4wZOXKk6d27t2P/7GWfnn32WbNr1y4zc+ZMz1v2yRhj3nzzTXPllVeagIAA06JFC/PNN984PtemTRvTt2/fHPsvW7bMXHvttSYgIMDccMMN5rPPPivjiuEsZ8b4qquuMpJyfYwfP77sC4dTnP1ZvhCB1D04O8abNm0yLVu2NIGBgaZevXpm8uTJJiMjo4yrhrOcGWe73W5eeOEFU79+fRMUFGRq165thg4dak6dOlX2haNQvvjiizx/z2aPa9++fU2bNm1yHdOkSRMTEBBg6tWrZxYuXOj0eX2MoWcOAAAA67jsNaQAAADwDgRSAAAAWIpACgAAAEsRSAEAAGApAikAAAAsRSAFAACApQikAAAAsBSBFAAAAJYikAIAAMBSBFIAAABYikAKAAAASxFIAQAAYKn/AxU3ju3Qy03dAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af10ad7-88f7-4548-c1eb-fb95ab489381"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "c051bc4c-0d86-445f-bc0d-1ca91c98bc46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e77bc06cf70>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "- Validation loss is around 50-55% in 200 epochs . As the number of epochs increases, the model's ability to adapt to unseen data decreases. But further increasing the number of epochs may increase its performance in unseen data. The error loss increases, which means applying regularization on data may help as the model is not able to generalize on new data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import data"
      ],
      "metadata": {
        "id": "Ej0FzvzCCQwF"
      },
      "id": "Ej0FzvzCCQwF"
    },
    {
      "cell_type": "code",
      "source": [
        "smokerdf = pd.read_csv('/content/drive/MyDrive/data/smoking.csv')"
      ],
      "metadata": {
        "id": "VNw9U6mVCPkl"
      },
      "id": "VNw9U6mVCPkl",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smokerdf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa1w1ePFEQus",
        "outputId": "3f0639e3-d73e-4c3b-96db-2c9b70737de5"
      },
      "id": "xa1w1ePFEQus",
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55692, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smokerdf.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-ZrhvCgEYtM",
        "outputId": "77f2663c-cba5-41fb-d575-e8e8be78a2da"
      },
      "id": "E-ZrhvCgEYtM",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                     0\n",
              "gender                 0\n",
              "age                    0\n",
              "height(cm)             0\n",
              "weight(kg)             0\n",
              "waist(cm)              0\n",
              "eyesight(left)         0\n",
              "eyesight(right)        0\n",
              "hearing(left)          0\n",
              "hearing(right)         0\n",
              "systolic               0\n",
              "relaxation             0\n",
              "fasting blood sugar    0\n",
              "Cholesterol            0\n",
              "triglyceride           0\n",
              "HDL                    0\n",
              "LDL                    0\n",
              "hemoglobin             0\n",
              "Urine protein          0\n",
              "serum creatinine       0\n",
              "AST                    0\n",
              "ALT                    0\n",
              "Gtp                    0\n",
              "oral                   0\n",
              "dental caries          0\n",
              "tartar                 0\n",
              "smoking                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smokerdf.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "WxE4oIE9EcG8",
        "outputId": "c3133bd1-441d-499d-aea7-91434ed4a40c"
      },
      "id": "WxE4oIE9EcG8",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 ID           age    height(cm)    weight(kg)     waist(cm)  \\\n",
              "count  55692.000000  55692.000000  55692.000000  55692.000000  55692.000000   \n",
              "mean   27845.500000     44.182917    164.649321     65.864936     82.046418   \n",
              "std    16077.039933     12.071418      9.194597     12.820306      9.274223   \n",
              "min        0.000000     20.000000    130.000000     30.000000     51.000000   \n",
              "25%    13922.750000     40.000000    160.000000     55.000000     76.000000   \n",
              "50%    27845.500000     40.000000    165.000000     65.000000     82.000000   \n",
              "75%    41768.250000     55.000000    170.000000     75.000000     88.000000   \n",
              "max    55691.000000     85.000000    190.000000    135.000000    129.000000   \n",
              "\n",
              "       eyesight(left)  eyesight(right)  hearing(left)  hearing(right)  \\\n",
              "count    55692.000000     55692.000000   55692.000000    55692.000000   \n",
              "mean         1.012623         1.007443       1.025587        1.026144   \n",
              "std          0.486873         0.485964       0.157902        0.159564   \n",
              "min          0.100000         0.100000       1.000000        1.000000   \n",
              "25%          0.800000         0.800000       1.000000        1.000000   \n",
              "50%          1.000000         1.000000       1.000000        1.000000   \n",
              "75%          1.200000         1.200000       1.000000        1.000000   \n",
              "max          9.900000         9.900000       2.000000        2.000000   \n",
              "\n",
              "           systolic  ...           HDL           LDL    hemoglobin  \\\n",
              "count  55692.000000  ...  55692.000000  55692.000000  55692.000000   \n",
              "mean     121.494218  ...     57.290347    114.964501     14.622592   \n",
              "std       13.675989  ...     14.738963     40.926476      1.564498   \n",
              "min       71.000000  ...      4.000000      1.000000      4.900000   \n",
              "25%      112.000000  ...     47.000000     92.000000     13.600000   \n",
              "50%      120.000000  ...     55.000000    113.000000     14.800000   \n",
              "75%      130.000000  ...     66.000000    136.000000     15.800000   \n",
              "max      240.000000  ...    618.000000   1860.000000     21.100000   \n",
              "\n",
              "       Urine protein  serum creatinine           AST           ALT  \\\n",
              "count   55692.000000      55692.000000  55692.000000  55692.000000   \n",
              "mean        1.087212          0.885738     26.182935     27.036037   \n",
              "std         0.404882          0.221524     19.355460     30.947853   \n",
              "min         1.000000          0.100000      6.000000      1.000000   \n",
              "25%         1.000000          0.800000     19.000000     15.000000   \n",
              "50%         1.000000          0.900000     23.000000     21.000000   \n",
              "75%         1.000000          1.000000     28.000000     31.000000   \n",
              "max         6.000000         11.600000   1311.000000   2914.000000   \n",
              "\n",
              "                Gtp  dental caries       smoking  \n",
              "count  55692.000000   55692.000000  55692.000000  \n",
              "mean      39.952201       0.213334      0.367288  \n",
              "std       50.290539       0.409665      0.482070  \n",
              "min        1.000000       0.000000      0.000000  \n",
              "25%       17.000000       0.000000      0.000000  \n",
              "50%       25.000000       0.000000      0.000000  \n",
              "75%       43.000000       0.000000      1.000000  \n",
              "max      999.000000       1.000000      1.000000  \n",
              "\n",
              "[8 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d9e5335-915b-4dd9-8c05-f041d363b405\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>age</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>waist(cm)</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>eyesight(right)</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>systolic</th>\n",
              "      <th>...</th>\n",
              "      <th>HDL</th>\n",
              "      <th>LDL</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>Urine protein</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>dental caries</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "      <td>55692.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>27845.500000</td>\n",
              "      <td>44.182917</td>\n",
              "      <td>164.649321</td>\n",
              "      <td>65.864936</td>\n",
              "      <td>82.046418</td>\n",
              "      <td>1.012623</td>\n",
              "      <td>1.007443</td>\n",
              "      <td>1.025587</td>\n",
              "      <td>1.026144</td>\n",
              "      <td>121.494218</td>\n",
              "      <td>...</td>\n",
              "      <td>57.290347</td>\n",
              "      <td>114.964501</td>\n",
              "      <td>14.622592</td>\n",
              "      <td>1.087212</td>\n",
              "      <td>0.885738</td>\n",
              "      <td>26.182935</td>\n",
              "      <td>27.036037</td>\n",
              "      <td>39.952201</td>\n",
              "      <td>0.213334</td>\n",
              "      <td>0.367288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16077.039933</td>\n",
              "      <td>12.071418</td>\n",
              "      <td>9.194597</td>\n",
              "      <td>12.820306</td>\n",
              "      <td>9.274223</td>\n",
              "      <td>0.486873</td>\n",
              "      <td>0.485964</td>\n",
              "      <td>0.157902</td>\n",
              "      <td>0.159564</td>\n",
              "      <td>13.675989</td>\n",
              "      <td>...</td>\n",
              "      <td>14.738963</td>\n",
              "      <td>40.926476</td>\n",
              "      <td>1.564498</td>\n",
              "      <td>0.404882</td>\n",
              "      <td>0.221524</td>\n",
              "      <td>19.355460</td>\n",
              "      <td>30.947853</td>\n",
              "      <td>50.290539</td>\n",
              "      <td>0.409665</td>\n",
              "      <td>0.482070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>13922.750000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>13.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>27845.500000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>165.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>14.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>41768.250000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>170.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>15.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>55691.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>129.000000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>9.900000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>240.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>618.000000</td>\n",
              "      <td>1860.000000</td>\n",
              "      <td>21.100000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.600000</td>\n",
              "      <td>1311.000000</td>\n",
              "      <td>2914.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows  24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d9e5335-915b-4dd9-8c05-f041d363b405')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d9e5335-915b-4dd9-8c05-f041d363b405 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d9e5335-915b-4dd9-8c05-f041d363b405');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a94c0305-b66e-4e11-9c1a-85bbc2781975\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a94c0305-b66e-4e11-9c1a-85bbc2781975')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a94c0305-b66e-4e11-9c1a-85bbc2781975 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Some maximum values within the data when compared to its corresponding mean are too large, which means StandardScaler should be used to normalize the behavior of data."
      ],
      "metadata": {
        "id": "QD-hbwIrkhHZ"
      },
      "id": "QD-hbwIrkhHZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dependent and independent variables\n",
        "X = smokerdf.iloc[:, 1:-1]\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "-vrKzJmlEuBl",
        "outputId": "cf4f6b73-09d8-4eff-b623-a2b88b1563e8"
      },
      "id": "-vrKzJmlEuBl",
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      gender  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
              "0          F   40         155          60       81.3             1.2   \n",
              "1          F   40         160          60       81.0             0.8   \n",
              "2          M   55         170          60       80.0             0.8   \n",
              "3          M   40         165          70       88.0             1.5   \n",
              "4          F   40         155          60       86.0             1.0   \n",
              "...      ...  ...         ...         ...        ...             ...   \n",
              "55687      F   40         170          65       75.0             0.9   \n",
              "55688      F   45         160          50       70.0             1.2   \n",
              "55689      F   55         160          50       68.5             1.0   \n",
              "55690      M   60         165          60       78.0             0.8   \n",
              "55691      M   55         160          65       85.0             0.9   \n",
              "\n",
              "       eyesight(right)  hearing(left)  hearing(right)  systolic  ...    LDL  \\\n",
              "0                  1.0            1.0             1.0     114.0  ...  126.0   \n",
              "1                  0.6            1.0             1.0     119.0  ...  127.0   \n",
              "2                  0.8            1.0             1.0     138.0  ...  151.0   \n",
              "3                  1.5            1.0             1.0     100.0  ...  226.0   \n",
              "4                  1.0            1.0             1.0     120.0  ...  107.0   \n",
              "...                ...            ...             ...       ...  ...    ...   \n",
              "55687              0.9            1.0             1.0     110.0  ...  118.0   \n",
              "55688              1.2            1.0             1.0     101.0  ...   79.0   \n",
              "55689              1.2            1.0             1.0     117.0  ...   63.0   \n",
              "55690              1.0            1.0             1.0     133.0  ...  146.0   \n",
              "55691              0.7            1.0             1.0     124.0  ...  150.0   \n",
              "\n",
              "       hemoglobin  Urine protein  serum creatinine   AST   ALT   Gtp  oral  \\\n",
              "0            12.9            1.0               0.7  18.0  19.0  27.0     Y   \n",
              "1            12.7            1.0               0.6  22.0  19.0  18.0     Y   \n",
              "2            15.8            1.0               1.0  21.0  16.0  22.0     Y   \n",
              "3            14.7            1.0               1.0  19.0  26.0  18.0     Y   \n",
              "4            12.5            1.0               0.6  16.0  14.0  22.0     Y   \n",
              "...           ...            ...               ...   ...   ...   ...   ...   \n",
              "55687        12.3            1.0               0.6  14.0   7.0  10.0     Y   \n",
              "55688        14.0            1.0               0.9  20.0  12.0  14.0     Y   \n",
              "55689        12.4            1.0               0.5  17.0  11.0  12.0     Y   \n",
              "55690        14.4            1.0               0.7  20.0  19.0  18.0     Y   \n",
              "55691        15.0            1.0               0.8  26.0  29.0  41.0     Y   \n",
              "\n",
              "       dental caries  tartar  \n",
              "0                  0       Y  \n",
              "1                  0       Y  \n",
              "2                  0       N  \n",
              "3                  0       Y  \n",
              "4                  0       N  \n",
              "...              ...     ...  \n",
              "55687              1       Y  \n",
              "55688              0       Y  \n",
              "55689              0       N  \n",
              "55690              0       N  \n",
              "55691              0       Y  \n",
              "\n",
              "[55692 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e754e67e-d9c9-48c9-aa35-7c63851a579d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>waist(cm)</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>eyesight(right)</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>systolic</th>\n",
              "      <th>...</th>\n",
              "      <th>LDL</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>Urine protein</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>oral</th>\n",
              "      <th>dental caries</th>\n",
              "      <th>tartar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>40</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>81.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>126.0</td>\n",
              "      <td>12.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>40</td>\n",
              "      <td>160</td>\n",
              "      <td>60</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>127.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>55</td>\n",
              "      <td>170</td>\n",
              "      <td>60</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>...</td>\n",
              "      <td>151.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>40</td>\n",
              "      <td>165</td>\n",
              "      <td>70</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>226.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F</td>\n",
              "      <td>40</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>107.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55687</th>\n",
              "      <td>F</td>\n",
              "      <td>40</td>\n",
              "      <td>170</td>\n",
              "      <td>65</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>...</td>\n",
              "      <td>118.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55688</th>\n",
              "      <td>F</td>\n",
              "      <td>45</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55689</th>\n",
              "      <td>F</td>\n",
              "      <td>55</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>68.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55690</th>\n",
              "      <td>M</td>\n",
              "      <td>60</td>\n",
              "      <td>165</td>\n",
              "      <td>60</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>...</td>\n",
              "      <td>146.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55691</th>\n",
              "      <td>M</td>\n",
              "      <td>55</td>\n",
              "      <td>160</td>\n",
              "      <td>65</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>...</td>\n",
              "      <td>150.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>Y</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55692 rows  25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e754e67e-d9c9-48c9-aa35-7c63851a579d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e754e67e-d9c9-48c9-aa35-7c63851a579d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e754e67e-d9c9-48c9-aa35-7c63851a579d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e82e1461-4bae-4770-b339-1e1da14c968d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e82e1461-4bae-4770-b339-1e1da14c968d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e82e1461-4bae-4770-b339-1e1da14c968d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = smokerdf.iloc[:, -1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp40OZbzl5F9",
        "outputId": "6f4d39e9-f107-4bca-b6e7-41f40c0b76cf"
      },
      "id": "jp40OZbzl5F9",
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        1\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "55687    0\n",
              "55688    0\n",
              "55689    0\n",
              "55690    0\n",
              "55691    1\n",
              "Name: smoking, Length: 55692, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Since there are columns that are not numerical, let's change it using np.where the value will be 1 if the corresponding value is equal to 'Y'. Otherwise it is 0."
      ],
      "metadata": {
        "id": "6VTmc7oUi2bC"
      },
      "id": "6VTmc7oUi2bC"
    },
    {
      "cell_type": "code",
      "source": [
        "X.oral = pd.Series(np.where(smokerdf.oral.values == 'Y', 1, 0), smokerdf.index)\n",
        "X.tartar = pd.Series(np.where(smokerdf.tartar.values == 'Y', 1, 0), smokerdf.index)\n",
        "X.gender = pd.Series(np.where(smokerdf.gender.values == 'M', 1, 0), smokerdf.index)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "QihIo6IfjGVD",
        "outputId": "3ef5a9a0-20b3-4260-f634-77e0f255bd9f"
      },
      "id": "QihIo6IfjGVD",
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       gender  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
              "0           0   40         155          60       81.3             1.2   \n",
              "1           0   40         160          60       81.0             0.8   \n",
              "2           1   55         170          60       80.0             0.8   \n",
              "3           1   40         165          70       88.0             1.5   \n",
              "4           0   40         155          60       86.0             1.0   \n",
              "...       ...  ...         ...         ...        ...             ...   \n",
              "55687       0   40         170          65       75.0             0.9   \n",
              "55688       0   45         160          50       70.0             1.2   \n",
              "55689       0   55         160          50       68.5             1.0   \n",
              "55690       1   60         165          60       78.0             0.8   \n",
              "55691       1   55         160          65       85.0             0.9   \n",
              "\n",
              "       eyesight(right)  hearing(left)  hearing(right)  systolic  ...    LDL  \\\n",
              "0                  1.0            1.0             1.0     114.0  ...  126.0   \n",
              "1                  0.6            1.0             1.0     119.0  ...  127.0   \n",
              "2                  0.8            1.0             1.0     138.0  ...  151.0   \n",
              "3                  1.5            1.0             1.0     100.0  ...  226.0   \n",
              "4                  1.0            1.0             1.0     120.0  ...  107.0   \n",
              "...                ...            ...             ...       ...  ...    ...   \n",
              "55687              0.9            1.0             1.0     110.0  ...  118.0   \n",
              "55688              1.2            1.0             1.0     101.0  ...   79.0   \n",
              "55689              1.2            1.0             1.0     117.0  ...   63.0   \n",
              "55690              1.0            1.0             1.0     133.0  ...  146.0   \n",
              "55691              0.7            1.0             1.0     124.0  ...  150.0   \n",
              "\n",
              "       hemoglobin  Urine protein  serum creatinine   AST   ALT   Gtp  oral  \\\n",
              "0            12.9            1.0               0.7  18.0  19.0  27.0     1   \n",
              "1            12.7            1.0               0.6  22.0  19.0  18.0     1   \n",
              "2            15.8            1.0               1.0  21.0  16.0  22.0     1   \n",
              "3            14.7            1.0               1.0  19.0  26.0  18.0     1   \n",
              "4            12.5            1.0               0.6  16.0  14.0  22.0     1   \n",
              "...           ...            ...               ...   ...   ...   ...   ...   \n",
              "55687        12.3            1.0               0.6  14.0   7.0  10.0     1   \n",
              "55688        14.0            1.0               0.9  20.0  12.0  14.0     1   \n",
              "55689        12.4            1.0               0.5  17.0  11.0  12.0     1   \n",
              "55690        14.4            1.0               0.7  20.0  19.0  18.0     1   \n",
              "55691        15.0            1.0               0.8  26.0  29.0  41.0     1   \n",
              "\n",
              "       dental caries  tartar  \n",
              "0                  0       1  \n",
              "1                  0       1  \n",
              "2                  0       0  \n",
              "3                  0       1  \n",
              "4                  0       0  \n",
              "...              ...     ...  \n",
              "55687              1       1  \n",
              "55688              0       1  \n",
              "55689              0       0  \n",
              "55690              0       0  \n",
              "55691              0       1  \n",
              "\n",
              "[55692 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a0f42f8-fe3d-48bc-b738-f35af8ca0ac7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>waist(cm)</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>eyesight(right)</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>systolic</th>\n",
              "      <th>...</th>\n",
              "      <th>LDL</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>Urine protein</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>oral</th>\n",
              "      <th>dental caries</th>\n",
              "      <th>tartar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>81.3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>...</td>\n",
              "      <td>126.0</td>\n",
              "      <td>12.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>160</td>\n",
              "      <td>60</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>...</td>\n",
              "      <td>127.0</td>\n",
              "      <td>12.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>170</td>\n",
              "      <td>60</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>...</td>\n",
              "      <td>151.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>165</td>\n",
              "      <td>70</td>\n",
              "      <td>88.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>226.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>107.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55687</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>170</td>\n",
              "      <td>65</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>...</td>\n",
              "      <td>118.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55688</th>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>...</td>\n",
              "      <td>79.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55689</th>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>68.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63.0</td>\n",
              "      <td>12.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>17.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55690</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>165</td>\n",
              "      <td>60</td>\n",
              "      <td>78.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>...</td>\n",
              "      <td>146.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>20.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55691</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>160</td>\n",
              "      <td>65</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>...</td>\n",
              "      <td>150.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>26.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55692 rows  25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a0f42f8-fe3d-48bc-b738-f35af8ca0ac7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a0f42f8-fe3d-48bc-b738-f35af8ca0ac7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a0f42f8-fe3d-48bc-b738-f35af8ca0ac7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9034538f-5030-4400-8a71-2ff04ff98057\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9034538f-5030-4400-8a71-2ff04ff98057')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9034538f-5030-4400-8a71-2ff04ff98057 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can now split the data to training and testing"
      ],
      "metadata": {
        "id": "wzplDQZ6l9d6"
      },
      "id": "wzplDQZ6l9d6"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "cbqzx7B5mAik",
        "outputId": "64996fe7-c9d7-4414-fa74-63dc35c763a0"
      },
      "id": "cbqzx7B5mAik",
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       gender  age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
              "36967       0   50         155          60       70.0             0.8   \n",
              "45466       0   40         155          50       73.0             1.2   \n",
              "47799       1   40         165          55       76.0             1.5   \n",
              "33247       0   45         160          50       74.0             1.0   \n",
              "19718       0   50         165          60       72.0             1.5   \n",
              "...       ...  ...         ...         ...        ...             ...   \n",
              "44732       1   25         170          80       82.0             1.0   \n",
              "54343       1   45         165          55       70.0             0.7   \n",
              "38158       1   35         180          75       86.7             1.2   \n",
              "860         0   55         155          60       86.0             0.8   \n",
              "15795       1   55         180          70       81.0             1.0   \n",
              "\n",
              "       eyesight(right)  hearing(left)  hearing(right)  systolic  ...    LDL  \\\n",
              "36967              0.8            1.0             1.0     100.0  ...  123.0   \n",
              "45466              1.0            1.0             1.0     122.0  ...   97.0   \n",
              "47799              1.5            1.0             1.0     110.0  ...  124.0   \n",
              "33247              1.2            1.0             1.0     139.0  ...  200.0   \n",
              "19718              1.5            1.0             2.0     113.0  ...  133.0   \n",
              "...                ...            ...             ...       ...  ...    ...   \n",
              "44732              1.2            1.0             1.0     106.0  ...  108.0   \n",
              "54343              1.0            1.0             1.0     135.0  ...  102.0   \n",
              "38158              1.5            1.0             1.0     125.0  ...  101.0   \n",
              "860                0.8            1.0             1.0     100.0  ...  158.0   \n",
              "15795              1.0            1.0             1.0     108.0  ...  120.0   \n",
              "\n",
              "       hemoglobin  Urine protein  serum creatinine   AST   ALT   Gtp  oral  \\\n",
              "36967        14.8            1.0               0.8  26.0  18.0  20.0     1   \n",
              "45466        12.3            1.0               0.7  18.0  13.0  12.0     1   \n",
              "47799        14.7            1.0               1.1  15.0  10.0  13.0     1   \n",
              "33247        13.1            1.0               0.6  16.0   8.0  11.0     1   \n",
              "19718        13.2            1.0               0.7  26.0  18.0  20.0     1   \n",
              "...           ...            ...               ...   ...   ...   ...   ...   \n",
              "44732        16.6            1.0               0.8  32.0  52.0  28.0     1   \n",
              "54343        13.0            1.0               0.8  25.0  16.0  21.0     1   \n",
              "38158        16.5            2.0               0.8  13.0  25.0  30.0     1   \n",
              "860          13.4            1.0               0.8  25.0  19.0  17.0     1   \n",
              "15795        16.5            1.0               1.0  17.0  16.0  22.0     1   \n",
              "\n",
              "       dental caries  tartar  \n",
              "36967              0       0  \n",
              "45466              0       1  \n",
              "47799              0       1  \n",
              "33247              1       0  \n",
              "19718              1       0  \n",
              "...              ...     ...  \n",
              "44732              0       1  \n",
              "54343              0       1  \n",
              "38158              1       1  \n",
              "860                0       1  \n",
              "15795              0       1  \n",
              "\n",
              "[38984 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0c5e3f3-5c3a-44b4-9e98-f8e3935cdfad\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>height(cm)</th>\n",
              "      <th>weight(kg)</th>\n",
              "      <th>waist(cm)</th>\n",
              "      <th>eyesight(left)</th>\n",
              "      <th>eyesight(right)</th>\n",
              "      <th>hearing(left)</th>\n",
              "      <th>hearing(right)</th>\n",
              "      <th>systolic</th>\n",
              "      <th>...</th>\n",
              "      <th>LDL</th>\n",
              "      <th>hemoglobin</th>\n",
              "      <th>Urine protein</th>\n",
              "      <th>serum creatinine</th>\n",
              "      <th>AST</th>\n",
              "      <th>ALT</th>\n",
              "      <th>Gtp</th>\n",
              "      <th>oral</th>\n",
              "      <th>dental caries</th>\n",
              "      <th>tartar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36967</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>123.0</td>\n",
              "      <td>14.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45466</th>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>155</td>\n",
              "      <td>50</td>\n",
              "      <td>73.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>...</td>\n",
              "      <td>97.0</td>\n",
              "      <td>12.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47799</th>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>165</td>\n",
              "      <td>55</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>...</td>\n",
              "      <td>124.0</td>\n",
              "      <td>14.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>15.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33247</th>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>160</td>\n",
              "      <td>50</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>139.0</td>\n",
              "      <td>...</td>\n",
              "      <td>200.0</td>\n",
              "      <td>13.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>16.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19718</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>165</td>\n",
              "      <td>60</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>...</td>\n",
              "      <td>133.0</td>\n",
              "      <td>13.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44732</th>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>170</td>\n",
              "      <td>80</td>\n",
              "      <td>82.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>...</td>\n",
              "      <td>108.0</td>\n",
              "      <td>16.6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>32.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54343</th>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>165</td>\n",
              "      <td>55</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>135.0</td>\n",
              "      <td>...</td>\n",
              "      <td>102.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>25.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38158</th>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>180</td>\n",
              "      <td>75</td>\n",
              "      <td>86.7</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>...</td>\n",
              "      <td>101.0</td>\n",
              "      <td>16.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>13.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0</td>\n",
              "      <td>55</td>\n",
              "      <td>155</td>\n",
              "      <td>60</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>...</td>\n",
              "      <td>158.0</td>\n",
              "      <td>13.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>25.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>180</td>\n",
              "      <td>70</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>...</td>\n",
              "      <td>120.0</td>\n",
              "      <td>16.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38984 rows  25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0c5e3f3-5c3a-44b4-9e98-f8e3935cdfad')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0c5e3f3-5c3a-44b4-9e98-f8e3935cdfad button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0c5e3f3-5c3a-44b4-9e98-f8e3935cdfad');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ed37332-ca44-4cf6-bbb0-8e93d097100d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ed37332-ca44-4cf6-bbb0-8e93d097100d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ed37332-ca44-4cf6-bbb0-8e93d097100d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalize data using Standard Scaler"
      ],
      "metadata": {
        "id": "pJe_E7aIEiYE"
      },
      "id": "pJe_E7aIEiYE"
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "EGILQgm-7nGA"
      },
      "id": "EGILQgm-7nGA",
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer"
      ],
      "metadata": {
        "id": "HGnwDSHxKgQL"
      },
      "id": "HGnwDSHxKgQL"
    },
    {
      "cell_type": "code",
      "source": [
        "## Build a model with two hidden layers, each with 6 nodes\n",
        "supple_model  = Sequential([\n",
        "    Dense(16, input_dim=25, activation=\"relu\"),\n",
        "    Dense(12, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "LL3OXBgaJnOC"
      },
      "id": "LL3OXBgaJnOC",
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supple_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSm0SDOT8IJT",
        "outputId": "87889a29-926e-4302-cc0c-3d1abd53ba86"
      },
      "id": "YSm0SDOT8IJT",
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_44 (Dense)            (None, 16)                416       \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 12)                204       \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 633 (2.47 KB)\n",
            "Trainable params: 633 (2.47 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I've created 2 hidden layers with the final layer using sigmoid activation"
      ],
      "metadata": {
        "id": "BX_YOusgoFXb"
      },
      "id": "BX_YOusgoFXb"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlORbPli8Mm9",
        "outputId": "19532ac9-1909-44c4-a3b6-16e22c938fb5"
      },
      "id": "UlORbPli8Mm9",
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38984, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "ROoDagKh98H9",
        "outputId": "e01d69bc-7ed1-41da-cb59-7b004609e25b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ROoDagKh98H9",
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38984,)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "Lg8t3t0e98Nr",
        "outputId": "cea489d0-7230-4a42-dd53-d9553217be01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Lg8t3t0e98Nr",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16708,)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "84pnm0-s98Ra"
      },
      "id": "84pnm0-s98Ra",
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a learning rate of .003 and train for 1500 epochs"
      ],
      "metadata": {
        "id": "ywlYNQCgK6F2"
      },
      "id": "ywlYNQCgK6F2"
    },
    {
      "cell_type": "code",
      "source": [
        "supple_model.compile(SGD(learning_rate = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "supple_hist_1 = supple_model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_train), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laVmX40cK9yt",
        "outputId": "b656600b-d7e9-49d3-db7e-b812fc3c160d"
      },
      "id": "laVmX40cK9yt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "1219/1219 [==============================] - 7s 4ms/step - loss: 0.4860 - accuracy: 0.7299 - val_loss: 0.4845 - val_accuracy: 0.7321\n",
            "Epoch 2/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4835 - accuracy: 0.7332 - val_loss: 0.4822 - val_accuracy: 0.7342\n",
            "Epoch 3/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4815 - accuracy: 0.7356 - val_loss: 0.4804 - val_accuracy: 0.7368\n",
            "Epoch 4/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4799 - accuracy: 0.7374 - val_loss: 0.4789 - val_accuracy: 0.7388\n",
            "Epoch 5/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4785 - accuracy: 0.7391 - val_loss: 0.4776 - val_accuracy: 0.7401\n",
            "Epoch 6/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4773 - accuracy: 0.7398 - val_loss: 0.4765 - val_accuracy: 0.7411\n",
            "Epoch 7/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4762 - accuracy: 0.7412 - val_loss: 0.4755 - val_accuracy: 0.7422\n",
            "Epoch 8/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4752 - accuracy: 0.7418 - val_loss: 0.4747 - val_accuracy: 0.7429\n",
            "Epoch 9/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4744 - accuracy: 0.7426 - val_loss: 0.4737 - val_accuracy: 0.7439\n",
            "Epoch 10/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4736 - accuracy: 0.7441 - val_loss: 0.4729 - val_accuracy: 0.7441\n",
            "Epoch 11/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4728 - accuracy: 0.7440 - val_loss: 0.4722 - val_accuracy: 0.7451\n",
            "Epoch 12/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4721 - accuracy: 0.7447 - val_loss: 0.4715 - val_accuracy: 0.7454\n",
            "Epoch 13/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4714 - accuracy: 0.7466 - val_loss: 0.4709 - val_accuracy: 0.7465\n",
            "Epoch 14/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4709 - accuracy: 0.7458 - val_loss: 0.4703 - val_accuracy: 0.7472\n",
            "Epoch 15/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4703 - accuracy: 0.7475 - val_loss: 0.4697 - val_accuracy: 0.7473\n",
            "Epoch 16/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4697 - accuracy: 0.7471 - val_loss: 0.4692 - val_accuracy: 0.7477\n",
            "Epoch 17/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4692 - accuracy: 0.7477 - val_loss: 0.4687 - val_accuracy: 0.7481\n",
            "Epoch 18/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4686 - accuracy: 0.7486 - val_loss: 0.4682 - val_accuracy: 0.7484\n",
            "Epoch 19/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4677 - accuracy: 0.7488 - val_loss: 0.4672 - val_accuracy: 0.7502\n",
            "Epoch 21/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4673 - accuracy: 0.7502 - val_loss: 0.4668 - val_accuracy: 0.7511\n",
            "Epoch 22/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4669 - accuracy: 0.7511 - val_loss: 0.4664 - val_accuracy: 0.7520\n",
            "Epoch 23/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4664 - accuracy: 0.7511 - val_loss: 0.4659 - val_accuracy: 0.7529\n",
            "Epoch 24/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4660 - accuracy: 0.7526 - val_loss: 0.4655 - val_accuracy: 0.7534\n",
            "Epoch 25/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4656 - accuracy: 0.7532 - val_loss: 0.4651 - val_accuracy: 0.7535\n",
            "Epoch 26/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4652 - accuracy: 0.7535 - val_loss: 0.4648 - val_accuracy: 0.7536\n",
            "Epoch 27/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4648 - accuracy: 0.7530 - val_loss: 0.4644 - val_accuracy: 0.7536\n",
            "Epoch 28/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4644 - accuracy: 0.7536 - val_loss: 0.4640 - val_accuracy: 0.7539\n",
            "Epoch 29/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4641 - accuracy: 0.7544 - val_loss: 0.4636 - val_accuracy: 0.7541\n",
            "Epoch 30/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4637 - accuracy: 0.7548 - val_loss: 0.4633 - val_accuracy: 0.7549\n",
            "Epoch 31/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4634 - accuracy: 0.7540 - val_loss: 0.4629 - val_accuracy: 0.7556\n",
            "Epoch 32/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4631 - accuracy: 0.7548 - val_loss: 0.4626 - val_accuracy: 0.7556\n",
            "Epoch 33/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4627 - accuracy: 0.7552 - val_loss: 0.4623 - val_accuracy: 0.7560\n",
            "Epoch 34/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4625 - accuracy: 0.7551 - val_loss: 0.4620 - val_accuracy: 0.7558\n",
            "Epoch 35/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4622 - accuracy: 0.7556 - val_loss: 0.4618 - val_accuracy: 0.7555\n",
            "Epoch 36/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4619 - accuracy: 0.7553 - val_loss: 0.4615 - val_accuracy: 0.7564\n",
            "Epoch 37/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4617 - accuracy: 0.7559 - val_loss: 0.4612 - val_accuracy: 0.7563\n",
            "Epoch 38/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4614 - accuracy: 0.7561 - val_loss: 0.4610 - val_accuracy: 0.7562\n",
            "Epoch 39/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4611 - accuracy: 0.7561 - val_loss: 0.4607 - val_accuracy: 0.7562\n",
            "Epoch 40/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4608 - accuracy: 0.7562 - val_loss: 0.4605 - val_accuracy: 0.7567\n",
            "Epoch 41/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4606 - accuracy: 0.7565 - val_loss: 0.4602 - val_accuracy: 0.7568\n",
            "Epoch 42/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4603 - accuracy: 0.7571 - val_loss: 0.4600 - val_accuracy: 0.7578\n",
            "Epoch 43/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4601 - accuracy: 0.7575 - val_loss: 0.4597 - val_accuracy: 0.7572\n",
            "Epoch 44/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4599 - accuracy: 0.7573 - val_loss: 0.4594 - val_accuracy: 0.7580\n",
            "Epoch 45/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4596 - accuracy: 0.7575 - val_loss: 0.4592 - val_accuracy: 0.7582\n",
            "Epoch 46/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4594 - accuracy: 0.7578 - val_loss: 0.4590 - val_accuracy: 0.7581\n",
            "Epoch 47/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4592 - accuracy: 0.7586 - val_loss: 0.4587 - val_accuracy: 0.7583\n",
            "Epoch 48/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4589 - accuracy: 0.7585 - val_loss: 0.4585 - val_accuracy: 0.7587\n",
            "Epoch 49/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4587 - accuracy: 0.7587 - val_loss: 0.4585 - val_accuracy: 0.7593\n",
            "Epoch 50/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4585 - accuracy: 0.7591 - val_loss: 0.4581 - val_accuracy: 0.7598\n",
            "Epoch 51/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4583 - accuracy: 0.7591 - val_loss: 0.4579 - val_accuracy: 0.7600\n",
            "Epoch 52/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4581 - accuracy: 0.7602 - val_loss: 0.4576 - val_accuracy: 0.7599\n",
            "Epoch 53/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4579 - accuracy: 0.7604 - val_loss: 0.4574 - val_accuracy: 0.7603\n",
            "Epoch 54/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4576 - accuracy: 0.7602 - val_loss: 0.4572 - val_accuracy: 0.7604\n",
            "Epoch 55/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4575 - accuracy: 0.7599 - val_loss: 0.4570 - val_accuracy: 0.7600\n",
            "Epoch 56/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4572 - accuracy: 0.7599 - val_loss: 0.4568 - val_accuracy: 0.7604\n",
            "Epoch 57/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4570 - accuracy: 0.7607 - val_loss: 0.4567 - val_accuracy: 0.7614\n",
            "Epoch 58/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4568 - accuracy: 0.7610 - val_loss: 0.4564 - val_accuracy: 0.7615\n",
            "Epoch 59/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4566 - accuracy: 0.7609 - val_loss: 0.4562 - val_accuracy: 0.7616\n",
            "Epoch 60/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4564 - accuracy: 0.7606 - val_loss: 0.4560 - val_accuracy: 0.7616\n",
            "Epoch 61/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4562 - accuracy: 0.7607 - val_loss: 0.4558 - val_accuracy: 0.7619\n",
            "Epoch 62/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4560 - accuracy: 0.7612 - val_loss: 0.4556 - val_accuracy: 0.7617\n",
            "Epoch 63/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4559 - accuracy: 0.7614 - val_loss: 0.4554 - val_accuracy: 0.7625\n",
            "Epoch 64/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4557 - accuracy: 0.7615 - val_loss: 0.4552 - val_accuracy: 0.7622\n",
            "Epoch 65/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4555 - accuracy: 0.7620 - val_loss: 0.4550 - val_accuracy: 0.7622\n",
            "Epoch 66/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4553 - accuracy: 0.7616 - val_loss: 0.4548 - val_accuracy: 0.7624\n",
            "Epoch 67/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4551 - accuracy: 0.7622 - val_loss: 0.4546 - val_accuracy: 0.7629\n",
            "Epoch 68/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4549 - accuracy: 0.7619 - val_loss: 0.4545 - val_accuracy: 0.7625\n",
            "Epoch 69/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.7628 - val_loss: 0.4543 - val_accuracy: 0.7633\n",
            "Epoch 70/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4546 - accuracy: 0.7624 - val_loss: 0.4542 - val_accuracy: 0.7619\n",
            "Epoch 71/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4545 - accuracy: 0.7624 - val_loss: 0.4540 - val_accuracy: 0.7623\n",
            "Epoch 72/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4543 - accuracy: 0.7625 - val_loss: 0.4539 - val_accuracy: 0.7630\n",
            "Epoch 73/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4541 - accuracy: 0.7628 - val_loss: 0.4538 - val_accuracy: 0.7641\n",
            "Epoch 74/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4540 - accuracy: 0.7628 - val_loss: 0.4535 - val_accuracy: 0.7642\n",
            "Epoch 75/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4539 - accuracy: 0.7640 - val_loss: 0.4534 - val_accuracy: 0.7634\n",
            "Epoch 76/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4537 - accuracy: 0.7636 - val_loss: 0.4533 - val_accuracy: 0.7644\n",
            "Epoch 77/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4536 - accuracy: 0.7635 - val_loss: 0.4531 - val_accuracy: 0.7642\n",
            "Epoch 78/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4535 - accuracy: 0.7639 - val_loss: 0.4530 - val_accuracy: 0.7645\n",
            "Epoch 79/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4534 - accuracy: 0.7639 - val_loss: 0.4529 - val_accuracy: 0.7644\n",
            "Epoch 80/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4532 - accuracy: 0.7645 - val_loss: 0.4528 - val_accuracy: 0.7645\n",
            "Epoch 81/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4531 - accuracy: 0.7642 - val_loss: 0.4526 - val_accuracy: 0.7644\n",
            "Epoch 82/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4530 - accuracy: 0.7646 - val_loss: 0.4525 - val_accuracy: 0.7637\n",
            "Epoch 83/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4529 - accuracy: 0.7638 - val_loss: 0.4525 - val_accuracy: 0.7635\n",
            "Epoch 84/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4528 - accuracy: 0.7635 - val_loss: 0.4523 - val_accuracy: 0.7658\n",
            "Epoch 85/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4526 - accuracy: 0.7644 - val_loss: 0.4522 - val_accuracy: 0.7650\n",
            "Epoch 86/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4525 - accuracy: 0.7649 - val_loss: 0.4520 - val_accuracy: 0.7653\n",
            "Epoch 87/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4524 - accuracy: 0.7648 - val_loss: 0.4520 - val_accuracy: 0.7653\n",
            "Epoch 88/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4523 - accuracy: 0.7646 - val_loss: 0.4518 - val_accuracy: 0.7649\n",
            "Epoch 89/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4522 - accuracy: 0.7651 - val_loss: 0.4518 - val_accuracy: 0.7659\n",
            "Epoch 90/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4521 - accuracy: 0.7654 - val_loss: 0.4516 - val_accuracy: 0.7656\n",
            "Epoch 91/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4520 - accuracy: 0.7657 - val_loss: 0.4515 - val_accuracy: 0.7655\n",
            "Epoch 92/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4519 - accuracy: 0.7658 - val_loss: 0.4514 - val_accuracy: 0.7654\n",
            "Epoch 93/1500\n",
            "1213/1219 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.7649Epoch 94/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4517 - accuracy: 0.7649 - val_loss: 0.4512 - val_accuracy: 0.7655\n",
            "Epoch 95/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4516 - accuracy: 0.7650 - val_loss: 0.4511 - val_accuracy: 0.7659\n",
            "Epoch 96/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4515 - accuracy: 0.7653 - val_loss: 0.4512 - val_accuracy: 0.7657\n",
            "Epoch 97/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4514 - accuracy: 0.7649 - val_loss: 0.4509 - val_accuracy: 0.7660\n",
            "Epoch 98/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4513 - accuracy: 0.7659 - val_loss: 0.4509 - val_accuracy: 0.7659\n",
            "Epoch 99/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4512 - accuracy: 0.7654 - val_loss: 0.4507 - val_accuracy: 0.7663\n",
            "Epoch 100/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4512 - accuracy: 0.7661 - val_loss: 0.4507 - val_accuracy: 0.7665\n",
            "Epoch 101/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4510 - accuracy: 0.7660 - val_loss: 0.4506 - val_accuracy: 0.7662\n",
            "Epoch 102/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4510 - accuracy: 0.7663 - val_loss: 0.4505 - val_accuracy: 0.7660\n",
            "Epoch 103/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4509 - accuracy: 0.7655 - val_loss: 0.4504 - val_accuracy: 0.7670\n",
            "Epoch 104/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4508 - accuracy: 0.7665 - val_loss: 0.4504 - val_accuracy: 0.7664\n",
            "Epoch 105/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4508 - accuracy: 0.7664 - val_loss: 0.4502 - val_accuracy: 0.7669\n",
            "Epoch 106/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4506 - accuracy: 0.7664 - val_loss: 0.4502 - val_accuracy: 0.7664\n",
            "Epoch 107/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4505 - accuracy: 0.7669 - val_loss: 0.4503 - val_accuracy: 0.7669\n",
            "Epoch 108/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4505 - accuracy: 0.7665 - val_loss: 0.4500 - val_accuracy: 0.7672\n",
            "Epoch 109/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4504 - accuracy: 0.7669 - val_loss: 0.4499 - val_accuracy: 0.7676\n",
            "Epoch 110/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4503 - accuracy: 0.7668 - val_loss: 0.4498 - val_accuracy: 0.7677\n",
            "Epoch 111/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4503 - accuracy: 0.7673 - val_loss: 0.4497 - val_accuracy: 0.7676\n",
            "Epoch 112/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4501 - accuracy: 0.7672 - val_loss: 0.4497 - val_accuracy: 0.7677\n",
            "Epoch 113/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4501 - accuracy: 0.7672 - val_loss: 0.4496 - val_accuracy: 0.7674\n",
            "Epoch 114/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4499 - accuracy: 0.7675 - val_loss: 0.4496 - val_accuracy: 0.7681\n",
            "Epoch 115/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4499 - accuracy: 0.7673 - val_loss: 0.4494 - val_accuracy: 0.7679\n",
            "Epoch 116/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4498 - accuracy: 0.7674 - val_loss: 0.4495 - val_accuracy: 0.7679\n",
            "Epoch 117/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4498 - accuracy: 0.7680 - val_loss: 0.4493 - val_accuracy: 0.7678\n",
            "Epoch 118/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4497 - accuracy: 0.7681 - val_loss: 0.4492 - val_accuracy: 0.7689\n",
            "Epoch 119/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4496 - accuracy: 0.7684 - val_loss: 0.4491 - val_accuracy: 0.7684\n",
            "Epoch 120/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4496 - accuracy: 0.7678 - val_loss: 0.4491 - val_accuracy: 0.7688\n",
            "Epoch 121/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4495 - accuracy: 0.7678 - val_loss: 0.4490 - val_accuracy: 0.7688\n",
            "Epoch 122/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4494 - accuracy: 0.7683 - val_loss: 0.4490 - val_accuracy: 0.7682\n",
            "Epoch 123/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4494 - accuracy: 0.7687 - val_loss: 0.4489 - val_accuracy: 0.7690\n",
            "Epoch 124/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4493 - accuracy: 0.7684 - val_loss: 0.4488 - val_accuracy: 0.7690\n",
            "Epoch 125/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4492 - accuracy: 0.7685 - val_loss: 0.4488 - val_accuracy: 0.7691\n",
            "Epoch 126/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4491 - accuracy: 0.7676 - val_loss: 0.4492 - val_accuracy: 0.7680\n",
            "Epoch 127/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4492 - accuracy: 0.7685 - val_loss: 0.4486 - val_accuracy: 0.7689\n",
            "Epoch 128/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4491 - accuracy: 0.7685 - val_loss: 0.4486 - val_accuracy: 0.7691\n",
            "Epoch 129/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4490 - accuracy: 0.7684 - val_loss: 0.4485 - val_accuracy: 0.7687\n",
            "Epoch 130/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4490 - accuracy: 0.7685 - val_loss: 0.4485 - val_accuracy: 0.7698\n",
            "Epoch 131/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4489 - accuracy: 0.7692 - val_loss: 0.4484 - val_accuracy: 0.7696\n",
            "Epoch 132/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4488 - accuracy: 0.7683 - val_loss: 0.4484 - val_accuracy: 0.7692\n",
            "Epoch 133/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4488 - accuracy: 0.7686 - val_loss: 0.4483 - val_accuracy: 0.7693\n",
            "Epoch 134/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4488 - accuracy: 0.7682 - val_loss: 0.4482 - val_accuracy: 0.7697\n",
            "Epoch 135/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4487 - accuracy: 0.7691 - val_loss: 0.4482 - val_accuracy: 0.7693\n",
            "Epoch 136/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4487 - accuracy: 0.7688 - val_loss: 0.4481 - val_accuracy: 0.7696\n",
            "Epoch 137/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4486 - accuracy: 0.7687 - val_loss: 0.4481 - val_accuracy: 0.7697\n",
            "Epoch 138/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4485 - accuracy: 0.7692 - val_loss: 0.4482 - val_accuracy: 0.7689\n",
            "Epoch 139/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4485 - accuracy: 0.7680 - val_loss: 0.4480 - val_accuracy: 0.7695\n",
            "Epoch 140/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4485 - accuracy: 0.7690 - val_loss: 0.4480 - val_accuracy: 0.7696\n",
            "Epoch 141/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4485 - accuracy: 0.7686 - val_loss: 0.4479 - val_accuracy: 0.7696\n",
            "Epoch 142/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4484 - accuracy: 0.7693 - val_loss: 0.4479 - val_accuracy: 0.7692\n",
            "Epoch 143/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4483 - accuracy: 0.7690 - val_loss: 0.4479 - val_accuracy: 0.7694\n",
            "Epoch 144/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4483 - accuracy: 0.7691 - val_loss: 0.4478 - val_accuracy: 0.7695\n",
            "Epoch 145/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4482 - accuracy: 0.7689 - val_loss: 0.4478 - val_accuracy: 0.7699\n",
            "Epoch 146/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4482 - accuracy: 0.7693 - val_loss: 0.4477 - val_accuracy: 0.7695\n",
            "Epoch 147/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4482 - accuracy: 0.7690 - val_loss: 0.4476 - val_accuracy: 0.7696\n",
            "Epoch 148/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4481 - accuracy: 0.7695 - val_loss: 0.4476 - val_accuracy: 0.7693\n",
            "Epoch 149/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4481 - accuracy: 0.7694 - val_loss: 0.4476 - val_accuracy: 0.7697\n",
            "Epoch 150/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4480 - accuracy: 0.7689 - val_loss: 0.4475 - val_accuracy: 0.7690\n",
            "Epoch 151/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4480 - accuracy: 0.7690 - val_loss: 0.4475 - val_accuracy: 0.7704\n",
            "Epoch 152/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4479 - accuracy: 0.7694 - val_loss: 0.4475 - val_accuracy: 0.7692\n",
            "Epoch 153/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4479 - accuracy: 0.7696 - val_loss: 0.4474 - val_accuracy: 0.7695\n",
            "Epoch 154/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4479 - accuracy: 0.7689 - val_loss: 0.4474 - val_accuracy: 0.7690\n",
            "Epoch 155/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4478 - accuracy: 0.7694 - val_loss: 0.4473 - val_accuracy: 0.7692\n",
            "Epoch 156/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4477 - accuracy: 0.7702 - val_loss: 0.4473 - val_accuracy: 0.7694\n",
            "Epoch 157/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4477 - accuracy: 0.7689 - val_loss: 0.4472 - val_accuracy: 0.7692\n",
            "Epoch 158/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4477 - accuracy: 0.7691 - val_loss: 0.4472 - val_accuracy: 0.7696\n",
            "Epoch 159/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4476 - accuracy: 0.7695 - val_loss: 0.4471 - val_accuracy: 0.7692\n",
            "Epoch 160/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4476 - accuracy: 0.7692 - val_loss: 0.4472 - val_accuracy: 0.7702\n",
            "Epoch 161/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4476 - accuracy: 0.7692 - val_loss: 0.4470 - val_accuracy: 0.7695\n",
            "Epoch 162/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4475 - accuracy: 0.7693 - val_loss: 0.4471 - val_accuracy: 0.7693\n",
            "Epoch 163/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4474 - accuracy: 0.7692 - val_loss: 0.4471 - val_accuracy: 0.7693\n",
            "Epoch 164/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4475 - accuracy: 0.7690 - val_loss: 0.4470 - val_accuracy: 0.7693\n",
            "Epoch 165/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4474 - accuracy: 0.7693 - val_loss: 0.4469 - val_accuracy: 0.7704\n",
            "Epoch 166/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4474 - accuracy: 0.7695 - val_loss: 0.4468 - val_accuracy: 0.7695\n",
            "Epoch 167/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4474 - accuracy: 0.7690 - val_loss: 0.4468 - val_accuracy: 0.7692\n",
            "Epoch 168/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4473 - accuracy: 0.7690 - val_loss: 0.4468 - val_accuracy: 0.7697\n",
            "Epoch 169/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4472 - accuracy: 0.7693 - val_loss: 0.4469 - val_accuracy: 0.7691\n",
            "Epoch 170/1500\n",
            "1213/1219 [============================>.] - ETA: 0s - loss: 0.4472 - accuracy: 0.7690Epoch 171/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4472 - accuracy: 0.7690 - val_loss: 0.4467 - val_accuracy: 0.7700\n",
            "Epoch 172/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4472 - accuracy: 0.7696 - val_loss: 0.4467 - val_accuracy: 0.7695\n",
            "Epoch 173/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4471 - accuracy: 0.7689 - val_loss: 0.4466 - val_accuracy: 0.7695\n",
            "Epoch 174/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4470 - accuracy: 0.7697 - val_loss: 0.4467 - val_accuracy: 0.7688\n",
            "Epoch 175/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4470 - accuracy: 0.7689 - val_loss: 0.4465 - val_accuracy: 0.7701\n",
            "Epoch 176/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4470 - accuracy: 0.7691 - val_loss: 0.4465 - val_accuracy: 0.7697\n",
            "Epoch 177/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4470 - accuracy: 0.7696 - val_loss: 0.4465 - val_accuracy: 0.7694\n",
            "Epoch 178/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4470 - accuracy: 0.7693 - val_loss: 0.4464 - val_accuracy: 0.7698\n",
            "Epoch 179/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4469 - accuracy: 0.7691 - val_loss: 0.4465 - val_accuracy: 0.7704\n",
            "Epoch 180/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4469 - accuracy: 0.7689 - val_loss: 0.4465 - val_accuracy: 0.7705\n",
            "Epoch 181/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4468 - accuracy: 0.7694 - val_loss: 0.4463 - val_accuracy: 0.7698\n",
            "Epoch 182/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4468 - accuracy: 0.7698 - val_loss: 0.4463 - val_accuracy: 0.7691\n",
            "Epoch 183/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4468 - accuracy: 0.7691 - val_loss: 0.4462 - val_accuracy: 0.7699\n",
            "Epoch 184/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4467 - accuracy: 0.7693 - val_loss: 0.4462 - val_accuracy: 0.7699\n",
            "Epoch 185/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4467 - accuracy: 0.7696 - val_loss: 0.4462 - val_accuracy: 0.7691\n",
            "Epoch 186/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4466 - accuracy: 0.7697 - val_loss: 0.4463 - val_accuracy: 0.7691\n",
            "Epoch 187/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4466 - accuracy: 0.7698 - val_loss: 0.4461 - val_accuracy: 0.7697\n",
            "Epoch 188/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4465 - accuracy: 0.7682 - val_loss: 0.4461 - val_accuracy: 0.7695\n",
            "Epoch 189/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4466 - accuracy: 0.7693 - val_loss: 0.4460 - val_accuracy: 0.7701\n",
            "Epoch 190/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4465 - accuracy: 0.7696 - val_loss: 0.4461 - val_accuracy: 0.7700\n",
            "Epoch 191/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4465 - accuracy: 0.7698 - val_loss: 0.4463 - val_accuracy: 0.7694\n",
            "Epoch 192/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4464 - accuracy: 0.7696 - val_loss: 0.4461 - val_accuracy: 0.7699\n",
            "Epoch 193/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4464 - accuracy: 0.7690 - val_loss: 0.4459 - val_accuracy: 0.7697\n",
            "Epoch 194/1500\n",
            "1219/1219 [==============================] - 9s 7ms/step - loss: 0.4464 - accuracy: 0.7693 - val_loss: 0.4459 - val_accuracy: 0.7696\n",
            "Epoch 195/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4463 - accuracy: 0.7701 - val_loss: 0.4460 - val_accuracy: 0.7706\n",
            "Epoch 196/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4463 - accuracy: 0.7692 - val_loss: 0.4458 - val_accuracy: 0.7700\n",
            "Epoch 197/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4463 - accuracy: 0.7694 - val_loss: 0.4458 - val_accuracy: 0.7703\n",
            "Epoch 198/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4462 - accuracy: 0.7694 - val_loss: 0.4458 - val_accuracy: 0.7705\n",
            "Epoch 199/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4463 - accuracy: 0.7696 - val_loss: 0.4457 - val_accuracy: 0.7702\n",
            "Epoch 200/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4462 - accuracy: 0.7702 - val_loss: 0.4456 - val_accuracy: 0.7700\n",
            "Epoch 201/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4462 - accuracy: 0.7695 - val_loss: 0.4458 - val_accuracy: 0.7704\n",
            "Epoch 202/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4461 - accuracy: 0.7697 - val_loss: 0.4456 - val_accuracy: 0.7699\n",
            "Epoch 203/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4461 - accuracy: 0.7688 - val_loss: 0.4455 - val_accuracy: 0.7697\n",
            "Epoch 204/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4461 - accuracy: 0.7686 - val_loss: 0.4456 - val_accuracy: 0.7705\n",
            "Epoch 205/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4461 - accuracy: 0.7698 - val_loss: 0.4455 - val_accuracy: 0.7695\n",
            "Epoch 206/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4460 - accuracy: 0.7703 - val_loss: 0.4457 - val_accuracy: 0.7699\n",
            "Epoch 207/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4460 - accuracy: 0.7694 - val_loss: 0.4455 - val_accuracy: 0.7708\n",
            "Epoch 208/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4460 - accuracy: 0.7695 - val_loss: 0.4454 - val_accuracy: 0.7696\n",
            "Epoch 209/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4459 - accuracy: 0.7694 - val_loss: 0.4454 - val_accuracy: 0.7701\n",
            "Epoch 210/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4459 - accuracy: 0.7698 - val_loss: 0.4454 - val_accuracy: 0.7704\n",
            "Epoch 211/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4459 - accuracy: 0.7696 - val_loss: 0.4453 - val_accuracy: 0.7702\n",
            "Epoch 212/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4458 - accuracy: 0.7701 - val_loss: 0.4453 - val_accuracy: 0.7703\n",
            "Epoch 213/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4458 - accuracy: 0.7701 - val_loss: 0.4454 - val_accuracy: 0.7704\n",
            "Epoch 214/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4458 - accuracy: 0.7700 - val_loss: 0.4453 - val_accuracy: 0.7706\n",
            "Epoch 215/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4458 - accuracy: 0.7705 - val_loss: 0.4453 - val_accuracy: 0.7704\n",
            "Epoch 216/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4458 - accuracy: 0.7702 - val_loss: 0.4452 - val_accuracy: 0.7701\n",
            "Epoch 217/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4457 - accuracy: 0.7706 - val_loss: 0.4452 - val_accuracy: 0.7712\n",
            "Epoch 218/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4457 - accuracy: 0.7705 - val_loss: 0.4452 - val_accuracy: 0.7704\n",
            "Epoch 219/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4456 - accuracy: 0.7702 - val_loss: 0.4451 - val_accuracy: 0.7703\n",
            "Epoch 220/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4456 - accuracy: 0.7697 - val_loss: 0.4451 - val_accuracy: 0.7710\n",
            "Epoch 221/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4456 - accuracy: 0.7703 - val_loss: 0.4450 - val_accuracy: 0.7704\n",
            "Epoch 222/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4456 - accuracy: 0.7702 - val_loss: 0.4453 - val_accuracy: 0.7710\n",
            "Epoch 223/1500\n",
            "1219/1219 [==============================] - 8s 6ms/step - loss: 0.4455 - accuracy: 0.7703 - val_loss: 0.4450 - val_accuracy: 0.7702\n",
            "Epoch 224/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4455 - accuracy: 0.7702 - val_loss: 0.4451 - val_accuracy: 0.7712\n",
            "Epoch 225/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4455 - accuracy: 0.7709 - val_loss: 0.4449 - val_accuracy: 0.7706\n",
            "Epoch 226/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4455 - accuracy: 0.7703 - val_loss: 0.4449 - val_accuracy: 0.7706\n",
            "Epoch 227/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4455 - accuracy: 0.7709 - val_loss: 0.4451 - val_accuracy: 0.7708\n",
            "Epoch 228/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4454 - accuracy: 0.7700 - val_loss: 0.4451 - val_accuracy: 0.7702\n",
            "Epoch 229/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4454 - accuracy: 0.7705 - val_loss: 0.4448 - val_accuracy: 0.7706\n",
            "Epoch 230/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4453 - accuracy: 0.7702 - val_loss: 0.4448 - val_accuracy: 0.7704\n",
            "Epoch 231/1500\n",
            "1219/1219 [==============================] - 9s 8ms/step - loss: 0.4453 - accuracy: 0.7708 - val_loss: 0.4448 - val_accuracy: 0.7710\n",
            "Epoch 232/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4453 - accuracy: 0.7704 - val_loss: 0.4448 - val_accuracy: 0.7708\n",
            "Epoch 233/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4453 - accuracy: 0.7702 - val_loss: 0.4448 - val_accuracy: 0.7708\n",
            "Epoch 234/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4452 - accuracy: 0.7699 - val_loss: 0.4447 - val_accuracy: 0.7709\n",
            "Epoch 235/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4453 - accuracy: 0.7705 - val_loss: 0.4446 - val_accuracy: 0.7712\n",
            "Epoch 236/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4452 - accuracy: 0.7705 - val_loss: 0.4447 - val_accuracy: 0.7718\n",
            "Epoch 237/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4452 - accuracy: 0.7714 - val_loss: 0.4449 - val_accuracy: 0.7706\n",
            "Epoch 238/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4451 - accuracy: 0.7708 - val_loss: 0.4448 - val_accuracy: 0.7707\n",
            "Epoch 239/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4451 - accuracy: 0.7708 - val_loss: 0.4446 - val_accuracy: 0.7704\n",
            "Epoch 240/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4450 - accuracy: 0.7707 - val_loss: 0.4446 - val_accuracy: 0.7711\n",
            "Epoch 241/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4450 - accuracy: 0.7704 - val_loss: 0.4447 - val_accuracy: 0.7713\n",
            "Epoch 242/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4450 - accuracy: 0.7712 - val_loss: 0.4445 - val_accuracy: 0.7713\n",
            "Epoch 243/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4450 - accuracy: 0.7704 - val_loss: 0.4444 - val_accuracy: 0.7713\n",
            "Epoch 244/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4450 - accuracy: 0.7705 - val_loss: 0.4444 - val_accuracy: 0.7713\n",
            "Epoch 245/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4449 - accuracy: 0.7710 - val_loss: 0.4443 - val_accuracy: 0.7712\n",
            "Epoch 246/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4449 - accuracy: 0.7716 - val_loss: 0.4445 - val_accuracy: 0.7712\n",
            "Epoch 247/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.7714 - val_loss: 0.4444 - val_accuracy: 0.7709\n",
            "Epoch 248/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4449 - accuracy: 0.7708 - val_loss: 0.4445 - val_accuracy: 0.7706\n",
            "Epoch 249/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.7705 - val_loss: 0.4442 - val_accuracy: 0.7718\n",
            "Epoch 250/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4448 - accuracy: 0.7714 - val_loss: 0.4442 - val_accuracy: 0.7713\n",
            "Epoch 251/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.7712 - val_loss: 0.4442 - val_accuracy: 0.7711\n",
            "Epoch 252/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4447 - accuracy: 0.7711 - val_loss: 0.4442 - val_accuracy: 0.7720\n",
            "Epoch 253/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4448 - accuracy: 0.7705 - val_loss: 0.4443 - val_accuracy: 0.7715\n",
            "Epoch 254/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4447 - accuracy: 0.7727 - val_loss: 0.4441 - val_accuracy: 0.7718\n",
            "Epoch 255/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4446 - accuracy: 0.7716 - val_loss: 0.4442 - val_accuracy: 0.7716\n",
            "Epoch 256/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4447 - accuracy: 0.7721 - val_loss: 0.4441 - val_accuracy: 0.7719\n",
            "Epoch 257/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4446 - accuracy: 0.7715 - val_loss: 0.4441 - val_accuracy: 0.7719\n",
            "Epoch 258/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4446 - accuracy: 0.7713 - val_loss: 0.4441 - val_accuracy: 0.7721\n",
            "Epoch 259/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4446 - accuracy: 0.7708 - val_loss: 0.4441 - val_accuracy: 0.7720\n",
            "Epoch 260/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4446 - accuracy: 0.7717 - val_loss: 0.4441 - val_accuracy: 0.7722\n",
            "Epoch 261/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4445 - accuracy: 0.7709 - val_loss: 0.4439 - val_accuracy: 0.7720\n",
            "Epoch 262/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4445 - accuracy: 0.7720 - val_loss: 0.4439 - val_accuracy: 0.7724\n",
            "Epoch 263/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4445 - accuracy: 0.7717 - val_loss: 0.4438 - val_accuracy: 0.7723\n",
            "Epoch 264/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4444 - accuracy: 0.7717 - val_loss: 0.4439 - val_accuracy: 0.7715\n",
            "Epoch 265/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4444 - accuracy: 0.7710 - val_loss: 0.4441 - val_accuracy: 0.7717\n",
            "Epoch 266/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4444 - accuracy: 0.7719 - val_loss: 0.4438 - val_accuracy: 0.7717\n",
            "Epoch 267/1500\n",
            "1219/1219 [==============================] - 9s 7ms/step - loss: 0.4444 - accuracy: 0.7714 - val_loss: 0.4438 - val_accuracy: 0.7721\n",
            "Epoch 268/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4443 - accuracy: 0.7719 - val_loss: 0.4437 - val_accuracy: 0.7724\n",
            "Epoch 269/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4443 - accuracy: 0.7719 - val_loss: 0.4437 - val_accuracy: 0.7723\n",
            "Epoch 270/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4443 - accuracy: 0.7714 - val_loss: 0.4437 - val_accuracy: 0.7721\n",
            "Epoch 271/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4442 - accuracy: 0.7724 - val_loss: 0.4437 - val_accuracy: 0.7716\n",
            "Epoch 272/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4443 - accuracy: 0.7708 - val_loss: 0.4438 - val_accuracy: 0.7719\n",
            "Epoch 273/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4443 - accuracy: 0.7716 - val_loss: 0.4436 - val_accuracy: 0.7722\n",
            "Epoch 274/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4442 - accuracy: 0.7718 - val_loss: 0.4436 - val_accuracy: 0.7724\n",
            "Epoch 275/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4442 - accuracy: 0.7717 - val_loss: 0.4436 - val_accuracy: 0.7723\n",
            "Epoch 276/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4441 - accuracy: 0.7716 - val_loss: 0.4437 - val_accuracy: 0.7720\n",
            "Epoch 277/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4441 - accuracy: 0.7718 - val_loss: 0.4436 - val_accuracy: 0.7729\n",
            "Epoch 278/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4441 - accuracy: 0.7716 - val_loss: 0.4436 - val_accuracy: 0.7722\n",
            "Epoch 279/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4440 - accuracy: 0.7715 - val_loss: 0.4436 - val_accuracy: 0.7726\n",
            "Epoch 280/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4440 - accuracy: 0.7728 - val_loss: 0.4435 - val_accuracy: 0.7721\n",
            "Epoch 281/1500\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4440 - accuracy: 0.7721 - val_loss: 0.4434 - val_accuracy: 0.7724\n",
            "Epoch 282/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4440 - accuracy: 0.7716 - val_loss: 0.4434 - val_accuracy: 0.7716\n",
            "Epoch 283/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4440 - accuracy: 0.7713 - val_loss: 0.4434 - val_accuracy: 0.7732\n",
            "Epoch 284/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4439 - accuracy: 0.7719 - val_loss: 0.4433 - val_accuracy: 0.7728\n",
            "Epoch 285/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4439 - accuracy: 0.7725 - val_loss: 0.4434 - val_accuracy: 0.7723\n",
            "Epoch 286/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4438 - accuracy: 0.7722 - val_loss: 0.4439 - val_accuracy: 0.7717\n",
            "Epoch 287/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4439 - accuracy: 0.7723 - val_loss: 0.4433 - val_accuracy: 0.7728\n",
            "Epoch 288/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4439 - accuracy: 0.7715 - val_loss: 0.4433 - val_accuracy: 0.7730\n",
            "Epoch 289/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4439 - accuracy: 0.7718 - val_loss: 0.4432 - val_accuracy: 0.7731\n",
            "1219/1219 [==============================] - 3s 3ms/step - loss: 0.4438 - accuracy: 0.7725 - val_loss: 0.4433 - val_accuracy: 0.7722\n",
            "Epoch 291/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4438 - accuracy: 0.7715 - val_loss: 0.4432 - val_accuracy: 0.7730\n",
            "Epoch 292/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4437 - accuracy: 0.7720 - val_loss: 0.4433 - val_accuracy: 0.7731\n",
            "Epoch 293/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4438 - accuracy: 0.7720 - val_loss: 0.4432 - val_accuracy: 0.7738\n",
            "Epoch 294/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4437 - accuracy: 0.7717 - val_loss: 0.4431 - val_accuracy: 0.7730\n",
            "Epoch 295/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4437 - accuracy: 0.7722 - val_loss: 0.4431 - val_accuracy: 0.7733\n",
            "Epoch 296/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4437 - accuracy: 0.7724 - val_loss: 0.4432 - val_accuracy: 0.7732\n",
            "Epoch 297/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4436 - accuracy: 0.7729 - val_loss: 0.4431 - val_accuracy: 0.7734\n",
            "Epoch 298/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4437 - accuracy: 0.7723 - val_loss: 0.4430 - val_accuracy: 0.7734\n",
            "Epoch 299/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4436 - accuracy: 0.7728 - val_loss: 0.4433 - val_accuracy: 0.7727\n",
            "Epoch 300/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4436 - accuracy: 0.7729 - val_loss: 0.4430 - val_accuracy: 0.7733\n",
            "Epoch 301/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4436 - accuracy: 0.7731 - val_loss: 0.4430 - val_accuracy: 0.7738\n",
            "Epoch 302/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4436 - accuracy: 0.7733 - val_loss: 0.4432 - val_accuracy: 0.7736\n",
            "Epoch 303/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4435 - accuracy: 0.7725 - val_loss: 0.4432 - val_accuracy: 0.7731\n",
            "Epoch 304/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4435 - accuracy: 0.7727 - val_loss: 0.4434 - val_accuracy: 0.7730\n",
            "Epoch 305/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4435 - accuracy: 0.7734 - val_loss: 0.4429 - val_accuracy: 0.7738\n",
            "Epoch 306/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4435 - accuracy: 0.7728 - val_loss: 0.4429 - val_accuracy: 0.7728\n",
            "Epoch 307/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4435 - accuracy: 0.7727 - val_loss: 0.4429 - val_accuracy: 0.7737\n",
            "Epoch 308/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4435 - accuracy: 0.7732 - val_loss: 0.4428 - val_accuracy: 0.7730\n",
            "Epoch 309/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4434 - accuracy: 0.7727 - val_loss: 0.4428 - val_accuracy: 0.7735\n",
            "Epoch 310/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4434 - accuracy: 0.7733 - val_loss: 0.4428 - val_accuracy: 0.7738\n",
            "Epoch 311/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4434 - accuracy: 0.7729 - val_loss: 0.4428 - val_accuracy: 0.7739\n",
            "Epoch 312/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4433 - accuracy: 0.7728 - val_loss: 0.4428 - val_accuracy: 0.7732\n",
            "Epoch 313/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4433 - accuracy: 0.7734 - val_loss: 0.4427 - val_accuracy: 0.7729\n",
            "Epoch 314/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4433 - accuracy: 0.7725 - val_loss: 0.4427 - val_accuracy: 0.7731\n",
            "Epoch 315/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4432 - accuracy: 0.7730 - val_loss: 0.4426 - val_accuracy: 0.7734\n",
            "Epoch 316/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4432 - accuracy: 0.7731 - val_loss: 0.4426 - val_accuracy: 0.7732\n",
            "Epoch 317/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4432 - accuracy: 0.7731 - val_loss: 0.4428 - val_accuracy: 0.7723\n",
            "Epoch 318/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4432 - accuracy: 0.7730 - val_loss: 0.4426 - val_accuracy: 0.7739\n",
            "Epoch 319/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4431 - accuracy: 0.7721 - val_loss: 0.4427 - val_accuracy: 0.7737\n",
            "Epoch 320/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4432 - accuracy: 0.7722 - val_loss: 0.4427 - val_accuracy: 0.7734\n",
            "Epoch 321/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4431 - accuracy: 0.7725 - val_loss: 0.4427 - val_accuracy: 0.7736\n",
            "Epoch 322/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4431 - accuracy: 0.7732 - val_loss: 0.4428 - val_accuracy: 0.7719\n",
            "Epoch 323/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4431 - accuracy: 0.7731 - val_loss: 0.4425 - val_accuracy: 0.7741\n",
            "Epoch 324/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4432 - accuracy: 0.7730 - val_loss: 0.4424 - val_accuracy: 0.7739\n",
            "Epoch 325/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4431 - accuracy: 0.7732 - val_loss: 0.4425 - val_accuracy: 0.7732\n",
            "Epoch 326/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4430 - accuracy: 0.7732 - val_loss: 0.4425 - val_accuracy: 0.7734\n",
            "Epoch 327/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4431 - accuracy: 0.7727 - val_loss: 0.4425 - val_accuracy: 0.7740\n",
            "Epoch 328/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4430 - accuracy: 0.7731 - val_loss: 0.4425 - val_accuracy: 0.7723\n",
            "Epoch 329/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4430 - accuracy: 0.7730 - val_loss: 0.4424 - val_accuracy: 0.7739\n",
            "Epoch 330/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7724 - val_loss: 0.4425 - val_accuracy: 0.7724\n",
            "Epoch 331/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7733 - val_loss: 0.4424 - val_accuracy: 0.7737\n",
            "Epoch 332/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4430 - accuracy: 0.7736 - val_loss: 0.4423 - val_accuracy: 0.7734\n",
            "Epoch 333/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7730 - val_loss: 0.4423 - val_accuracy: 0.7742\n",
            "Epoch 334/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7736 - val_loss: 0.4423 - val_accuracy: 0.7737\n",
            "Epoch 335/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7733 - val_loss: 0.4422 - val_accuracy: 0.7738\n",
            "Epoch 336/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4429 - accuracy: 0.7731 - val_loss: 0.4422 - val_accuracy: 0.7745\n",
            "Epoch 337/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4429 - accuracy: 0.7729 - val_loss: 0.4423 - val_accuracy: 0.7724\n",
            "Epoch 338/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4428 - accuracy: 0.7727 - val_loss: 0.4422 - val_accuracy: 0.7744\n",
            "Epoch 339/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4428 - accuracy: 0.7730 - val_loss: 0.4422 - val_accuracy: 0.7741\n",
            "Epoch 340/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4427 - accuracy: 0.7742 - val_loss: 0.4425 - val_accuracy: 0.7719\n",
            "Epoch 341/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4428 - accuracy: 0.7729 - val_loss: 0.4422 - val_accuracy: 0.7737\n",
            "Epoch 342/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4427 - accuracy: 0.7731 - val_loss: 0.4423 - val_accuracy: 0.7729\n",
            "Epoch 343/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4428 - accuracy: 0.7732 - val_loss: 0.4422 - val_accuracy: 0.7732\n",
            "Epoch 344/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4427 - accuracy: 0.7736 - val_loss: 0.4421 - val_accuracy: 0.7739\n",
            "Epoch 345/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4427 - accuracy: 0.7730 - val_loss: 0.4420 - val_accuracy: 0.7740\n",
            "Epoch 346/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7735 - val_loss: 0.4421 - val_accuracy: 0.7734\n",
            "Epoch 347/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7728 - val_loss: 0.4421 - val_accuracy: 0.7731\n",
            "Epoch 348/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7733 - val_loss: 0.4421 - val_accuracy: 0.7740\n",
            "Epoch 349/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4426 - accuracy: 0.7723 - val_loss: 0.4420 - val_accuracy: 0.7738\n",
            "Epoch 350/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7732 - val_loss: 0.4422 - val_accuracy: 0.7731\n",
            "Epoch 351/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7734 - val_loss: 0.4421 - val_accuracy: 0.7721\n",
            "Epoch 352/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4426 - accuracy: 0.7727 - val_loss: 0.4419 - val_accuracy: 0.7744\n",
            "Epoch 353/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.7723 - val_loss: 0.4420 - val_accuracy: 0.7731\n",
            "Epoch 354/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4426 - accuracy: 0.7738 - val_loss: 0.4419 - val_accuracy: 0.7740\n",
            "Epoch 355/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.7729 - val_loss: 0.4419 - val_accuracy: 0.7739\n",
            "Epoch 356/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.7730 - val_loss: 0.4418 - val_accuracy: 0.7738\n",
            "Epoch 357/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4424 - accuracy: 0.7729 - val_loss: 0.4420 - val_accuracy: 0.7734\n",
            "Epoch 358/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.7736 - val_loss: 0.4418 - val_accuracy: 0.7740\n",
            "Epoch 359/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4425 - accuracy: 0.7730 - val_loss: 0.4418 - val_accuracy: 0.7733\n",
            "Epoch 360/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4424 - accuracy: 0.7736 - val_loss: 0.4419 - val_accuracy: 0.7731\n",
            "Epoch 361/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.7729 - val_loss: 0.4417 - val_accuracy: 0.7739\n",
            "Epoch 362/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4424 - accuracy: 0.7733 - val_loss: 0.4418 - val_accuracy: 0.7736\n",
            "Epoch 363/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.7723 - val_loss: 0.4417 - val_accuracy: 0.7744\n",
            "Epoch 364/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.7736 - val_loss: 0.4417 - val_accuracy: 0.7737\n",
            "Epoch 365/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4423 - accuracy: 0.7737 - val_loss: 0.4417 - val_accuracy: 0.7732\n",
            "Epoch 366/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4423 - accuracy: 0.7730 - val_loss: 0.4416 - val_accuracy: 0.7742\n",
            "Epoch 367/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4423 - accuracy: 0.7725 - val_loss: 0.4418 - val_accuracy: 0.7729\n",
            "Epoch 368/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4422 - accuracy: 0.7722 - val_loss: 0.4418 - val_accuracy: 0.7738\n",
            "Epoch 369/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4423 - accuracy: 0.7728 - val_loss: 0.4416 - val_accuracy: 0.7740\n",
            "Epoch 370/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4423 - accuracy: 0.7733 - val_loss: 0.4416 - val_accuracy: 0.7739\n",
            "Epoch 371/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.4416 - val_accuracy: 0.7743\n",
            "Epoch 372/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4422 - accuracy: 0.7733 - val_loss: 0.4416 - val_accuracy: 0.7735\n",
            "Epoch 373/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4423 - accuracy: 0.7737 - val_loss: 0.4415 - val_accuracy: 0.7742\n",
            "Epoch 374/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4422 - accuracy: 0.7731 - val_loss: 0.4415 - val_accuracy: 0.7739\n",
            "Epoch 375/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4422 - accuracy: 0.7730 - val_loss: 0.4416 - val_accuracy: 0.7732\n",
            "Epoch 376/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4421 - accuracy: 0.7730 - val_loss: 0.4416 - val_accuracy: 0.7738\n",
            "Epoch 377/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4422 - accuracy: 0.7738 - val_loss: 0.4415 - val_accuracy: 0.7740\n",
            "Epoch 378/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4421 - accuracy: 0.7731 - val_loss: 0.4415 - val_accuracy: 0.7731\n",
            "Epoch 379/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4422 - accuracy: 0.7733 - val_loss: 0.4415 - val_accuracy: 0.7739\n",
            "Epoch 380/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4422 - accuracy: 0.7736 - val_loss: 0.4414 - val_accuracy: 0.7742\n",
            "Epoch 381/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4421 - accuracy: 0.7734 - val_loss: 0.4414 - val_accuracy: 0.7743\n",
            "Epoch 382/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4421 - accuracy: 0.7743 - val_loss: 0.4414 - val_accuracy: 0.7744\n",
            "Epoch 383/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4421 - accuracy: 0.7729 - val_loss: 0.4416 - val_accuracy: 0.7733\n",
            "Epoch 384/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4421 - accuracy: 0.7732 - val_loss: 0.4414 - val_accuracy: 0.7741\n",
            "Epoch 385/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.7739 - val_loss: 0.4413 - val_accuracy: 0.7740\n",
            "Epoch 386/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4419 - accuracy: 0.7730 - val_loss: 0.4416 - val_accuracy: 0.7733\n",
            "Epoch 387/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4420 - accuracy: 0.7734 - val_loss: 0.4413 - val_accuracy: 0.7745\n",
            "Epoch 388/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4420 - accuracy: 0.7734 - val_loss: 0.4413 - val_accuracy: 0.7742\n",
            "Epoch 389/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4419 - accuracy: 0.7741 - val_loss: 0.4416 - val_accuracy: 0.7735\n",
            "Epoch 390/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4420 - accuracy: 0.7731 - val_loss: 0.4412 - val_accuracy: 0.7740\n",
            "Epoch 391/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4419 - accuracy: 0.7734 - val_loss: 0.4413 - val_accuracy: 0.7745\n",
            "Epoch 392/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4419 - accuracy: 0.7736 - val_loss: 0.4412 - val_accuracy: 0.7746\n",
            "Epoch 393/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4418 - accuracy: 0.7734 - val_loss: 0.4414 - val_accuracy: 0.7742\n",
            "Epoch 394/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4418 - accuracy: 0.7742 - val_loss: 0.4414 - val_accuracy: 0.7733\n",
            "Epoch 395/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4419 - accuracy: 0.7732 - val_loss: 0.4412 - val_accuracy: 0.7742\n",
            "Epoch 396/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4418 - accuracy: 0.7747 - val_loss: 0.4412 - val_accuracy: 0.7742\n",
            "Epoch 397/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4419 - accuracy: 0.7740 - val_loss: 0.4411 - val_accuracy: 0.7742\n",
            "Epoch 398/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4419 - accuracy: 0.7741 - val_loss: 0.4411 - val_accuracy: 0.7742\n",
            "Epoch 399/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4418 - accuracy: 0.7730 - val_loss: 0.4411 - val_accuracy: 0.7745\n",
            "Epoch 400/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4417 - accuracy: 0.7738 - val_loss: 0.4412 - val_accuracy: 0.7742\n",
            "Epoch 401/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4418 - accuracy: 0.7736 - val_loss: 0.4412 - val_accuracy: 0.7744\n",
            "Epoch 402/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4418 - accuracy: 0.7737 - val_loss: 0.4411 - val_accuracy: 0.7740\n",
            "Epoch 403/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.7739 - val_loss: 0.4411 - val_accuracy: 0.7741\n",
            "Epoch 404/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4417 - accuracy: 0.7739 - val_loss: 0.4410 - val_accuracy: 0.7743\n",
            "Epoch 405/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4417 - accuracy: 0.7735 - val_loss: 0.4411 - val_accuracy: 0.7739\n",
            "Epoch 406/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.7737 - val_loss: 0.4410 - val_accuracy: 0.7739\n",
            "Epoch 407/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.7729 - val_loss: 0.4409 - val_accuracy: 0.7748\n",
            "Epoch 408/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.7739 - val_loss: 0.4409 - val_accuracy: 0.7747\n",
            "Epoch 409/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4416 - accuracy: 0.7742 - val_loss: 0.4409 - val_accuracy: 0.7745\n",
            "Epoch 410/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4415 - accuracy: 0.7739 - val_loss: 0.4413 - val_accuracy: 0.7738\n",
            "Epoch 411/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4416 - accuracy: 0.7741 - val_loss: 0.4409 - val_accuracy: 0.7745\n",
            "Epoch 412/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4415 - accuracy: 0.7737 - val_loss: 0.4409 - val_accuracy: 0.7742\n",
            "Epoch 413/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4415 - accuracy: 0.7744 - val_loss: 0.4409 - val_accuracy: 0.7742\n",
            "Epoch 414/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4415 - accuracy: 0.7743 - val_loss: 0.4410 - val_accuracy: 0.7748\n",
            "Epoch 415/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4415 - accuracy: 0.7737 - val_loss: 0.4409 - val_accuracy: 0.7737\n",
            "Epoch 416/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4415 - accuracy: 0.7740 - val_loss: 0.4410 - val_accuracy: 0.7742\n",
            "Epoch 417/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4415 - accuracy: 0.7734 - val_loss: 0.4409 - val_accuracy: 0.7743\n",
            "Epoch 418/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4414 - accuracy: 0.7743 - val_loss: 0.4407 - val_accuracy: 0.7745\n",
            "Epoch 419/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4413 - accuracy: 0.7735 - val_loss: 0.4408 - val_accuracy: 0.7746\n",
            "Epoch 420/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4414 - accuracy: 0.7728 - val_loss: 0.4408 - val_accuracy: 0.7753\n",
            "Epoch 421/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4414 - accuracy: 0.7737 - val_loss: 0.4407 - val_accuracy: 0.7745\n",
            "Epoch 422/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4414 - accuracy: 0.7741 - val_loss: 0.4407 - val_accuracy: 0.7752\n",
            "Epoch 423/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4414 - accuracy: 0.7740 - val_loss: 0.4407 - val_accuracy: 0.7749\n",
            "Epoch 424/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4413 - accuracy: 0.7745 - val_loss: 0.4406 - val_accuracy: 0.7751\n",
            "Epoch 425/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4414 - accuracy: 0.7743 - val_loss: 0.4406 - val_accuracy: 0.7751\n",
            "Epoch 426/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.7739 - val_loss: 0.4406 - val_accuracy: 0.7754\n",
            "Epoch 427/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.7744 - val_loss: 0.4407 - val_accuracy: 0.7745\n",
            "Epoch 428/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4413 - accuracy: 0.7744 - val_loss: 0.4406 - val_accuracy: 0.7747\n",
            "Epoch 429/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4413 - accuracy: 0.7743 - val_loss: 0.4405 - val_accuracy: 0.7750\n",
            "Epoch 430/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4412 - accuracy: 0.7740 - val_loss: 0.4406 - val_accuracy: 0.7747\n",
            "Epoch 431/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.7750 - val_loss: 0.4405 - val_accuracy: 0.7740\n",
            "Epoch 432/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4411 - accuracy: 0.7734 - val_loss: 0.4405 - val_accuracy: 0.7747\n",
            "Epoch 433/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4412 - accuracy: 0.7749 - val_loss: 0.4405 - val_accuracy: 0.7749\n",
            "Epoch 434/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4410 - accuracy: 0.7749 - val_loss: 0.4407 - val_accuracy: 0.7743\n",
            "Epoch 435/1500\n",
            "1219/1219 [==============================] - 8s 7ms/step - loss: 0.4411 - accuracy: 0.7746 - val_loss: 0.4405 - val_accuracy: 0.7745\n",
            "Epoch 436/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.7735 - val_loss: 0.4404 - val_accuracy: 0.7754\n",
            "Epoch 437/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4411 - accuracy: 0.7740 - val_loss: 0.4404 - val_accuracy: 0.7754\n",
            "Epoch 438/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4410 - accuracy: 0.7737 - val_loss: 0.4404 - val_accuracy: 0.7753\n",
            "Epoch 439/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.4406 - val_accuracy: 0.7745\n",
            "Epoch 440/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4411 - accuracy: 0.7737 - val_loss: 0.4404 - val_accuracy: 0.7746\n",
            "Epoch 441/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4410 - accuracy: 0.7742 - val_loss: 0.4405 - val_accuracy: 0.7738\n",
            "Epoch 442/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4411 - accuracy: 0.7742 - val_loss: 0.4403 - val_accuracy: 0.7759\n",
            "Epoch 443/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4409 - accuracy: 0.7747 - val_loss: 0.4406 - val_accuracy: 0.7751\n",
            "Epoch 444/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4410 - accuracy: 0.7751 - val_loss: 0.4403 - val_accuracy: 0.7754\n",
            "Epoch 445/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4410 - accuracy: 0.7741 - val_loss: 0.4403 - val_accuracy: 0.7756\n",
            "Epoch 446/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4410 - accuracy: 0.7745 - val_loss: 0.4404 - val_accuracy: 0.7754\n",
            "Epoch 447/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4409 - accuracy: 0.7744 - val_loss: 0.4404 - val_accuracy: 0.7758\n",
            "Epoch 448/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4410 - accuracy: 0.7743 - val_loss: 0.4403 - val_accuracy: 0.7753\n",
            "Epoch 449/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4410 - accuracy: 0.7742 - val_loss: 0.4402 - val_accuracy: 0.7754\n",
            "Epoch 450/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4409 - accuracy: 0.7748 - val_loss: 0.4404 - val_accuracy: 0.7749\n",
            "Epoch 451/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4409 - accuracy: 0.7747 - val_loss: 0.4402 - val_accuracy: 0.7752\n",
            "Epoch 452/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4403 - val_accuracy: 0.7739\n",
            "Epoch 453/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7742 - val_loss: 0.4402 - val_accuracy: 0.7752\n",
            "Epoch 454/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7742 - val_loss: 0.4403 - val_accuracy: 0.7748\n",
            "Epoch 455/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7746 - val_loss: 0.4401 - val_accuracy: 0.7756\n",
            "Epoch 456/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4408 - accuracy: 0.7744 - val_loss: 0.4401 - val_accuracy: 0.7754\n",
            "Epoch 457/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7748 - val_loss: 0.4402 - val_accuracy: 0.7739\n",
            "Epoch 458/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4407 - accuracy: 0.7746 - val_loss: 0.4401 - val_accuracy: 0.7760\n",
            "Epoch 459/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4401 - val_accuracy: 0.7756\n",
            "Epoch 460/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7742 - val_loss: 0.4401 - val_accuracy: 0.7757\n",
            "Epoch 461/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4401 - val_accuracy: 0.7756\n",
            "Epoch 462/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4401 - val_accuracy: 0.7745\n",
            "Epoch 463/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4407 - accuracy: 0.7743 - val_loss: 0.4400 - val_accuracy: 0.7750\n",
            "Epoch 464/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4407 - accuracy: 0.7750 - val_loss: 0.4400 - val_accuracy: 0.7757\n",
            "Epoch 465/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4407 - accuracy: 0.7752 - val_loss: 0.4400 - val_accuracy: 0.7754\n",
            "Epoch 466/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4407 - accuracy: 0.7749 - val_loss: 0.4399 - val_accuracy: 0.7757\n",
            "Epoch 467/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4407 - accuracy: 0.7749 - val_loss: 0.4400 - val_accuracy: 0.7760\n",
            "Epoch 468/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4406 - accuracy: 0.7744 - val_loss: 0.4401 - val_accuracy: 0.7742\n",
            "Epoch 469/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4406 - accuracy: 0.7752 - val_loss: 0.4400 - val_accuracy: 0.7758\n",
            "Epoch 470/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4406 - accuracy: 0.7745 - val_loss: 0.4401 - val_accuracy: 0.7755\n",
            "Epoch 471/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4407 - accuracy: 0.7752 - val_loss: 0.4399 - val_accuracy: 0.7754\n",
            "Epoch 472/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4406 - accuracy: 0.7741 - val_loss: 0.4399 - val_accuracy: 0.7753\n",
            "Epoch 473/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4406 - accuracy: 0.7745 - val_loss: 0.4399 - val_accuracy: 0.7757\n",
            "Epoch 474/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4405 - accuracy: 0.7753 - val_loss: 0.4398 - val_accuracy: 0.7758\n",
            "Epoch 475/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4406 - accuracy: 0.7754 - val_loss: 0.4398 - val_accuracy: 0.7759\n",
            "Epoch 476/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4405 - accuracy: 0.7756 - val_loss: 0.4398 - val_accuracy: 0.7756\n",
            "Epoch 477/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4405 - accuracy: 0.7749 - val_loss: 0.4398 - val_accuracy: 0.7752\n",
            "Epoch 478/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4405 - accuracy: 0.7752 - val_loss: 0.4401 - val_accuracy: 0.7747\n",
            "Epoch 479/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4405 - accuracy: 0.7744 - val_loss: 0.4398 - val_accuracy: 0.7755\n",
            "Epoch 480/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4405 - accuracy: 0.7750 - val_loss: 0.4398 - val_accuracy: 0.7760\n",
            "Epoch 481/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4405 - accuracy: 0.7744 - val_loss: 0.4398 - val_accuracy: 0.7759\n",
            "Epoch 482/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7748 - val_loss: 0.4398 - val_accuracy: 0.7755\n",
            "Epoch 483/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7753 - val_loss: 0.4399 - val_accuracy: 0.7759\n",
            "Epoch 484/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4404 - accuracy: 0.7755 - val_loss: 0.4401 - val_accuracy: 0.7745\n",
            "Epoch 485/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4404 - accuracy: 0.7755 - val_loss: 0.4397 - val_accuracy: 0.7752\n",
            "Epoch 486/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7744 - val_loss: 0.4397 - val_accuracy: 0.7763\n",
            "Epoch 487/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4404 - accuracy: 0.7759 - val_loss: 0.4396 - val_accuracy: 0.7754\n",
            "Epoch 488/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7751 - val_loss: 0.4396 - val_accuracy: 0.7761\n",
            "Epoch 489/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7759 - val_loss: 0.4397 - val_accuracy: 0.7766\n",
            "Epoch 490/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4403 - accuracy: 0.7752 - val_loss: 0.4397 - val_accuracy: 0.7756\n",
            "Epoch 491/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4402 - accuracy: 0.7758 - val_loss: 0.4400 - val_accuracy: 0.7751\n",
            "Epoch 492/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4404 - accuracy: 0.7752 - val_loss: 0.4396 - val_accuracy: 0.7753\n",
            "Epoch 493/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4396 - val_accuracy: 0.7764\n",
            "Epoch 494/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4403 - accuracy: 0.7757 - val_loss: 0.4396 - val_accuracy: 0.7753\n",
            "Epoch 495/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4402 - accuracy: 0.7750 - val_loss: 0.4398 - val_accuracy: 0.7754\n",
            "Epoch 496/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4403 - accuracy: 0.7756 - val_loss: 0.4396 - val_accuracy: 0.7755\n",
            "Epoch 497/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4403 - accuracy: 0.7747 - val_loss: 0.4396 - val_accuracy: 0.7761\n",
            "Epoch 498/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4402 - accuracy: 0.7748 - val_loss: 0.4396 - val_accuracy: 0.7760\n",
            "Epoch 499/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4401 - accuracy: 0.7752 - val_loss: 0.4399 - val_accuracy: 0.7747\n",
            "Epoch 500/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4401 - accuracy: 0.7748 - val_loss: 0.4395 - val_accuracy: 0.7762\n",
            "Epoch 501/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4402 - accuracy: 0.7745 - val_loss: 0.4396 - val_accuracy: 0.7754\n",
            "Epoch 502/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4401 - accuracy: 0.7753 - val_loss: 0.4396 - val_accuracy: 0.7758\n",
            "Epoch 503/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4402 - accuracy: 0.7755 - val_loss: 0.4394 - val_accuracy: 0.7765\n",
            "Epoch 504/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4402 - accuracy: 0.7749 - val_loss: 0.4394 - val_accuracy: 0.7752\n",
            "Epoch 505/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4401 - accuracy: 0.7750 - val_loss: 0.4396 - val_accuracy: 0.7756\n",
            "Epoch 506/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4401 - accuracy: 0.7750 - val_loss: 0.4395 - val_accuracy: 0.7761\n",
            "Epoch 507/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4401 - accuracy: 0.7752 - val_loss: 0.4396 - val_accuracy: 0.7740\n",
            "Epoch 508/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4402 - accuracy: 0.7752 - val_loss: 0.4394 - val_accuracy: 0.7764\n",
            "Epoch 509/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4401 - accuracy: 0.7751 - val_loss: 0.4394 - val_accuracy: 0.7755\n",
            "Epoch 510/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7750 - val_loss: 0.4395 - val_accuracy: 0.7758\n",
            "Epoch 511/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7747 - val_loss: 0.4396 - val_accuracy: 0.7755\n",
            "Epoch 512/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4402 - accuracy: 0.7753 - val_loss: 0.4393 - val_accuracy: 0.7764\n",
            "Epoch 513/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7747 - val_loss: 0.4394 - val_accuracy: 0.7754\n",
            "Epoch 514/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7755 - val_loss: 0.4394 - val_accuracy: 0.7764\n",
            "Epoch 515/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4401 - accuracy: 0.7748 - val_loss: 0.4393 - val_accuracy: 0.7754\n",
            "Epoch 516/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7751 - val_loss: 0.4393 - val_accuracy: 0.7752\n",
            "Epoch 517/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4399 - accuracy: 0.7749 - val_loss: 0.4395 - val_accuracy: 0.7761\n",
            "Epoch 518/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4401 - accuracy: 0.7745 - val_loss: 0.4392 - val_accuracy: 0.7760\n",
            "Epoch 519/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7749 - val_loss: 0.4395 - val_accuracy: 0.7759\n",
            "Epoch 520/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4400 - accuracy: 0.7757 - val_loss: 0.4392 - val_accuracy: 0.7753\n",
            "Epoch 521/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4400 - accuracy: 0.7749 - val_loss: 0.4392 - val_accuracy: 0.7750\n",
            "Epoch 522/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7747 - val_loss: 0.4393 - val_accuracy: 0.7758\n",
            "Epoch 523/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7754 - val_loss: 0.4393 - val_accuracy: 0.7750\n",
            "Epoch 524/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4399 - accuracy: 0.7751 - val_loss: 0.4394 - val_accuracy: 0.7754\n",
            "Epoch 525/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4400 - accuracy: 0.7748 - val_loss: 0.4392 - val_accuracy: 0.7754\n",
            "Epoch 526/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7752 - val_loss: 0.4393 - val_accuracy: 0.7750\n",
            "Epoch 527/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4399 - accuracy: 0.7757 - val_loss: 0.4391 - val_accuracy: 0.7757\n",
            "Epoch 528/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4395 - val_accuracy: 0.7764\n",
            "Epoch 529/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4400 - accuracy: 0.7752 - val_loss: 0.4392 - val_accuracy: 0.7752\n",
            "Epoch 530/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7752 - val_loss: 0.4391 - val_accuracy: 0.7757\n",
            "Epoch 531/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4391 - val_accuracy: 0.7762\n",
            "Epoch 532/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7749 - val_loss: 0.4393 - val_accuracy: 0.7758\n",
            "Epoch 533/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7748 - val_loss: 0.4392 - val_accuracy: 0.7755\n",
            "Epoch 534/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4398 - accuracy: 0.7755 - val_loss: 0.4393 - val_accuracy: 0.7761\n",
            "Epoch 535/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4398 - accuracy: 0.7751 - val_loss: 0.4394 - val_accuracy: 0.7758\n",
            "Epoch 536/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4398 - accuracy: 0.7745 - val_loss: 0.4393 - val_accuracy: 0.7759\n",
            "Epoch 537/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4398 - accuracy: 0.7746 - val_loss: 0.4392 - val_accuracy: 0.7762\n",
            "Epoch 538/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4398 - accuracy: 0.7753 - val_loss: 0.4391 - val_accuracy: 0.7758\n",
            "Epoch 539/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4398 - accuracy: 0.7753 - val_loss: 0.4390 - val_accuracy: 0.7756\n",
            "Epoch 540/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4398 - accuracy: 0.7754 - val_loss: 0.4390 - val_accuracy: 0.7755\n",
            "Epoch 541/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4397 - accuracy: 0.7753 - val_loss: 0.4390 - val_accuracy: 0.7761\n",
            "Epoch 542/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4398 - accuracy: 0.7747 - val_loss: 0.4390 - val_accuracy: 0.7759\n",
            "Epoch 543/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4397 - accuracy: 0.7748 - val_loss: 0.4391 - val_accuracy: 0.7761\n",
            "Epoch 544/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4397 - accuracy: 0.7747 - val_loss: 0.4390 - val_accuracy: 0.7761\n",
            "Epoch 545/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4397 - accuracy: 0.7750 - val_loss: 0.4389 - val_accuracy: 0.7760\n",
            "Epoch 546/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4397 - accuracy: 0.7753 - val_loss: 0.4389 - val_accuracy: 0.7761\n",
            "Epoch 547/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4397 - accuracy: 0.7754 - val_loss: 0.4389 - val_accuracy: 0.7758\n",
            "Epoch 548/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4396 - accuracy: 0.7744 - val_loss: 0.4390 - val_accuracy: 0.7758\n",
            "Epoch 549/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4397 - accuracy: 0.7752 - val_loss: 0.4390 - val_accuracy: 0.7761\n",
            "Epoch 550/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4396 - accuracy: 0.7756 - val_loss: 0.4390 - val_accuracy: 0.7765\n",
            "Epoch 551/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4396 - accuracy: 0.7751 - val_loss: 0.4389 - val_accuracy: 0.7762\n",
            "Epoch 552/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7752 - val_loss: 0.4390 - val_accuracy: 0.7748\n",
            "Epoch 553/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4396 - accuracy: 0.7756 - val_loss: 0.4391 - val_accuracy: 0.7768\n",
            "Epoch 554/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4396 - accuracy: 0.7749 - val_loss: 0.4388 - val_accuracy: 0.7755\n",
            "Epoch 555/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7753 - val_loss: 0.4389 - val_accuracy: 0.7755\n",
            "Epoch 556/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7757 - val_loss: 0.4388 - val_accuracy: 0.7762\n",
            "Epoch 557/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7753 - val_loss: 0.4389 - val_accuracy: 0.7760\n",
            "Epoch 558/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7761 - val_loss: 0.4389 - val_accuracy: 0.7758\n",
            "Epoch 559/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7744 - val_loss: 0.4389 - val_accuracy: 0.7759\n",
            "Epoch 560/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.4388 - val_accuracy: 0.7762\n",
            "Epoch 561/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4395 - accuracy: 0.7752 - val_loss: 0.4388 - val_accuracy: 0.7759\n",
            "Epoch 562/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7760 - val_loss: 0.4392 - val_accuracy: 0.7754\n",
            "Epoch 563/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7749 - val_loss: 0.4389 - val_accuracy: 0.7755\n",
            "Epoch 564/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4396 - accuracy: 0.7755 - val_loss: 0.4387 - val_accuracy: 0.7763\n",
            "Epoch 565/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7757 - val_loss: 0.4388 - val_accuracy: 0.7753\n",
            "Epoch 566/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7752 - val_loss: 0.4388 - val_accuracy: 0.7762\n",
            "Epoch 567/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7747 - val_loss: 0.4387 - val_accuracy: 0.7763\n",
            "Epoch 568/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4395 - accuracy: 0.7762 - val_loss: 0.4388 - val_accuracy: 0.7765\n",
            "Epoch 569/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7745 - val_loss: 0.4387 - val_accuracy: 0.7756\n",
            "Epoch 570/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4395 - accuracy: 0.7757 - val_loss: 0.4389 - val_accuracy: 0.7761\n",
            "Epoch 571/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4395 - accuracy: 0.7754 - val_loss: 0.4387 - val_accuracy: 0.7756\n",
            "Epoch 572/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7750 - val_loss: 0.4389 - val_accuracy: 0.7748\n",
            "Epoch 573/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4394 - accuracy: 0.7753 - val_loss: 0.4389 - val_accuracy: 0.7757\n",
            "Epoch 574/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4394 - accuracy: 0.7753 - val_loss: 0.4387 - val_accuracy: 0.7762\n",
            "Epoch 575/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4394 - accuracy: 0.7753 - val_loss: 0.4388 - val_accuracy: 0.7760\n",
            "Epoch 576/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4394 - accuracy: 0.7752 - val_loss: 0.4388 - val_accuracy: 0.7759\n",
            "Epoch 577/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4394 - accuracy: 0.7750 - val_loss: 0.4388 - val_accuracy: 0.7758\n",
            "Epoch 578/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7755 - val_loss: 0.4392 - val_accuracy: 0.7752\n",
            "Epoch 579/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4394 - accuracy: 0.7754 - val_loss: 0.4388 - val_accuracy: 0.7759\n",
            "Epoch 580/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4395 - accuracy: 0.7752 - val_loss: 0.4386 - val_accuracy: 0.7758\n",
            "Epoch 581/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4394 - accuracy: 0.7751 - val_loss: 0.4386 - val_accuracy: 0.7762\n",
            "Epoch 582/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7744 - val_loss: 0.4387 - val_accuracy: 0.7757\n",
            "Epoch 583/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4394 - accuracy: 0.7753 - val_loss: 0.4386 - val_accuracy: 0.7761\n",
            "Epoch 584/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4393 - accuracy: 0.7759 - val_loss: 0.4386 - val_accuracy: 0.7762\n",
            "Epoch 585/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4394 - accuracy: 0.7755 - val_loss: 0.4387 - val_accuracy: 0.7760\n",
            "Epoch 586/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7750 - val_loss: 0.4386 - val_accuracy: 0.7757\n",
            "Epoch 587/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4392 - accuracy: 0.7759 - val_loss: 0.4386 - val_accuracy: 0.7759\n",
            "Epoch 588/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7751 - val_loss: 0.4386 - val_accuracy: 0.7760\n",
            "Epoch 589/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7755 - val_loss: 0.4385 - val_accuracy: 0.7758\n",
            "Epoch 590/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7747 - val_loss: 0.4385 - val_accuracy: 0.7758\n",
            "Epoch 591/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4393 - accuracy: 0.7752 - val_loss: 0.4386 - val_accuracy: 0.7754\n",
            "Epoch 592/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4393 - accuracy: 0.7753 - val_loss: 0.4385 - val_accuracy: 0.7763\n",
            "Epoch 593/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4392 - accuracy: 0.7753 - val_loss: 0.4385 - val_accuracy: 0.7757\n",
            "Epoch 594/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4392 - accuracy: 0.7754 - val_loss: 0.4387 - val_accuracy: 0.7754\n",
            "Epoch 595/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4391 - accuracy: 0.7749 - val_loss: 0.4385 - val_accuracy: 0.7765\n",
            "Epoch 596/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4393 - accuracy: 0.7751 - val_loss: 0.4385 - val_accuracy: 0.7760\n",
            "Epoch 597/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.7752 - val_loss: 0.4384 - val_accuracy: 0.7762\n",
            "Epoch 598/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4392 - accuracy: 0.7752 - val_loss: 0.4386 - val_accuracy: 0.7758\n",
            "Epoch 599/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4391 - accuracy: 0.7758 - val_loss: 0.4384 - val_accuracy: 0.7758\n",
            "Epoch 600/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7757 - val_loss: 0.4386 - val_accuracy: 0.7759\n",
            "Epoch 601/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4392 - accuracy: 0.7756 - val_loss: 0.4385 - val_accuracy: 0.7760\n",
            "Epoch 602/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4392 - accuracy: 0.7751 - val_loss: 0.4384 - val_accuracy: 0.7759\n",
            "Epoch 603/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4392 - accuracy: 0.7756 - val_loss: 0.4383 - val_accuracy: 0.7767\n",
            "Epoch 604/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7747 - val_loss: 0.4385 - val_accuracy: 0.7759\n",
            "Epoch 605/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4392 - accuracy: 0.7756 - val_loss: 0.4384 - val_accuracy: 0.7765\n",
            "Epoch 606/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7758 - val_loss: 0.4386 - val_accuracy: 0.7766\n",
            "Epoch 607/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7752 - val_loss: 0.4386 - val_accuracy: 0.7757\n",
            "Epoch 608/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7747 - val_loss: 0.4384 - val_accuracy: 0.7759\n",
            "Epoch 609/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4391 - accuracy: 0.7754 - val_loss: 0.4384 - val_accuracy: 0.7770\n",
            "Epoch 610/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7751 - val_loss: 0.4385 - val_accuracy: 0.7761\n",
            "Epoch 611/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7754 - val_loss: 0.4383 - val_accuracy: 0.7755\n",
            "Epoch 612/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4391 - accuracy: 0.7751 - val_loss: 0.4384 - val_accuracy: 0.7759\n",
            "Epoch 613/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7754 - val_loss: 0.4383 - val_accuracy: 0.7757\n",
            "Epoch 614/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7747 - val_loss: 0.4383 - val_accuracy: 0.7758\n",
            "Epoch 615/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4391 - accuracy: 0.7754 - val_loss: 0.4383 - val_accuracy: 0.7761\n",
            "Epoch 616/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4391 - accuracy: 0.7744 - val_loss: 0.4383 - val_accuracy: 0.7759\n",
            "Epoch 617/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4391 - accuracy: 0.7751 - val_loss: 0.4384 - val_accuracy: 0.7760\n",
            "Epoch 618/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4391 - accuracy: 0.7753 - val_loss: 0.4382 - val_accuracy: 0.7762\n",
            "Epoch 619/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4390 - accuracy: 0.7755 - val_loss: 0.4383 - val_accuracy: 0.7754\n",
            "Epoch 620/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7755 - val_loss: 0.4383 - val_accuracy: 0.7761\n",
            "Epoch 621/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4390 - accuracy: 0.7749 - val_loss: 0.4384 - val_accuracy: 0.7754\n",
            "Epoch 622/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7752 - val_loss: 0.4382 - val_accuracy: 0.7763\n",
            "Epoch 623/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7750 - val_loss: 0.4384 - val_accuracy: 0.7761\n",
            "Epoch 624/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4390 - accuracy: 0.7758 - val_loss: 0.4382 - val_accuracy: 0.7752\n",
            "Epoch 625/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4389 - accuracy: 0.7755 - val_loss: 0.4383 - val_accuracy: 0.7760\n",
            "Epoch 626/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7752 - val_loss: 0.4382 - val_accuracy: 0.7758\n",
            "Epoch 627/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7750 - val_loss: 0.4388 - val_accuracy: 0.7753\n",
            "Epoch 628/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7760 - val_loss: 0.4382 - val_accuracy: 0.7762\n",
            "Epoch 629/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4389 - accuracy: 0.7755 - val_loss: 0.4382 - val_accuracy: 0.7759\n",
            "Epoch 630/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4390 - accuracy: 0.7755 - val_loss: 0.4382 - val_accuracy: 0.7753\n",
            "Epoch 631/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4389 - accuracy: 0.7743 - val_loss: 0.4382 - val_accuracy: 0.7763\n",
            "Epoch 632/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4390 - accuracy: 0.7750 - val_loss: 0.4383 - val_accuracy: 0.7759\n",
            "Epoch 633/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.7757 - val_loss: 0.4381 - val_accuracy: 0.7754\n",
            "Epoch 634/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7756 - val_loss: 0.4384 - val_accuracy: 0.7768\n",
            "Epoch 635/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4390 - accuracy: 0.7751 - val_loss: 0.4381 - val_accuracy: 0.7763\n",
            "Epoch 636/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7750 - val_loss: 0.4383 - val_accuracy: 0.7760\n",
            "Epoch 637/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7756 - val_loss: 0.4381 - val_accuracy: 0.7755\n",
            "Epoch 638/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4389 - accuracy: 0.7759 - val_loss: 0.4384 - val_accuracy: 0.7762\n",
            "Epoch 639/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7755 - val_loss: 0.4385 - val_accuracy: 0.7760\n",
            "Epoch 640/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4389 - accuracy: 0.7750 - val_loss: 0.4382 - val_accuracy: 0.7754\n",
            "Epoch 641/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7754 - val_loss: 0.4382 - val_accuracy: 0.7756\n",
            "Epoch 642/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7756 - val_loss: 0.4386 - val_accuracy: 0.7753\n",
            "Epoch 643/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7754 - val_loss: 0.4381 - val_accuracy: 0.7759\n",
            "Epoch 644/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7756 - val_loss: 0.4383 - val_accuracy: 0.7767\n",
            "Epoch 645/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7761 - val_loss: 0.4380 - val_accuracy: 0.7760\n",
            "Epoch 646/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4389 - accuracy: 0.7759 - val_loss: 0.4381 - val_accuracy: 0.7762\n",
            "Epoch 647/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4389 - accuracy: 0.7751 - val_loss: 0.4381 - val_accuracy: 0.7765\n",
            "Epoch 648/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7752 - val_loss: 0.4381 - val_accuracy: 0.7758\n",
            "Epoch 649/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4388 - accuracy: 0.7767 - val_loss: 0.4383 - val_accuracy: 0.7758\n",
            "Epoch 650/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4389 - accuracy: 0.7747 - val_loss: 0.4381 - val_accuracy: 0.7757\n",
            "Epoch 651/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7760 - val_loss: 0.4386 - val_accuracy: 0.7746\n",
            "Epoch 652/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4389 - accuracy: 0.7758 - val_loss: 0.4380 - val_accuracy: 0.7762\n",
            "Epoch 653/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4387 - accuracy: 0.7750 - val_loss: 0.4383 - val_accuracy: 0.7768\n",
            "Epoch 654/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7751 - val_loss: 0.4381 - val_accuracy: 0.7757\n",
            "Epoch 655/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4388 - accuracy: 0.7754 - val_loss: 0.4381 - val_accuracy: 0.7764\n",
            "Epoch 656/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7766 - val_loss: 0.4381 - val_accuracy: 0.7766\n",
            "Epoch 657/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4389 - accuracy: 0.7758 - val_loss: 0.4381 - val_accuracy: 0.7760\n",
            "Epoch 658/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4387 - accuracy: 0.7754 - val_loss: 0.4385 - val_accuracy: 0.7753\n",
            "Epoch 659/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4388 - accuracy: 0.7753 - val_loss: 0.4383 - val_accuracy: 0.7761\n",
            "Epoch 660/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4388 - accuracy: 0.7760 - val_loss: 0.4380 - val_accuracy: 0.7758\n",
            "Epoch 661/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7750 - val_loss: 0.4380 - val_accuracy: 0.7766\n",
            "Epoch 662/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7752 - val_loss: 0.4380 - val_accuracy: 0.7761\n",
            "Epoch 663/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4388 - accuracy: 0.7762 - val_loss: 0.4380 - val_accuracy: 0.7754\n",
            "Epoch 664/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7757 - val_loss: 0.4379 - val_accuracy: 0.7754\n",
            "Epoch 665/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7751 - val_loss: 0.4379 - val_accuracy: 0.7764\n",
            "Epoch 666/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7766 - val_loss: 0.4380 - val_accuracy: 0.7759\n",
            "Epoch 667/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4387 - accuracy: 0.7754 - val_loss: 0.4382 - val_accuracy: 0.7764\n",
            "Epoch 668/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7756 - val_loss: 0.4380 - val_accuracy: 0.7757\n",
            "Epoch 669/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4387 - accuracy: 0.7757 - val_loss: 0.4379 - val_accuracy: 0.7764\n",
            "Epoch 670/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4387 - accuracy: 0.7753 - val_loss: 0.4379 - val_accuracy: 0.7757\n",
            "Epoch 671/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4388 - accuracy: 0.7753 - val_loss: 0.4379 - val_accuracy: 0.7759\n",
            "Epoch 672/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7761 - val_loss: 0.4381 - val_accuracy: 0.7757\n",
            "Epoch 673/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4386 - accuracy: 0.7761 - val_loss: 0.4379 - val_accuracy: 0.7761\n",
            "Epoch 674/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7748 - val_loss: 0.4379 - val_accuracy: 0.7759\n",
            "Epoch 675/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4387 - accuracy: 0.7761 - val_loss: 0.4379 - val_accuracy: 0.7768\n",
            "Epoch 676/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4387 - accuracy: 0.7759 - val_loss: 0.4379 - val_accuracy: 0.7761\n",
            "Epoch 677/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.7755 - val_loss: 0.4379 - val_accuracy: 0.7765\n",
            "Epoch 678/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7750 - val_loss: 0.4380 - val_accuracy: 0.7755\n",
            "Epoch 679/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4386 - accuracy: 0.7746 - val_loss: 0.4378 - val_accuracy: 0.7760\n",
            "Epoch 680/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4386 - accuracy: 0.7763 - val_loss: 0.4379 - val_accuracy: 0.7759\n",
            "Epoch 681/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4386 - accuracy: 0.7756 - val_loss: 0.4379 - val_accuracy: 0.7765\n",
            "Epoch 682/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4386 - accuracy: 0.7758 - val_loss: 0.4379 - val_accuracy: 0.7767\n",
            "Epoch 683/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4386 - accuracy: 0.7761 - val_loss: 0.4379 - val_accuracy: 0.7765\n",
            "Epoch 684/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4386 - accuracy: 0.7754 - val_loss: 0.4378 - val_accuracy: 0.7765\n",
            "Epoch 685/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7760 - val_loss: 0.4378 - val_accuracy: 0.7767\n",
            "Epoch 686/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7752 - val_loss: 0.4379 - val_accuracy: 0.7763\n",
            "Epoch 687/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7761 - val_loss: 0.4377 - val_accuracy: 0.7769\n",
            "Epoch 688/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7762 - val_loss: 0.4380 - val_accuracy: 0.7764\n",
            "Epoch 689/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4387 - accuracy: 0.7752 - val_loss: 0.4377 - val_accuracy: 0.7762\n",
            "Epoch 690/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7744 - val_loss: 0.4377 - val_accuracy: 0.7768\n",
            "Epoch 691/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4385 - accuracy: 0.7758 - val_loss: 0.4379 - val_accuracy: 0.7757\n",
            "Epoch 692/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4386 - accuracy: 0.7756 - val_loss: 0.4378 - val_accuracy: 0.7759\n",
            "Epoch 693/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7751 - val_loss: 0.4378 - val_accuracy: 0.7762\n",
            "Epoch 694/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4386 - accuracy: 0.7749 - val_loss: 0.4377 - val_accuracy: 0.7761\n",
            "Epoch 695/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4385 - accuracy: 0.7754 - val_loss: 0.4378 - val_accuracy: 0.7765\n",
            "Epoch 696/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4385 - accuracy: 0.7758 - val_loss: 0.4380 - val_accuracy: 0.7760\n",
            "Epoch 697/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7753 - val_loss: 0.4378 - val_accuracy: 0.7752\n",
            "Epoch 698/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4385 - accuracy: 0.7756 - val_loss: 0.4380 - val_accuracy: 0.7759\n",
            "Epoch 699/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7754 - val_loss: 0.4377 - val_accuracy: 0.7764\n",
            "Epoch 700/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7751 - val_loss: 0.4377 - val_accuracy: 0.7765\n",
            "Epoch 701/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7758 - val_loss: 0.4378 - val_accuracy: 0.7759\n",
            "Epoch 702/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4386 - accuracy: 0.7760 - val_loss: 0.4376 - val_accuracy: 0.7759\n",
            "Epoch 703/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7756 - val_loss: 0.4377 - val_accuracy: 0.7768\n",
            "Epoch 704/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4384 - accuracy: 0.7763 - val_loss: 0.4378 - val_accuracy: 0.7767\n",
            "Epoch 705/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7757 - val_loss: 0.4376 - val_accuracy: 0.7767\n",
            "Epoch 706/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4384 - accuracy: 0.7758 - val_loss: 0.4376 - val_accuracy: 0.7767\n",
            "Epoch 707/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4385 - accuracy: 0.7762 - val_loss: 0.4377 - val_accuracy: 0.7763\n",
            "Epoch 708/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4384 - accuracy: 0.7756 - val_loss: 0.4376 - val_accuracy: 0.7763\n",
            "Epoch 709/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4384 - accuracy: 0.7753 - val_loss: 0.4377 - val_accuracy: 0.7761\n",
            "Epoch 710/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7756 - val_loss: 0.4378 - val_accuracy: 0.7760\n",
            "Epoch 711/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7756 - val_loss: 0.4377 - val_accuracy: 0.7769\n",
            "Epoch 712/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7750 - val_loss: 0.4377 - val_accuracy: 0.7768\n",
            "Epoch 713/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4384 - accuracy: 0.7761 - val_loss: 0.4376 - val_accuracy: 0.7774\n",
            "Epoch 714/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7763 - val_loss: 0.4384 - val_accuracy: 0.7755\n",
            "Epoch 715/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4384 - accuracy: 0.7751 - val_loss: 0.4375 - val_accuracy: 0.7766\n",
            "Epoch 716/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4384 - accuracy: 0.7754 - val_loss: 0.4375 - val_accuracy: 0.7758\n",
            "Epoch 717/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7763 - val_loss: 0.4376 - val_accuracy: 0.7767\n",
            "Epoch 718/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7756 - val_loss: 0.4374 - val_accuracy: 0.7763\n",
            "Epoch 719/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4383 - accuracy: 0.7754 - val_loss: 0.4375 - val_accuracy: 0.7760\n",
            "Epoch 720/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7751 - val_loss: 0.4375 - val_accuracy: 0.7764\n",
            "Epoch 721/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7753 - val_loss: 0.4375 - val_accuracy: 0.7761\n",
            "Epoch 722/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4383 - accuracy: 0.7761 - val_loss: 0.4377 - val_accuracy: 0.7754\n",
            "Epoch 723/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7751 - val_loss: 0.4375 - val_accuracy: 0.7762\n",
            "Epoch 724/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4384 - accuracy: 0.7757 - val_loss: 0.4378 - val_accuracy: 0.7760\n",
            "Epoch 725/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4383 - accuracy: 0.7753 - val_loss: 0.4375 - val_accuracy: 0.7759\n",
            "Epoch 726/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4383 - accuracy: 0.7764 - val_loss: 0.4378 - val_accuracy: 0.7772\n",
            "Epoch 727/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4383 - accuracy: 0.7761 - val_loss: 0.4375 - val_accuracy: 0.7762\n",
            "Epoch 728/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7755 - val_loss: 0.4377 - val_accuracy: 0.7761\n",
            "Epoch 729/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7751 - val_loss: 0.4377 - val_accuracy: 0.7771\n",
            "Epoch 730/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7753 - val_loss: 0.4376 - val_accuracy: 0.7771\n",
            "Epoch 731/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7757 - val_loss: 0.4376 - val_accuracy: 0.7766\n",
            "Epoch 732/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4383 - accuracy: 0.7765 - val_loss: 0.4374 - val_accuracy: 0.7767\n",
            "Epoch 733/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7759 - val_loss: 0.4375 - val_accuracy: 0.7762\n",
            "Epoch 734/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7764 - val_loss: 0.4377 - val_accuracy: 0.7767\n",
            "Epoch 735/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7751 - val_loss: 0.4376 - val_accuracy: 0.7763\n",
            "Epoch 736/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7755 - val_loss: 0.4376 - val_accuracy: 0.7771\n",
            "Epoch 737/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7764 - val_loss: 0.4380 - val_accuracy: 0.7759\n",
            "Epoch 738/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4383 - accuracy: 0.7757 - val_loss: 0.4375 - val_accuracy: 0.7762\n",
            "Epoch 739/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7755 - val_loss: 0.4374 - val_accuracy: 0.7767\n",
            "Epoch 740/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7754 - val_loss: 0.4375 - val_accuracy: 0.7761\n",
            "Epoch 741/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7762 - val_loss: 0.4375 - val_accuracy: 0.7758\n",
            "Epoch 742/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4383 - accuracy: 0.7761 - val_loss: 0.4375 - val_accuracy: 0.7765\n",
            "Epoch 743/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7763 - val_loss: 0.4374 - val_accuracy: 0.7759\n",
            "Epoch 744/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7762 - val_loss: 0.4377 - val_accuracy: 0.7767\n",
            "Epoch 745/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7755 - val_loss: 0.4378 - val_accuracy: 0.7770\n",
            "Epoch 746/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7757 - val_loss: 0.4374 - val_accuracy: 0.7764\n",
            "Epoch 747/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7763 - val_loss: 0.4376 - val_accuracy: 0.7767\n",
            "Epoch 748/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4382 - accuracy: 0.7756 - val_loss: 0.4373 - val_accuracy: 0.7770\n",
            "Epoch 749/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7759 - val_loss: 0.4376 - val_accuracy: 0.7754\n",
            "Epoch 750/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7759 - val_loss: 0.4374 - val_accuracy: 0.7761\n",
            "Epoch 751/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7761 - val_loss: 0.4374 - val_accuracy: 0.7760\n",
            "Epoch 752/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4382 - accuracy: 0.7751 - val_loss: 0.4373 - val_accuracy: 0.7766\n",
            "Epoch 753/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7765 - val_loss: 0.4374 - val_accuracy: 0.7758\n",
            "Epoch 754/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7765 - val_loss: 0.4375 - val_accuracy: 0.7760\n",
            "Epoch 755/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4382 - accuracy: 0.7759 - val_loss: 0.4374 - val_accuracy: 0.7766\n",
            "Epoch 756/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7761 - val_loss: 0.4377 - val_accuracy: 0.7762\n",
            "Epoch 757/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7763 - val_loss: 0.4373 - val_accuracy: 0.7761\n",
            "Epoch 758/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4382 - accuracy: 0.7758 - val_loss: 0.4373 - val_accuracy: 0.7764\n",
            "Epoch 759/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7763 - val_loss: 0.4374 - val_accuracy: 0.7765\n",
            "Epoch 760/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.4373 - val_accuracy: 0.7767\n",
            "Epoch 761/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4381 - accuracy: 0.7754 - val_loss: 0.4374 - val_accuracy: 0.7772\n",
            "Epoch 762/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7750 - val_loss: 0.4373 - val_accuracy: 0.7755\n",
            "Epoch 763/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.4373 - val_accuracy: 0.7755\n",
            "Epoch 764/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4382 - accuracy: 0.7754 - val_loss: 0.4373 - val_accuracy: 0.7761\n",
            "Epoch 765/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4380 - accuracy: 0.7756 - val_loss: 0.4381 - val_accuracy: 0.7745\n",
            "Epoch 766/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7760 - val_loss: 0.4375 - val_accuracy: 0.7755\n",
            "Epoch 767/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4381 - accuracy: 0.7754 - val_loss: 0.4375 - val_accuracy: 0.7756\n",
            "Epoch 768/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7748 - val_loss: 0.4374 - val_accuracy: 0.7762\n",
            "Epoch 769/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7752 - val_loss: 0.4376 - val_accuracy: 0.7756\n",
            "Epoch 770/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4381 - accuracy: 0.7761 - val_loss: 0.4375 - val_accuracy: 0.7770\n",
            "Epoch 771/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7762 - val_loss: 0.4373 - val_accuracy: 0.7757\n",
            "Epoch 772/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4380 - accuracy: 0.7763 - val_loss: 0.4374 - val_accuracy: 0.7772\n",
            "Epoch 773/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4381 - accuracy: 0.7755 - val_loss: 0.4374 - val_accuracy: 0.7770\n",
            "Epoch 774/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4381 - accuracy: 0.7758 - val_loss: 0.4373 - val_accuracy: 0.7767\n",
            "Epoch 775/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7758 - val_loss: 0.4374 - val_accuracy: 0.7767\n",
            "Epoch 776/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7755 - val_loss: 0.4373 - val_accuracy: 0.7772\n",
            "Epoch 777/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4380 - accuracy: 0.7758 - val_loss: 0.4374 - val_accuracy: 0.7767\n",
            "Epoch 778/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4381 - accuracy: 0.7755 - val_loss: 0.4373 - val_accuracy: 0.7769\n",
            "Epoch 779/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7763 - val_loss: 0.4375 - val_accuracy: 0.7761\n",
            "Epoch 780/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.4375 - val_accuracy: 0.7775\n",
            "Epoch 781/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7759 - val_loss: 0.4372 - val_accuracy: 0.7767\n",
            "Epoch 782/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4381 - accuracy: 0.7764 - val_loss: 0.4374 - val_accuracy: 0.7766\n",
            "Epoch 783/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.4373 - val_accuracy: 0.7761\n",
            "Epoch 784/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7761 - val_loss: 0.4373 - val_accuracy: 0.7757\n",
            "Epoch 785/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7765 - val_loss: 0.4373 - val_accuracy: 0.7765\n",
            "Epoch 786/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7759 - val_loss: 0.4373 - val_accuracy: 0.7776\n",
            "Epoch 787/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7762 - val_loss: 0.4373 - val_accuracy: 0.7758\n",
            "Epoch 788/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7754 - val_loss: 0.4371 - val_accuracy: 0.7766\n",
            "Epoch 789/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7756 - val_loss: 0.4375 - val_accuracy: 0.7777\n",
            "Epoch 790/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7756 - val_loss: 0.4372 - val_accuracy: 0.7754\n",
            "Epoch 791/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7761 - val_loss: 0.4374 - val_accuracy: 0.7777\n",
            "Epoch 792/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7767 - val_loss: 0.4372 - val_accuracy: 0.7762\n",
            "Epoch 793/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7758 - val_loss: 0.4372 - val_accuracy: 0.7755\n",
            "Epoch 794/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4380 - accuracy: 0.7759 - val_loss: 0.4372 - val_accuracy: 0.7769\n",
            "Epoch 795/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4380 - accuracy: 0.7760 - val_loss: 0.4375 - val_accuracy: 0.7773\n",
            "Epoch 796/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4379 - accuracy: 0.7761 - val_loss: 0.4372 - val_accuracy: 0.7763\n",
            "Epoch 797/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7754 - val_loss: 0.4376 - val_accuracy: 0.7771\n",
            "Epoch 798/1500\n",
            "1219/1219 [==============================] - 9s 7ms/step - loss: 0.4380 - accuracy: 0.7763 - val_loss: 0.4371 - val_accuracy: 0.7772\n",
            "Epoch 799/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7762 - val_loss: 0.4371 - val_accuracy: 0.7764\n",
            "Epoch 800/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4378 - accuracy: 0.7754 - val_loss: 0.4378 - val_accuracy: 0.7755\n",
            "Epoch 801/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7757 - val_loss: 0.4371 - val_accuracy: 0.7763\n",
            "Epoch 802/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7762 - val_loss: 0.4371 - val_accuracy: 0.7761\n",
            "Epoch 803/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7757 - val_loss: 0.4373 - val_accuracy: 0.7773\n",
            "Epoch 804/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4379 - accuracy: 0.7759 - val_loss: 0.4371 - val_accuracy: 0.7765\n",
            "Epoch 805/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7755 - val_loss: 0.4371 - val_accuracy: 0.7753\n",
            "Epoch 806/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7764 - val_loss: 0.4374 - val_accuracy: 0.7765\n",
            "Epoch 807/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7761 - val_loss: 0.4372 - val_accuracy: 0.7769\n",
            "Epoch 808/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7760 - val_loss: 0.4371 - val_accuracy: 0.7777\n",
            "Epoch 809/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7759 - val_loss: 0.4371 - val_accuracy: 0.7762\n",
            "Epoch 810/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7771 - val_loss: 0.4371 - val_accuracy: 0.7768\n",
            "Epoch 811/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7764 - val_loss: 0.4371 - val_accuracy: 0.7761\n",
            "Epoch 812/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7756 - val_loss: 0.4372 - val_accuracy: 0.7779\n",
            "Epoch 813/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7761 - val_loss: 0.4372 - val_accuracy: 0.7767\n",
            "Epoch 814/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7757 - val_loss: 0.4370 - val_accuracy: 0.7775\n",
            "Epoch 815/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.7773\n",
            "Epoch 816/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7759 - val_loss: 0.4371 - val_accuracy: 0.7775\n",
            "Epoch 817/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7759 - val_loss: 0.4371 - val_accuracy: 0.7759\n",
            "Epoch 818/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4379 - accuracy: 0.7767 - val_loss: 0.4370 - val_accuracy: 0.7771\n",
            "Epoch 819/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4379 - accuracy: 0.7758 - val_loss: 0.4372 - val_accuracy: 0.7760\n",
            "Epoch 820/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.7768 - val_loss: 0.4374 - val_accuracy: 0.7772\n",
            "Epoch 821/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7763 - val_loss: 0.4373 - val_accuracy: 0.7756\n",
            "Epoch 822/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4379 - accuracy: 0.7757 - val_loss: 0.4370 - val_accuracy: 0.7766\n",
            "Epoch 823/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4378 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.7771\n",
            "Epoch 824/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4378 - accuracy: 0.7762 - val_loss: 0.4371 - val_accuracy: 0.7779\n",
            "Epoch 825/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7770 - val_loss: 0.4369 - val_accuracy: 0.7776\n",
            "Epoch 826/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7759 - val_loss: 0.4370 - val_accuracy: 0.7760\n",
            "Epoch 827/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4378 - accuracy: 0.7756 - val_loss: 0.4371 - val_accuracy: 0.7771\n",
            "Epoch 828/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4378 - accuracy: 0.7758 - val_loss: 0.4373 - val_accuracy: 0.7755\n",
            "Epoch 829/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4378 - accuracy: 0.7761 - val_loss: 0.4373 - val_accuracy: 0.7773\n",
            "Epoch 830/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7767 - val_loss: 0.4371 - val_accuracy: 0.7762\n",
            "Epoch 831/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7764 - val_loss: 0.4372 - val_accuracy: 0.7763\n",
            "Epoch 832/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4378 - accuracy: 0.7768 - val_loss: 0.4372 - val_accuracy: 0.7767\n",
            "Epoch 833/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7768 - val_loss: 0.4370 - val_accuracy: 0.7772\n",
            "Epoch 834/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7761 - val_loss: 0.4375 - val_accuracy: 0.7759\n",
            "Epoch 835/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7758 - val_loss: 0.4370 - val_accuracy: 0.7770\n",
            "Epoch 836/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7763 - val_loss: 0.4371 - val_accuracy: 0.7763\n",
            "Epoch 837/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7757 - val_loss: 0.4372 - val_accuracy: 0.7771\n",
            "Epoch 838/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4377 - accuracy: 0.7758 - val_loss: 0.4370 - val_accuracy: 0.7757\n",
            "Epoch 839/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7761 - val_loss: 0.4369 - val_accuracy: 0.7762\n",
            "Epoch 840/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7773 - val_loss: 0.4371 - val_accuracy: 0.7752\n",
            "Epoch 841/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7765 - val_loss: 0.4369 - val_accuracy: 0.7766\n",
            "Epoch 842/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7763 - val_loss: 0.4370 - val_accuracy: 0.7774\n",
            "Epoch 843/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.4370 - val_accuracy: 0.7767\n",
            "Epoch 844/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7768 - val_loss: 0.4371 - val_accuracy: 0.7764\n",
            "Epoch 845/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7768 - val_loss: 0.4372 - val_accuracy: 0.7774\n",
            "Epoch 846/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7761 - val_loss: 0.4369 - val_accuracy: 0.7771\n",
            "Epoch 847/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7754 - val_loss: 0.4370 - val_accuracy: 0.7766\n",
            "Epoch 848/1500\n",
            "1219/1219 [==============================] - 7s 6ms/step - loss: 0.4378 - accuracy: 0.7758 - val_loss: 0.4371 - val_accuracy: 0.7765\n",
            "Epoch 849/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7761 - val_loss: 0.4369 - val_accuracy: 0.7767\n",
            "Epoch 850/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7764 - val_loss: 0.4373 - val_accuracy: 0.7780\n",
            "Epoch 851/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7766 - val_loss: 0.4369 - val_accuracy: 0.7772\n",
            "Epoch 852/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7755 - val_loss: 0.4374 - val_accuracy: 0.7775\n",
            "Epoch 853/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7766 - val_loss: 0.4371 - val_accuracy: 0.7769\n",
            "Epoch 854/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7759 - val_loss: 0.4370 - val_accuracy: 0.7770\n",
            "Epoch 855/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7763 - val_loss: 0.4371 - val_accuracy: 0.7762\n",
            "Epoch 856/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7770 - val_loss: 0.4370 - val_accuracy: 0.7767\n",
            "Epoch 857/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4377 - accuracy: 0.7761 - val_loss: 0.4370 - val_accuracy: 0.7769\n",
            "Epoch 858/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7766 - val_loss: 0.4369 - val_accuracy: 0.7763\n",
            "Epoch 859/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.7763\n",
            "Epoch 860/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4378 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.7773\n",
            "Epoch 861/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.4368 - val_accuracy: 0.7779\n",
            "Epoch 862/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4377 - accuracy: 0.7758 - val_loss: 0.4369 - val_accuracy: 0.7774\n",
            "Epoch 863/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7760 - val_loss: 0.4369 - val_accuracy: 0.7767\n",
            "Epoch 864/1500\n",
            "1219/1219 [==============================] - 9s 7ms/step - loss: 0.4376 - accuracy: 0.7764 - val_loss: 0.4368 - val_accuracy: 0.7768\n",
            "Epoch 865/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7758 - val_loss: 0.4369 - val_accuracy: 0.7771\n",
            "Epoch 866/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7762 - val_loss: 0.4368 - val_accuracy: 0.7772\n",
            "Epoch 867/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.7759 - val_loss: 0.4369 - val_accuracy: 0.7777\n",
            "Epoch 868/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7761 - val_loss: 0.4371 - val_accuracy: 0.7766\n",
            "Epoch 869/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7762 - val_loss: 0.4368 - val_accuracy: 0.7776\n",
            "Epoch 870/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7761 - val_loss: 0.4369 - val_accuracy: 0.7761\n",
            "Epoch 871/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7758 - val_loss: 0.4370 - val_accuracy: 0.7769\n",
            "Epoch 872/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4376 - accuracy: 0.7769 - val_loss: 0.4368 - val_accuracy: 0.7764\n",
            "Epoch 873/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7767 - val_loss: 0.4367 - val_accuracy: 0.7775\n",
            "Epoch 874/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4377 - accuracy: 0.7761 - val_loss: 0.4368 - val_accuracy: 0.7771\n",
            "Epoch 875/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7767 - val_loss: 0.4369 - val_accuracy: 0.7766\n",
            "Epoch 876/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4376 - accuracy: 0.7758 - val_loss: 0.4372 - val_accuracy: 0.7754\n",
            "Epoch 877/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7763 - val_loss: 0.4368 - val_accuracy: 0.7781\n",
            "Epoch 878/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7758 - val_loss: 0.4367 - val_accuracy: 0.7774\n",
            "Epoch 879/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7759 - val_loss: 0.4368 - val_accuracy: 0.7758\n",
            "Epoch 880/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.4368 - val_accuracy: 0.7774\n",
            "Epoch 881/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7761 - val_loss: 0.4370 - val_accuracy: 0.7774\n",
            "Epoch 882/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7771 - val_loss: 0.4370 - val_accuracy: 0.7759\n",
            "Epoch 883/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7767 - val_loss: 0.4370 - val_accuracy: 0.7772\n",
            "Epoch 884/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7767 - val_loss: 0.4370 - val_accuracy: 0.7774\n",
            "Epoch 885/1500\n",
            "1219/1219 [==============================] - 9s 7ms/step - loss: 0.4376 - accuracy: 0.7759 - val_loss: 0.4367 - val_accuracy: 0.7768\n",
            "Epoch 886/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.7773 - val_loss: 0.4368 - val_accuracy: 0.7773\n",
            "Epoch 887/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7763 - val_loss: 0.4370 - val_accuracy: 0.7777\n",
            "Epoch 888/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7767 - val_loss: 0.4369 - val_accuracy: 0.7776\n",
            "Epoch 889/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4376 - accuracy: 0.7763 - val_loss: 0.4367 - val_accuracy: 0.7771\n",
            "Epoch 890/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7766 - val_loss: 0.4370 - val_accuracy: 0.7761\n",
            "Epoch 891/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7757 - val_loss: 0.4369 - val_accuracy: 0.7771\n",
            "Epoch 892/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7755 - val_loss: 0.4368 - val_accuracy: 0.7767\n",
            "Epoch 893/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4376 - accuracy: 0.7765 - val_loss: 0.4366 - val_accuracy: 0.7770\n",
            "Epoch 894/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4376 - accuracy: 0.7764 - val_loss: 0.4367 - val_accuracy: 0.7780\n",
            "Epoch 895/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7758 - val_loss: 0.4367 - val_accuracy: 0.7764\n",
            "Epoch 896/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7768 - val_loss: 0.4368 - val_accuracy: 0.7771\n",
            "Epoch 897/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7764 - val_loss: 0.4367 - val_accuracy: 0.7770\n",
            "Epoch 898/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7758 - val_loss: 0.4367 - val_accuracy: 0.7771\n",
            "Epoch 899/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7758 - val_loss: 0.4371 - val_accuracy: 0.7774\n",
            "Epoch 900/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7764 - val_loss: 0.4369 - val_accuracy: 0.7782\n",
            "Epoch 901/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7759 - val_loss: 0.4367 - val_accuracy: 0.7767\n",
            "Epoch 902/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7771 - val_loss: 0.4382 - val_accuracy: 0.7749\n",
            "Epoch 903/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7764 - val_loss: 0.4370 - val_accuracy: 0.7776\n",
            "Epoch 904/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7758 - val_loss: 0.4368 - val_accuracy: 0.7775\n",
            "Epoch 905/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4375 - accuracy: 0.7764 - val_loss: 0.4367 - val_accuracy: 0.7777\n",
            "Epoch 906/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7765 - val_loss: 0.4367 - val_accuracy: 0.7772\n",
            "Epoch 907/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7755 - val_loss: 0.4369 - val_accuracy: 0.7756\n",
            "Epoch 908/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7753 - val_loss: 0.4366 - val_accuracy: 0.7767\n",
            "Epoch 909/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7765 - val_loss: 0.4368 - val_accuracy: 0.7776\n",
            "Epoch 910/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7765 - val_loss: 0.4371 - val_accuracy: 0.7756\n",
            "Epoch 911/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7762 - val_loss: 0.4370 - val_accuracy: 0.7761\n",
            "Epoch 912/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.4367 - val_accuracy: 0.7774\n",
            "Epoch 913/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7757 - val_loss: 0.4368 - val_accuracy: 0.7763\n",
            "Epoch 914/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4375 - accuracy: 0.7761 - val_loss: 0.4366 - val_accuracy: 0.7767\n",
            "Epoch 915/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7758 - val_loss: 0.4366 - val_accuracy: 0.7777\n",
            "Epoch 916/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4374 - accuracy: 0.7768 - val_loss: 0.4366 - val_accuracy: 0.7775\n",
            "Epoch 917/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7761 - val_loss: 0.4367 - val_accuracy: 0.7769\n",
            "Epoch 918/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7771 - val_loss: 0.4366 - val_accuracy: 0.7767\n",
            "Epoch 919/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4375 - accuracy: 0.7760 - val_loss: 0.4367 - val_accuracy: 0.7773\n",
            "Epoch 920/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7753 - val_loss: 0.4371 - val_accuracy: 0.7775\n",
            "Epoch 921/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4375 - accuracy: 0.7771 - val_loss: 0.4366 - val_accuracy: 0.7776\n",
            "Epoch 922/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7762 - val_loss: 0.4368 - val_accuracy: 0.7768\n",
            "Epoch 923/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4374 - accuracy: 0.7772 - val_loss: 0.4367 - val_accuracy: 0.7765\n",
            "Epoch 924/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7770 - val_loss: 0.4366 - val_accuracy: 0.7774\n",
            "Epoch 925/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7769 - val_loss: 0.4367 - val_accuracy: 0.7763\n",
            "Epoch 926/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4374 - accuracy: 0.7763 - val_loss: 0.4367 - val_accuracy: 0.7770\n",
            "Epoch 927/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7760 - val_loss: 0.4366 - val_accuracy: 0.7776\n",
            "Epoch 928/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4374 - accuracy: 0.7762 - val_loss: 0.4366 - val_accuracy: 0.7778\n",
            "Epoch 929/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7764 - val_loss: 0.4367 - val_accuracy: 0.7776\n",
            "Epoch 930/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7768\n",
            "Epoch 931/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4374 - accuracy: 0.7761 - val_loss: 0.4365 - val_accuracy: 0.7772\n",
            "Epoch 932/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7763 - val_loss: 0.4368 - val_accuracy: 0.7764\n",
            "Epoch 933/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7763 - val_loss: 0.4366 - val_accuracy: 0.7766\n",
            "Epoch 934/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7763 - val_loss: 0.4367 - val_accuracy: 0.7775\n",
            "Epoch 935/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7763 - val_loss: 0.4366 - val_accuracy: 0.7770\n",
            "Epoch 936/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7767 - val_loss: 0.4366 - val_accuracy: 0.7767\n",
            "Epoch 937/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7763 - val_loss: 0.4367 - val_accuracy: 0.7776\n",
            "Epoch 938/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7757 - val_loss: 0.4365 - val_accuracy: 0.7780\n",
            "Epoch 939/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7764 - val_loss: 0.4366 - val_accuracy: 0.7768\n",
            "Epoch 940/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4374 - accuracy: 0.7767 - val_loss: 0.4366 - val_accuracy: 0.7769\n",
            "Epoch 941/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7769 - val_loss: 0.4365 - val_accuracy: 0.7779\n",
            "Epoch 942/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4374 - accuracy: 0.7765 - val_loss: 0.4365 - val_accuracy: 0.7773\n",
            "Epoch 943/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7781\n",
            "Epoch 944/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7766\n",
            "Epoch 945/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7766 - val_loss: 0.4366 - val_accuracy: 0.7771\n",
            "Epoch 946/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7766 - val_loss: 0.4366 - val_accuracy: 0.7769\n",
            "Epoch 947/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4374 - accuracy: 0.7762 - val_loss: 0.4364 - val_accuracy: 0.7773\n",
            "Epoch 948/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4374 - accuracy: 0.7763 - val_loss: 0.4364 - val_accuracy: 0.7772\n",
            "Epoch 949/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.4369 - val_accuracy: 0.7765\n",
            "Epoch 950/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7767 - val_loss: 0.4364 - val_accuracy: 0.7768\n",
            "Epoch 951/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.4364 - val_accuracy: 0.7776\n",
            "Epoch 952/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.4367 - val_accuracy: 0.7766\n",
            "Epoch 953/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7764 - val_loss: 0.4367 - val_accuracy: 0.7763\n",
            "Epoch 954/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7767 - val_loss: 0.4366 - val_accuracy: 0.7769\n",
            "Epoch 955/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4373 - accuracy: 0.7764 - val_loss: 0.4366 - val_accuracy: 0.7778\n",
            "Epoch 956/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7770 - val_loss: 0.4365 - val_accuracy: 0.7766\n",
            "Epoch 957/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7782 - val_loss: 0.4365 - val_accuracy: 0.7770\n",
            "Epoch 958/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7767 - val_loss: 0.4364 - val_accuracy: 0.7777\n",
            "Epoch 959/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7770\n",
            "Epoch 960/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.4366 - val_accuracy: 0.7781\n",
            "Epoch 961/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7773 - val_loss: 0.4367 - val_accuracy: 0.7777\n",
            "Epoch 962/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7764 - val_loss: 0.4365 - val_accuracy: 0.7782\n",
            "Epoch 963/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4373 - accuracy: 0.7766 - val_loss: 0.4366 - val_accuracy: 0.7765\n",
            "Epoch 964/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.7770 - val_loss: 0.4364 - val_accuracy: 0.7781\n",
            "Epoch 965/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7764 - val_loss: 0.4368 - val_accuracy: 0.7769\n",
            "Epoch 966/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7767 - val_loss: 0.4364 - val_accuracy: 0.7775\n",
            "Epoch 967/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4373 - accuracy: 0.7765 - val_loss: 0.4364 - val_accuracy: 0.7775\n",
            "Epoch 968/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7770 - val_loss: 0.4365 - val_accuracy: 0.7761\n",
            "Epoch 969/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4373 - accuracy: 0.7768 - val_loss: 0.4363 - val_accuracy: 0.7768\n",
            "Epoch 970/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7760 - val_loss: 0.4368 - val_accuracy: 0.7780\n",
            "Epoch 971/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7773 - val_loss: 0.4364 - val_accuracy: 0.7768\n",
            "Epoch 972/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4372 - accuracy: 0.7770 - val_loss: 0.4366 - val_accuracy: 0.7763\n",
            "Epoch 973/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7768 - val_loss: 0.4363 - val_accuracy: 0.7769\n",
            "Epoch 974/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4372 - accuracy: 0.7764 - val_loss: 0.4363 - val_accuracy: 0.7773\n",
            "Epoch 975/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4372 - accuracy: 0.7770 - val_loss: 0.4364 - val_accuracy: 0.7771\n",
            "Epoch 976/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4371 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7773\n",
            "Epoch 977/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4372 - accuracy: 0.7769 - val_loss: 0.4364 - val_accuracy: 0.7771\n",
            "Epoch 978/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7765 - val_loss: 0.4364 - val_accuracy: 0.7773\n",
            "Epoch 979/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7758 - val_loss: 0.4363 - val_accuracy: 0.7782\n",
            "Epoch 980/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7772 - val_loss: 0.4364 - val_accuracy: 0.7774\n",
            "Epoch 981/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7767 - val_loss: 0.4364 - val_accuracy: 0.7776\n",
            "Epoch 982/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7765 - val_loss: 0.4363 - val_accuracy: 0.7782\n",
            "Epoch 983/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7769 - val_loss: 0.4370 - val_accuracy: 0.7758\n",
            "Epoch 984/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7767 - val_loss: 0.4364 - val_accuracy: 0.7782\n",
            "Epoch 985/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7768 - val_loss: 0.4364 - val_accuracy: 0.7775\n",
            "Epoch 986/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4372 - accuracy: 0.7766 - val_loss: 0.4363 - val_accuracy: 0.7771\n",
            "Epoch 987/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4371 - accuracy: 0.7768 - val_loss: 0.4364 - val_accuracy: 0.7780\n",
            "Epoch 988/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4370 - accuracy: 0.7765 - val_loss: 0.4365 - val_accuracy: 0.7760\n",
            "Epoch 989/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4372 - accuracy: 0.7765 - val_loss: 0.4363 - val_accuracy: 0.7777\n",
            "Epoch 990/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4371 - accuracy: 0.7763 - val_loss: 0.4368 - val_accuracy: 0.7776\n",
            "Epoch 991/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.7764 - val_loss: 0.4363 - val_accuracy: 0.7781\n",
            "Epoch 992/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7772 - val_loss: 0.4362 - val_accuracy: 0.7764\n",
            "Epoch 993/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7773 - val_loss: 0.4364 - val_accuracy: 0.7785\n",
            "Epoch 994/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.7762 - val_loss: 0.4362 - val_accuracy: 0.7784\n",
            "Epoch 995/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.7780 - val_loss: 0.4365 - val_accuracy: 0.7766\n",
            "Epoch 996/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.4362 - val_accuracy: 0.7779\n",
            "Epoch 997/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7772 - val_loss: 0.4363 - val_accuracy: 0.7770\n",
            "Epoch 998/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7769 - val_loss: 0.4376 - val_accuracy: 0.7752\n",
            "Epoch 999/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7765 - val_loss: 0.4368 - val_accuracy: 0.7754\n",
            "Epoch 1000/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4371 - accuracy: 0.7768 - val_loss: 0.4364 - val_accuracy: 0.7778\n",
            "Epoch 1001/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7764 - val_loss: 0.4362 - val_accuracy: 0.7781\n",
            "Epoch 1002/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7768 - val_loss: 0.4363 - val_accuracy: 0.7770\n",
            "Epoch 1003/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7767 - val_loss: 0.4367 - val_accuracy: 0.7766\n",
            "Epoch 1004/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4371 - accuracy: 0.7768 - val_loss: 0.4362 - val_accuracy: 0.7778\n",
            "Epoch 1005/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7758 - val_loss: 0.4361 - val_accuracy: 0.7784\n",
            "Epoch 1006/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4370 - accuracy: 0.7765 - val_loss: 0.4362 - val_accuracy: 0.7773\n",
            "Epoch 1007/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7775 - val_loss: 0.4366 - val_accuracy: 0.7782\n",
            "Epoch 1008/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7776 - val_loss: 0.4361 - val_accuracy: 0.7779\n",
            "Epoch 1009/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7767 - val_loss: 0.4362 - val_accuracy: 0.7774\n",
            "Epoch 1010/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7766 - val_loss: 0.4365 - val_accuracy: 0.7786\n",
            "Epoch 1011/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7771 - val_loss: 0.4362 - val_accuracy: 0.7775\n",
            "Epoch 1012/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4370 - accuracy: 0.7773 - val_loss: 0.4364 - val_accuracy: 0.7769\n",
            "Epoch 1013/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4370 - accuracy: 0.7763 - val_loss: 0.4366 - val_accuracy: 0.7776\n",
            "Epoch 1014/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4370 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7778\n",
            "Epoch 1015/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4371 - accuracy: 0.7766 - val_loss: 0.4361 - val_accuracy: 0.7788\n",
            "Epoch 1016/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7774 - val_loss: 0.4362 - val_accuracy: 0.7778\n",
            "Epoch 1017/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7772 - val_loss: 0.4362 - val_accuracy: 0.7767\n",
            "Epoch 1018/1500\n",
            "1219/1219 [==============================] - 7s 5ms/step - loss: 0.4370 - accuracy: 0.7769 - val_loss: 0.4363 - val_accuracy: 0.7775\n",
            "Epoch 1019/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4369 - accuracy: 0.7776 - val_loss: 0.4362 - val_accuracy: 0.7784\n",
            "Epoch 1020/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7763 - val_loss: 0.4361 - val_accuracy: 0.7779\n",
            "Epoch 1021/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7768 - val_loss: 0.4365 - val_accuracy: 0.7784\n",
            "Epoch 1022/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4370 - accuracy: 0.7774 - val_loss: 0.4361 - val_accuracy: 0.7776\n",
            "Epoch 1023/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7768 - val_loss: 0.4362 - val_accuracy: 0.7780\n",
            "Epoch 1024/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7774 - val_loss: 0.4364 - val_accuracy: 0.7763\n",
            "Epoch 1025/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4370 - accuracy: 0.7772 - val_loss: 0.4363 - val_accuracy: 0.7781\n",
            "Epoch 1026/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7768 - val_loss: 0.4360 - val_accuracy: 0.7781\n",
            "Epoch 1027/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7766 - val_loss: 0.4363 - val_accuracy: 0.7780\n",
            "Epoch 1028/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7769 - val_loss: 0.4363 - val_accuracy: 0.7766\n",
            "Epoch 1029/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7771 - val_loss: 0.4361 - val_accuracy: 0.7781\n",
            "Epoch 1030/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4370 - accuracy: 0.7772 - val_loss: 0.4360 - val_accuracy: 0.7780\n",
            "Epoch 1031/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7769 - val_loss: 0.4361 - val_accuracy: 0.7779\n",
            "Epoch 1032/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7768 - val_loss: 0.4361 - val_accuracy: 0.7784\n",
            "Epoch 1033/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4369 - accuracy: 0.7772 - val_loss: 0.4362 - val_accuracy: 0.7770\n",
            "Epoch 1034/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7773 - val_loss: 0.4360 - val_accuracy: 0.7771\n",
            "Epoch 1035/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7763 - val_loss: 0.4360 - val_accuracy: 0.7779\n",
            "Epoch 1036/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4369 - accuracy: 0.7772 - val_loss: 0.4362 - val_accuracy: 0.7774\n",
            "Epoch 1037/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7775 - val_loss: 0.4361 - val_accuracy: 0.7782\n",
            "Epoch 1038/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7774 - val_loss: 0.4363 - val_accuracy: 0.7790\n",
            "Epoch 1039/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4369 - accuracy: 0.7777 - val_loss: 0.4360 - val_accuracy: 0.7778\n",
            "Epoch 1040/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7770 - val_loss: 0.4361 - val_accuracy: 0.7773\n",
            "Epoch 1041/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7772 - val_loss: 0.4362 - val_accuracy: 0.7780\n",
            "Epoch 1042/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7774 - val_loss: 0.4363 - val_accuracy: 0.7790\n",
            "Epoch 1043/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4369 - accuracy: 0.7768 - val_loss: 0.4361 - val_accuracy: 0.7779\n",
            "Epoch 1044/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.4365 - val_accuracy: 0.7761\n",
            "Epoch 1045/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7776 - val_loss: 0.4361 - val_accuracy: 0.7782\n",
            "Epoch 1046/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7776 - val_loss: 0.4360 - val_accuracy: 0.7778\n",
            "Epoch 1047/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7763 - val_loss: 0.4360 - val_accuracy: 0.7775\n",
            "Epoch 1048/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7775 - val_loss: 0.4360 - val_accuracy: 0.7784\n",
            "Epoch 1049/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7778 - val_loss: 0.4360 - val_accuracy: 0.7776\n",
            "Epoch 1050/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7770 - val_loss: 0.4360 - val_accuracy: 0.7779\n",
            "Epoch 1051/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7766 - val_loss: 0.4359 - val_accuracy: 0.7779\n",
            "Epoch 1052/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4367 - accuracy: 0.7764 - val_loss: 0.4365 - val_accuracy: 0.7783\n",
            "Epoch 1053/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7779 - val_loss: 0.4361 - val_accuracy: 0.7770\n",
            "Epoch 1054/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7773 - val_loss: 0.4366 - val_accuracy: 0.7757\n",
            "Epoch 1055/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7769 - val_loss: 0.4363 - val_accuracy: 0.7782\n",
            "Epoch 1056/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7771 - val_loss: 0.4360 - val_accuracy: 0.7782\n",
            "Epoch 1057/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7770 - val_loss: 0.4360 - val_accuracy: 0.7772\n",
            "Epoch 1058/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7777 - val_loss: 0.4361 - val_accuracy: 0.7777\n",
            "Epoch 1059/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4369 - accuracy: 0.7772 - val_loss: 0.4359 - val_accuracy: 0.7783\n",
            "Epoch 1060/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7777 - val_loss: 0.4360 - val_accuracy: 0.7777\n",
            "Epoch 1061/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7770 - val_loss: 0.4359 - val_accuracy: 0.7772\n",
            "Epoch 1062/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7774 - val_loss: 0.4361 - val_accuracy: 0.7781\n",
            "Epoch 1063/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7772 - val_loss: 0.4359 - val_accuracy: 0.7788\n",
            "Epoch 1064/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7772 - val_loss: 0.4360 - val_accuracy: 0.7772\n",
            "Epoch 1065/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7766 - val_loss: 0.4358 - val_accuracy: 0.7779\n",
            "Epoch 1066/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4368 - accuracy: 0.7774 - val_loss: 0.4359 - val_accuracy: 0.7784\n",
            "Epoch 1067/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7770 - val_loss: 0.4360 - val_accuracy: 0.7774\n",
            "Epoch 1068/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7775 - val_loss: 0.4358 - val_accuracy: 0.7782\n",
            "Epoch 1069/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7773 - val_loss: 0.4360 - val_accuracy: 0.7784\n",
            "Epoch 1070/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7771 - val_loss: 0.4359 - val_accuracy: 0.7786\n",
            "Epoch 1071/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4368 - accuracy: 0.7773 - val_loss: 0.4358 - val_accuracy: 0.7789\n",
            "Epoch 1072/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7774 - val_loss: 0.4361 - val_accuracy: 0.7776\n",
            "Epoch 1073/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7770 - val_loss: 0.4360 - val_accuracy: 0.7780\n",
            "Epoch 1074/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4368 - accuracy: 0.7771 - val_loss: 0.4358 - val_accuracy: 0.7776\n",
            "Epoch 1075/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7775 - val_loss: 0.4374 - val_accuracy: 0.7767\n",
            "Epoch 1076/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4368 - accuracy: 0.7777 - val_loss: 0.4361 - val_accuracy: 0.7777\n",
            "Epoch 1077/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4368 - accuracy: 0.7769 - val_loss: 0.4359 - val_accuracy: 0.7782\n",
            "Epoch 1078/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4367 - accuracy: 0.7768 - val_loss: 0.4360 - val_accuracy: 0.7765\n",
            "Epoch 1079/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7768 - val_loss: 0.4361 - val_accuracy: 0.7769\n",
            "Epoch 1080/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7781 - val_loss: 0.4363 - val_accuracy: 0.7768\n",
            "Epoch 1081/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4367 - accuracy: 0.7786 - val_loss: 0.4360 - val_accuracy: 0.7773\n",
            "Epoch 1082/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7763 - val_loss: 0.4357 - val_accuracy: 0.7786\n",
            "Epoch 1083/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7779 - val_loss: 0.4359 - val_accuracy: 0.7781\n",
            "Epoch 1084/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4367 - accuracy: 0.7772 - val_loss: 0.4359 - val_accuracy: 0.7794\n",
            "Epoch 1085/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7774 - val_loss: 0.4359 - val_accuracy: 0.7781\n",
            "Epoch 1086/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7770 - val_loss: 0.4358 - val_accuracy: 0.7784\n",
            "Epoch 1087/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4367 - accuracy: 0.7784 - val_loss: 0.4358 - val_accuracy: 0.7779\n",
            "Epoch 1088/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4366 - accuracy: 0.7774 - val_loss: 0.4359 - val_accuracy: 0.7786\n",
            "Epoch 1089/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7775 - val_loss: 0.4359 - val_accuracy: 0.7785\n",
            "Epoch 1090/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7775 - val_loss: 0.4358 - val_accuracy: 0.7788\n",
            "Epoch 1091/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7776 - val_loss: 0.4357 - val_accuracy: 0.7782\n",
            "Epoch 1092/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7772 - val_loss: 0.4360 - val_accuracy: 0.7784\n",
            "Epoch 1093/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7775 - val_loss: 0.4361 - val_accuracy: 0.7789\n",
            "Epoch 1094/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4366 - accuracy: 0.7765 - val_loss: 0.4367 - val_accuracy: 0.7784\n",
            "Epoch 1095/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7774 - val_loss: 0.4363 - val_accuracy: 0.7777\n",
            "Epoch 1096/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7779 - val_loss: 0.4358 - val_accuracy: 0.7778\n",
            "Epoch 1097/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4366 - accuracy: 0.7770 - val_loss: 0.4358 - val_accuracy: 0.7784\n",
            "Epoch 1098/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.7776 - val_loss: 0.4359 - val_accuracy: 0.7788\n",
            "Epoch 1099/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4367 - accuracy: 0.7776 - val_loss: 0.4358 - val_accuracy: 0.7773\n",
            "Epoch 1100/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4367 - accuracy: 0.7767 - val_loss: 0.4357 - val_accuracy: 0.7785\n",
            "Epoch 1101/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7768 - val_loss: 0.4357 - val_accuracy: 0.7783\n",
            "Epoch 1102/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.4358 - val_accuracy: 0.7774\n",
            "Epoch 1103/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4365 - accuracy: 0.7783 - val_loss: 0.4361 - val_accuracy: 0.7791\n",
            "Epoch 1104/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7777 - val_loss: 0.4359 - val_accuracy: 0.7783\n",
            "Epoch 1105/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4366 - accuracy: 0.7778 - val_loss: 0.4358 - val_accuracy: 0.7781\n",
            "Epoch 1106/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7772 - val_loss: 0.4359 - val_accuracy: 0.7778\n",
            "Epoch 1107/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7780 - val_loss: 0.4359 - val_accuracy: 0.7763\n",
            "Epoch 1108/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7762 - val_loss: 0.4358 - val_accuracy: 0.7782\n",
            "Epoch 1109/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7774 - val_loss: 0.4357 - val_accuracy: 0.7775\n",
            "Epoch 1110/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7776 - val_loss: 0.4360 - val_accuracy: 0.7788\n",
            "Epoch 1111/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4367 - accuracy: 0.7771 - val_loss: 0.4360 - val_accuracy: 0.7769\n",
            "Epoch 1112/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7772 - val_loss: 0.4359 - val_accuracy: 0.7779\n",
            "Epoch 1113/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7769 - val_loss: 0.4360 - val_accuracy: 0.7784\n",
            "Epoch 1114/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4365 - accuracy: 0.7767 - val_loss: 0.4358 - val_accuracy: 0.7776\n",
            "Epoch 1115/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7767 - val_loss: 0.4361 - val_accuracy: 0.7780\n",
            "Epoch 1116/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7767 - val_loss: 0.4356 - val_accuracy: 0.7784\n",
            "Epoch 1117/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4365 - accuracy: 0.7779 - val_loss: 0.4358 - val_accuracy: 0.7792\n",
            "Epoch 1118/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7781 - val_loss: 0.4360 - val_accuracy: 0.7770\n",
            "Epoch 1119/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.7784 - val_loss: 0.4357 - val_accuracy: 0.7779\n",
            "Epoch 1120/1500\n",
            "1219/1219 [==============================] - 4s 4ms/step - loss: 0.4365 - accuracy: 0.7777 - val_loss: 0.4359 - val_accuracy: 0.7783\n",
            "Epoch 1121/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7774 - val_loss: 0.4361 - val_accuracy: 0.7777\n",
            "Epoch 1122/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7773 - val_loss: 0.4357 - val_accuracy: 0.7784\n",
            "Epoch 1123/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4366 - accuracy: 0.7774 - val_loss: 0.4357 - val_accuracy: 0.7775\n",
            "Epoch 1124/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7773 - val_loss: 0.4357 - val_accuracy: 0.7773\n",
            "Epoch 1125/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7777 - val_loss: 0.4357 - val_accuracy: 0.7786\n",
            "Epoch 1126/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7769 - val_loss: 0.4356 - val_accuracy: 0.7777\n",
            "Epoch 1127/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7767 - val_loss: 0.4360 - val_accuracy: 0.7778\n",
            "Epoch 1128/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7776 - val_loss: 0.4358 - val_accuracy: 0.7777\n",
            "Epoch 1129/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7770 - val_loss: 0.4362 - val_accuracy: 0.7783\n",
            "Epoch 1130/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7780 - val_loss: 0.4356 - val_accuracy: 0.7782\n",
            "Epoch 1131/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7777 - val_loss: 0.4358 - val_accuracy: 0.7785\n",
            "Epoch 1132/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7769 - val_loss: 0.4355 - val_accuracy: 0.7784\n",
            "Epoch 1133/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7781 - val_loss: 0.4359 - val_accuracy: 0.7773\n",
            "Epoch 1134/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7770 - val_loss: 0.4367 - val_accuracy: 0.7783\n",
            "Epoch 1135/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7771 - val_loss: 0.4360 - val_accuracy: 0.7771\n",
            "Epoch 1136/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7773 - val_loss: 0.4356 - val_accuracy: 0.7778\n",
            "Epoch 1137/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4363 - accuracy: 0.7775 - val_loss: 0.4358 - val_accuracy: 0.7780\n",
            "Epoch 1138/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4365 - accuracy: 0.7772 - val_loss: 0.4356 - val_accuracy: 0.7782\n",
            "Epoch 1139/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4365 - accuracy: 0.7771 - val_loss: 0.4355 - val_accuracy: 0.7781\n",
            "Epoch 1140/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4365 - accuracy: 0.7770 - val_loss: 0.4356 - val_accuracy: 0.7781\n",
            "Epoch 1141/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7770 - val_loss: 0.4356 - val_accuracy: 0.7775\n",
            "Epoch 1142/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7774 - val_loss: 0.4357 - val_accuracy: 0.7790\n",
            "Epoch 1143/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4364 - accuracy: 0.7768 - val_loss: 0.4356 - val_accuracy: 0.7787\n",
            "Epoch 1144/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.4357 - val_accuracy: 0.7789\n",
            "Epoch 1145/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7779 - val_loss: 0.4357 - val_accuracy: 0.7779\n",
            "Epoch 1146/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4365 - accuracy: 0.7771 - val_loss: 0.4355 - val_accuracy: 0.7781\n",
            "Epoch 1147/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7766 - val_loss: 0.4359 - val_accuracy: 0.7782\n",
            "Epoch 1148/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7772 - val_loss: 0.4354 - val_accuracy: 0.7783\n",
            "Epoch 1149/1500\n",
            "1219/1219 [==============================] - 5s 5ms/step - loss: 0.4364 - accuracy: 0.7779 - val_loss: 0.4355 - val_accuracy: 0.7784\n",
            "Epoch 1150/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7770 - val_loss: 0.4356 - val_accuracy: 0.7776\n",
            "Epoch 1151/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7772 - val_loss: 0.4356 - val_accuracy: 0.7785\n",
            "Epoch 1152/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7768 - val_loss: 0.4358 - val_accuracy: 0.7789\n",
            "Epoch 1153/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7770 - val_loss: 0.4356 - val_accuracy: 0.7775\n",
            "Epoch 1154/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7772 - val_loss: 0.4356 - val_accuracy: 0.7771\n",
            "Epoch 1155/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7772 - val_loss: 0.4358 - val_accuracy: 0.7774\n",
            "Epoch 1156/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7775 - val_loss: 0.4356 - val_accuracy: 0.7783\n",
            "Epoch 1157/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7769 - val_loss: 0.4356 - val_accuracy: 0.7785\n",
            "Epoch 1158/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7771 - val_loss: 0.4357 - val_accuracy: 0.7784\n",
            "Epoch 1159/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7771 - val_loss: 0.4365 - val_accuracy: 0.7755\n",
            "Epoch 1160/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7769 - val_loss: 0.4356 - val_accuracy: 0.7785\n",
            "Epoch 1161/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7777 - val_loss: 0.4353 - val_accuracy: 0.7778\n",
            "Epoch 1162/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7780 - val_loss: 0.4361 - val_accuracy: 0.7762\n",
            "Epoch 1163/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7774 - val_loss: 0.4354 - val_accuracy: 0.7784\n",
            "Epoch 1164/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7777 - val_loss: 0.4355 - val_accuracy: 0.7785\n",
            "Epoch 1165/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7776 - val_loss: 0.4355 - val_accuracy: 0.7774\n",
            "Epoch 1166/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.7765 - val_loss: 0.4354 - val_accuracy: 0.7788\n",
            "Epoch 1167/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7779 - val_loss: 0.4358 - val_accuracy: 0.7773\n",
            "Epoch 1168/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7776 - val_loss: 0.4355 - val_accuracy: 0.7779\n",
            "Epoch 1169/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7773 - val_loss: 0.4355 - val_accuracy: 0.7777\n",
            "Epoch 1170/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.4354 - val_accuracy: 0.7788\n",
            "Epoch 1171/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7772 - val_loss: 0.4355 - val_accuracy: 0.7781\n",
            "Epoch 1172/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7777 - val_loss: 0.4356 - val_accuracy: 0.7787\n",
            "Epoch 1173/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4363 - accuracy: 0.7775 - val_loss: 0.4354 - val_accuracy: 0.7793\n",
            "Epoch 1174/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7782 - val_loss: 0.4355 - val_accuracy: 0.7780\n",
            "Epoch 1175/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4360 - accuracy: 0.7785 - val_loss: 0.4356 - val_accuracy: 0.7774\n",
            "Epoch 1176/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7779 - val_loss: 0.4355 - val_accuracy: 0.7783\n",
            "Epoch 1177/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4364 - accuracy: 0.7774 - val_loss: 0.4354 - val_accuracy: 0.7788\n",
            "Epoch 1178/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7771 - val_loss: 0.4356 - val_accuracy: 0.7785\n",
            "Epoch 1179/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4363 - accuracy: 0.7774 - val_loss: 0.4353 - val_accuracy: 0.7785\n",
            "Epoch 1180/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7770 - val_loss: 0.4356 - val_accuracy: 0.7775\n",
            "Epoch 1181/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7774 - val_loss: 0.4353 - val_accuracy: 0.7782\n",
            "Epoch 1182/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7773 - val_loss: 0.4370 - val_accuracy: 0.7779\n",
            "Epoch 1183/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7775 - val_loss: 0.4352 - val_accuracy: 0.7784\n",
            "Epoch 1184/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7774 - val_loss: 0.4353 - val_accuracy: 0.7791\n",
            "Epoch 1185/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7780 - val_loss: 0.4354 - val_accuracy: 0.7782\n",
            "Epoch 1186/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7775 - val_loss: 0.4354 - val_accuracy: 0.7788\n",
            "Epoch 1187/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7772 - val_loss: 0.4357 - val_accuracy: 0.7778\n",
            "Epoch 1188/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7776 - val_loss: 0.4355 - val_accuracy: 0.7782\n",
            "Epoch 1189/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4363 - accuracy: 0.7772 - val_loss: 0.4353 - val_accuracy: 0.7793\n",
            "Epoch 1190/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7775 - val_loss: 0.4354 - val_accuracy: 0.7785\n",
            "Epoch 1191/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7783 - val_loss: 0.4354 - val_accuracy: 0.7782\n",
            "Epoch 1192/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7779 - val_loss: 0.4353 - val_accuracy: 0.7787\n",
            "Epoch 1193/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7784 - val_loss: 0.4355 - val_accuracy: 0.7782\n",
            "Epoch 1194/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4362 - accuracy: 0.7775 - val_loss: 0.4353 - val_accuracy: 0.7784\n",
            "Epoch 1195/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7778 - val_loss: 0.4353 - val_accuracy: 0.7782\n",
            "Epoch 1196/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4362 - accuracy: 0.7776 - val_loss: 0.4354 - val_accuracy: 0.7780\n",
            "Epoch 1197/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7778 - val_loss: 0.4353 - val_accuracy: 0.7783\n",
            "Epoch 1198/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7785 - val_loss: 0.4355 - val_accuracy: 0.7779\n",
            "Epoch 1199/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4361 - accuracy: 0.7775 - val_loss: 0.4355 - val_accuracy: 0.7785\n",
            "Epoch 1200/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.7775 - val_loss: 0.4353 - val_accuracy: 0.7782\n",
            "Epoch 1201/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7770 - val_loss: 0.4353 - val_accuracy: 0.7787\n",
            "Epoch 1202/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7777 - val_loss: 0.4353 - val_accuracy: 0.7785\n",
            "Epoch 1203/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4361 - accuracy: 0.7777 - val_loss: 0.4355 - val_accuracy: 0.7775\n",
            "Epoch 1204/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7779 - val_loss: 0.4356 - val_accuracy: 0.7775\n",
            "Epoch 1205/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7779 - val_loss: 0.4353 - val_accuracy: 0.7773\n",
            "Epoch 1206/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7784 - val_loss: 0.4353 - val_accuracy: 0.7777\n",
            "Epoch 1207/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7773 - val_loss: 0.4352 - val_accuracy: 0.7784\n",
            "Epoch 1208/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7777 - val_loss: 0.4352 - val_accuracy: 0.7777\n",
            "Epoch 1209/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4362 - accuracy: 0.7776 - val_loss: 0.4352 - val_accuracy: 0.7784\n",
            "Epoch 1210/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4361 - accuracy: 0.7772 - val_loss: 0.4352 - val_accuracy: 0.7779\n",
            "Epoch 1211/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7770 - val_loss: 0.4354 - val_accuracy: 0.7784\n",
            "Epoch 1212/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7774 - val_loss: 0.4352 - val_accuracy: 0.7786\n",
            "Epoch 1213/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7781 - val_loss: 0.4356 - val_accuracy: 0.7778\n",
            "Epoch 1214/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7776 - val_loss: 0.4352 - val_accuracy: 0.7784\n",
            "Epoch 1215/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4361 - accuracy: 0.7781 - val_loss: 0.4353 - val_accuracy: 0.7779\n",
            "Epoch 1216/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4361 - accuracy: 0.7773 - val_loss: 0.4351 - val_accuracy: 0.7789\n",
            "Epoch 1217/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7776 - val_loss: 0.4352 - val_accuracy: 0.7786\n",
            "Epoch 1218/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4353 - val_accuracy: 0.7790\n",
            "Epoch 1219/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4361 - accuracy: 0.7781 - val_loss: 0.4351 - val_accuracy: 0.7784\n",
            "Epoch 1220/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4360 - accuracy: 0.7778 - val_loss: 0.4352 - val_accuracy: 0.7789\n",
            "Epoch 1221/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4360 - accuracy: 0.7784 - val_loss: 0.4353 - val_accuracy: 0.7783\n",
            "Epoch 1222/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4356 - val_accuracy: 0.7769\n",
            "Epoch 1223/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4361 - accuracy: 0.7776 - val_loss: 0.4352 - val_accuracy: 0.7789\n",
            "Epoch 1224/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7773 - val_loss: 0.4355 - val_accuracy: 0.7773\n",
            "Epoch 1225/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4351 - val_accuracy: 0.7786\n",
            "Epoch 1226/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4360 - accuracy: 0.7783 - val_loss: 0.4353 - val_accuracy: 0.7780\n",
            "Epoch 1227/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4351 - val_accuracy: 0.7791\n",
            "Epoch 1228/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4351 - val_accuracy: 0.7787\n",
            "Epoch 1229/1500\n",
            "1219/1219 [==============================] - 6s 5ms/step - loss: 0.4360 - accuracy: 0.7783 - val_loss: 0.4354 - val_accuracy: 0.7776\n",
            "Epoch 1230/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4359 - accuracy: 0.7780 - val_loss: 0.4354 - val_accuracy: 0.7781\n",
            "Epoch 1231/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7775 - val_loss: 0.4352 - val_accuracy: 0.7781\n",
            "Epoch 1232/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7783 - val_loss: 0.4353 - val_accuracy: 0.7784\n",
            "Epoch 1233/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4360 - accuracy: 0.7776 - val_loss: 0.4353 - val_accuracy: 0.7788\n",
            "Epoch 1234/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7776 - val_loss: 0.4350 - val_accuracy: 0.7787\n",
            "Epoch 1235/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4358 - accuracy: 0.7780 - val_loss: 0.4352 - val_accuracy: 0.7787\n",
            "Epoch 1236/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4359 - accuracy: 0.7777 - val_loss: 0.4352 - val_accuracy: 0.7778\n",
            "Epoch 1237/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4360 - accuracy: 0.7778 - val_loss: 0.4361 - val_accuracy: 0.7788\n",
            "Epoch 1238/1500\n",
            "1219/1219 [==============================] - 4s 3ms/step - loss: 0.4359 - accuracy: 0.7788 - val_loss: 0.4351 - val_accuracy: 0.7792\n",
            "Epoch 1239/1500\n",
            "1219/1219 [==============================] - 5s 4ms/step - loss: 0.4359 - accuracy: 0.7785 - val_loss: 0.4350 - val_accuracy: 0.7789\n",
            "Epoch 1240/1500\n",
            " 435/1219 [=========>....................] - ETA: 1s - loss: 0.4353 - accuracy: 0.7799"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph the trajectory of the loss functions, accuracy on both train and test set"
      ],
      "metadata": {
        "id": "GX54_q8_LaTb"
      },
      "id": "GX54_q8_LaTb"
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (supple_model.predict(X_test_norm) > 0.5 ).astype('int32')\n",
        "y_pred_prob_nn_1 = supple_model.predict(X_test_norm)"
      ],
      "metadata": {
        "id": "oMludZdsLbaH"
      },
      "id": "oMludZdsLbaH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supple_hist_1.history.keys()"
      ],
      "metadata": {
        "id": "AO9YZcQCLkg0"
      },
      "id": "AO9YZcQCLkg0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(supple_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(supple_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "gsDooM1GLlmo"
      },
      "id": "gsDooM1GLlmo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1Z76I6DEJ2B1bX6-taErtGxD1173pH0TN?usp=sharing"
      ],
      "metadata": {
        "id": "ViM-QA8rM11r"
      },
      "id": "ViM-QA8rM11r"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}